{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8081439,"sourceType":"datasetVersion","datasetId":4749401},{"sourceId":8122822,"sourceType":"datasetVersion","datasetId":4747496},{"sourceId":28272,"sourceType":"modelInstanceVersion","modelInstanceId":23804},{"sourceId":29043,"sourceType":"modelInstanceVersion","modelInstanceId":24461}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchinfo\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchinfo import summary\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator, GloVe, vocab\nfrom tqdm import tqdm\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom collections import OrderedDict","metadata":{"execution":{"iopub.status.busy":"2024-04-17T17:14:59.491536Z","iopub.execute_input":"2024-04-17T17:14:59.492248Z","iopub.status.idle":"2024-04-17T17:15:26.725099Z","shell.execute_reply.started":"2024-04-17T17:14:59.492213Z","shell.execute_reply":"2024-04-17T17:15:26.723285Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchinfo in /opt/conda/lib/python3.10/site-packages (1.8.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 1. HAN Analysis","metadata":{}},{"cell_type":"markdown","source":"This notebook corresponds to the discussion section of the report. First, define the model:","metadata":{}},{"cell_type":"code","source":"class AttentionUnit(nn.Module):\n    def __init__(self, input_dim, hidden_dim=None, num_outputs=1, attn_dropout=0.0):\n        super(AttentionUnit, self).__init__()\n        if hidden_dim is None:\n            hidden_dim = input_dim\n        self.hidden = nn.Linear(input_dim, hidden_dim)\n        self.query = nn.Linear(hidden_dim, num_outputs, bias=False)\n        \n    def forward(self, encoder_output, padding_positions=None, return_weights=False):\n        # [B,L,I]-->[B,L,H]\n        hidden_rep = F.tanh(self.hidden(encoder_output))\n        \n        # [B,L,H]-->[B,L,1]\n        similarity = self.query(hidden_rep)\n        if padding_positions is not None:\n            similarity = similarity.masked_fill(padding_positions, -float('inf'))\n        attention_weights = F.softmax(similarity, dim=1)\n        \n        #Return weighted sum [B,L,1], [B,L,H]-->[B,H]\n        if return_weights:\n            return torch.bmm(attention_weights.transpose(1,2), hidden_rep).squeeze(1), attention_weights\n        return torch.bmm(attention_weights.transpose(1,2), hidden_rep).squeeze(1)\n\nclass BiLSTMHeAttFCNNClassifier(nn.Module):\n    '''\n    Classifier that uses heirarchical attention to encode a document and \n    a Fully-Connected Neural Network(FCNN) as a decoder.\n\n    '''\n    def __init__(self, vocab_len, embed_dim, hidden_dim, num_lstm_layers, num_classes, attn_dropout=0.0, pretrained_embeddings=None, freeze_embeds=False):\n        super(BiLSTMHeAttFCNNClassifier, self).__init__()\n        if pretrained_embeddings is not None:\n            self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=freeze_embeds)\n        else:\n            self.embedding = nn.Embedding(num_embeddings=vocab_len, embedding_dim=embed_dim)\n        \n        self.word_encoder = nn.LSTM(input_size=embed_dim, hidden_size=hidden_dim, num_layers=num_lstm_layers, batch_first=True, bidirectional=True)\n        self.word_attn = AttentionUnit(2*hidden_dim)\n        \n        self.sent_encoder = nn.LSTM(input_size=2*hidden_dim, hidden_size=hidden_dim, num_layers=num_lstm_layers, batch_first=True, bidirectional=True)\n        self.sent_attn = AttentionUnit(2*hidden_dim)\n        \n        self.decoder = nn.Linear(2*hidden_dim, num_classes)\n\n\n    def forward(self, X_batch, num_sents, sent_lens, return_attn_weights=False):\n        '''\n        Returns logits if return_attn_weights is False,\n        else returns (logits, word-level attention weights, sentence-level attention weights)\n        '''\n        max_sent_len = X_batch.shape[2]\n        max_num_sent = X_batch.shape[1]\n        \n        # Use word embeddings to form sentence embeddings\n        word_attn_weights = []\n        docs = []\n        for doc, n, lens in zip(X_batch, num_sents, sent_lens):\n            words_batch = doc[:n]\n            embeddings = self.embedding(words_batch)\n            output, (_, _) = self.word_encoder(embeddings)\n            padding_positions = self.__get_padding_masks(lens[:n], max_sent_len).to(output.device)\n            sent_embeddings = self.word_attn(output, padding_positions=padding_positions, return_weights=return_attn_weights)\n            if return_attn_weights:\n                word_attn_weights.append(sent_embeddings[1])\n                sent_embeddings = sent_embeddings[0]\n            sent_embeddings = self.__repad_sentence_embeddings(sent_embeddings, max_num_sent)\n            docs.append(sent_embeddings)\n        \n        # Use sentence embeddings to form document embedding\n        sent_embeddings_batch = torch.stack(docs) \n        output, (_, _) = self.sent_encoder(sent_embeddings_batch)\n        padding_positions = self.__get_padding_masks(num_sents, max_num_sent).to(output.device)\n        doc_embeddings = self.word_attn(output, padding_positions=padding_positions, return_weights=return_attn_weights)\n        # Pass document embedding through output layer\n        if return_attn_weights:\n            return self.decoder(doc_embeddings[0]), word_attn_weights, doc_embeddings[1]\n        else:\n            return self.decoder(doc_embeddings)\n        \n    def __repad_sentence_embeddings(self, sents, max_num_sent):\n        return torch.cat([sents,\n                          torch.zeros((max_num_sent-sents.shape[0], \n                                       sents.shape[1]), device=sents.device)],dim=0)\n    \n    def __get_padding_masks(self, lengths, max_len):\n        '''\n        Returns a mask (shape BxLx1) that indicates the position of pad tokens as '1's\n        '''\n        return torch.tensor([[False]*i + [True]*(max_len-i) for i in lengths]).unsqueeze(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T11:13:59.299797Z","iopub.execute_input":"2024-04-17T11:13:59.300626Z","iopub.status.idle":"2024-04-17T11:13:59.332230Z","shell.execute_reply.started":"2024-04-17T11:13:59.300581Z","shell.execute_reply":"2024-04-17T11:13:59.330338Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## 1. Categorized evals","metadata":{}},{"cell_type":"markdown","source":"Set hyperparameters and load model","metadata":{}},{"cell_type":"code","source":"MAX_SENT_LEN = 30\nMAX_NUM_SENTS = 30\nNUM_CLASSES = 4\nEMBED_DIM = 100\nHIDDEN_DIM = 100\nNUM_LSTM_LAYERS = 1\n\nVOCAB_LEN = 400001 #harcoded for convenience; see below for how it was obtained\n# glove, _ = DataPreprocessorHcl.from_pretrained_embeds(NUM_CLASSES,'/kaggle/input/lun-glove/glove.6B.100d.txt', EMBED_DIM)\n# VOCAB_LEN = len(glove.vocab)\n\nMODEL_PATH = './outputs/model/bestHAN_msl30_mns30_ba256_emb100hid100lay1cla4_ep10lr0.0005wd5e-06_af0.5_ap2_model.pt'\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = BiLSTMHeAttFCNNClassifier(VOCAB_LEN, EMBED_DIM, HIDDEN_DIM, NUM_LSTM_LAYERS, NUM_CLASSES)\nmodel.to(DEVICE)\nmodel.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))","metadata":{"execution":{"iopub.status.busy":"2024-04-17T11:13:59.335016Z","iopub.execute_input":"2024-04-17T11:13:59.335563Z","iopub.status.idle":"2024-04-17T11:14:03.804449Z","shell.execute_reply.started":"2024-04-17T11:13:59.335522Z","shell.execute_reply":"2024-04-17T11:14:03.802749Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"Load Preprocessed test data and sub-categorized test data","metadata":{"execution":{"iopub.status.busy":"2024-04-11T12:15:02.320834Z","iopub.execute_input":"2024-04-11T12:15:02.321256Z","iopub.status.idle":"2024-04-11T12:15:04.003140Z","shell.execute_reply.started":"2024-04-11T12:15:02.321225Z","shell.execute_reply":"2024-04-11T12:15:04.002122Z"}}},{"cell_type":"code","source":"X_hier_test = np.load('./HAN_prepro_data/X_test_prep.npy')\nylens_test = pd.read_csv('./HAN_prepro_data/ylens_test_prep.csv')\nimport ast\nylens_test['Num_Tokens'] = ylens_test['Num_Tokens'].apply(ast.literal_eval)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:09:24.706770Z","iopub.execute_input":"2024-04-17T07:09:24.707200Z","iopub.status.idle":"2024-04-17T07:09:25.041161Z","shell.execute_reply.started":"2024-04-17T07:09:24.707168Z","shell.execute_reply":"2024-04-17T07:09:25.039750Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"test_df_categorised = pd.read_csv('/kaggle/input/lun-glove/balancedtestwithclass_new_cleaned.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T16:36:32.672581Z","iopub.execute_input":"2024-04-16T16:36:32.672997Z","iopub.status.idle":"2024-04-16T16:36:32.771911Z","shell.execute_reply.started":"2024-04-16T16:36:32.672959Z","shell.execute_reply":"2024-04-16T16:36:32.770801Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\ndef categorised_eval(categories_df, X, ylens, model, device, category_list=[0,1,2,3,4,5], batch_size=128, return_preds=False):\n    all_preds = []\n    records = {'category':[], 'support':[], 'acc':[], 'f1':[], 'precision':[], 'recall':[]}\n    for cat in category_list:\n        idx = categories_df[categories_df['Category']==cat].index\n        ylens_cat = ylens.loc[idx]\n        X_cat = X[idx]\n        \n        model.to(device)\n        preds=[]\n        truths=[]\n        \n        for tokens, (_, (label, num_sent, sent_len)) in tqdm(zip(X_cat, ylens_cat[['Label','Num_Sentences','Num_Tokens']].iterrows())):\n            \n            X_in = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n            num_sent = torch.tensor(num_sent, dtype=torch.long).unsqueeze(0)\n            sent_len = torch.tensor(sent_len, dtype=torch.long).unsqueeze(0)\n            \n            #Forward pass\n            outputs = model(X_in, num_sent, sent_len, return_attn_weights=False)\n\n            #Logging\n            preds.append(torch.argmax(outputs, dim=-1).cpu().item())\n            truths.append(label)\n        \n        records['category'].append(cat)\n        records['support'].append(len(X_cat))\n        records['acc'].append(accuracy_score(truths, preds))\n        records['f1'].append(f1_score(truths, preds, average='macro'))\n        records['precision'].append(precision_score(truths, preds, average='macro'))\n        records['recall'].append(recall_score(truths, preds, average='macro'))\n        all_preds.append((idx,preds,truths))\n    return records if not return_preds else (records, all_preds)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:09:35.562872Z","iopub.execute_input":"2024-04-17T07:09:35.563363Z","iopub.status.idle":"2024-04-17T07:09:35.579910Z","shell.execute_reply.started":"2024-04-17T07:09:35.563327Z","shell.execute_reply":"2024-04-17T07:09:35.578585Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"results, preds = categorised_eval(test_df_categorised, X_hier_test, ylens_test, model, DEVICE, category_list=[0,1,2,3,4,5], batch_size=128, return_preds=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:09:41.555962Z","iopub.execute_input":"2024-04-17T07:09:41.556431Z","iopub.status.idle":"2024-04-17T07:10:17.872005Z","shell.execute_reply.started":"2024-04-17T07:09:41.556398Z","shell.execute_reply":"2024-04-17T07:10:17.870198Z"},"trusted":true},"execution_count":120,"outputs":[{"name":"stderr","text":"179it [00:02, 77.85it/s]\n112it [00:01, 93.76it/s]\n559it [00:07, 72.61it/s]\n930it [00:11, 82.10it/s] \n1051it [00:11, 88.23it/s]\n169it [00:01, 95.39it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(results)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T15:05:50.098513Z","iopub.execute_input":"2024-04-15T15:05:50.099229Z","iopub.status.idle":"2024-04-15T15:05:50.116859Z","shell.execute_reply.started":"2024-04-15T15:05:50.099191Z","shell.execute_reply":"2024-04-15T15:05:50.115003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(results).to_csv('./outputs/HAN_categorized_eval_results.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-15T07:49:56.978768Z","iopub.execute_input":"2024-04-15T07:49:56.979281Z","iopub.status.idle":"2024-04-15T07:49:56.988593Z","shell.execute_reply.started":"2024-04-15T07:49:56.979241Z","shell.execute_reply":"2024-04-15T07:49:56.987028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# health propaganda articles\nprophealth = test_df_categorised[(test_df_categorised['Category']==2) & (test_df_categorised['Label'] == 3)]\nprophealth","metadata":{"execution":{"iopub.status.busy":"2024-04-16T16:35:42.932901Z","iopub.execute_input":"2024-04-16T16:35:42.934022Z","iopub.status.idle":"2024-04-16T16:35:42.948024Z","shell.execute_reply.started":"2024-04-16T16:35:42.933980Z","shell.execute_reply":"2024-04-16T16:35:42.946745Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                                   Text  Label  Category  \\\n1500   New research suggests that one of the more po...      3         2   \n1503   Infectious disease medicine and psychiatry ha...      3         2   \n1504   Water fluoridation may cause hypothyroidism a...      3         2   \n1507   As controversial as it may sound, botox has n...      3         2   \n1508   Having bad skin is something that millions of...      3         2   \n...                                                 ...    ...       ...   \n2242   There's a good chance that the vast majority ...      3         2   \n2245   Medicinal substances that can effectively hel...      3         2   \n2246   Tweet (NewsTarget) Viruses that cause winter ...      3         2   \n2247   Tweet (NewsTarget) The foundation of a health...      3         2   \n2249   There are plenty of good reasons why, in a wo...      3         2   \n\n      Length  \n1500     728  \n1503     618  \n1504     630  \n1507    1537  \n1508     473  \n...      ...  \n2242     525  \n2245     594  \n2246     489  \n2247     707  \n2249     706  \n\n[493 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Category</th>\n      <th>Length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1500</th>\n      <td>New research suggests that one of the more po...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>728</td>\n    </tr>\n    <tr>\n      <th>1503</th>\n      <td>Infectious disease medicine and psychiatry ha...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>618</td>\n    </tr>\n    <tr>\n      <th>1504</th>\n      <td>Water fluoridation may cause hypothyroidism a...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>630</td>\n    </tr>\n    <tr>\n      <th>1507</th>\n      <td>As controversial as it may sound, botox has n...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1537</td>\n    </tr>\n    <tr>\n      <th>1508</th>\n      <td>Having bad skin is something that millions of...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>473</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2242</th>\n      <td>There's a good chance that the vast majority ...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>525</td>\n    </tr>\n    <tr>\n      <th>2245</th>\n      <td>Medicinal substances that can effectively hel...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>594</td>\n    </tr>\n    <tr>\n      <th>2246</th>\n      <td>Tweet (NewsTarget) Viruses that cause winter ...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>489</td>\n    </tr>\n    <tr>\n      <th>2247</th>\n      <td>Tweet (NewsTarget) The foundation of a health...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>707</td>\n    </tr>\n    <tr>\n      <th>2249</th>\n      <td>There are plenty of good reasons why, in a wo...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>706</td>\n    </tr>\n  </tbody>\n</table>\n<p>493 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nprint(classification_report(test_df_categorised[test_df_categorised['Category'] == 2]['Label'], test_df_categorised[test_df_categorised['Category'] == 2]['prediction']))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:18:07.354071Z","iopub.execute_input":"2024-04-16T17:18:07.354461Z","iopub.status.idle":"2024-04-16T17:18:07.370833Z","shell.execute_reply.started":"2024-04-16T17:18:07.354433Z","shell.execute_reply":"2024-04-16T17:18:07.370009Z"},"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           1       0.48      0.62      0.54        16\n           2       0.35      0.33      0.34        18\n           3       0.96      0.78      0.86       493\n           4       0.21      0.81      0.34        32\n\n    accuracy                           0.76       559\n   macro avg       0.50      0.64      0.52       559\nweighted avg       0.89      0.76      0.81       559\n\n","output_type":"stream"}]},{"cell_type":"code","source":"prophealth[prophealth['Label'] != prophealth['prediction']]","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:39:43.188963Z","iopub.execute_input":"2024-04-16T17:39:43.189447Z","iopub.status.idle":"2024-04-16T17:39:43.205213Z","shell.execute_reply.started":"2024-04-16T17:39:43.189415Z","shell.execute_reply":"2024-04-16T17:39:43.203888Z"},"trusted":true},"execution_count":145,"outputs":[{"execution_count":145,"output_type":"execute_result","data":{"text/plain":"                                                   Text  Label  Category  \\\n1500   New research suggests that one of the more po...      3         2   \n1512   Tweet Eli Lilly treated the American public '...      3         2   \n1526   Tens of millions of Americans are obese, and ...      3         2   \n1535   Compared to land vegetables like broccoli and...      3         2   \n1540   Tweet (NewsTarget) In the third installment o...      3         2   \n...                                                 ...    ...       ...   \n2202   Winter is the season of the kidney according ...      3         2   \n2203   June is National Fresh Fruit and Vegetable Mo...      3         2   \n2208   As terrifying as a diagnosis of cancer can be...      3         2   \n2220   From happy childish squeals of delight during...      3         2   \n2239   Nearly all non-organic veggie burgers on the ...      3         2   \n\n      Length  prediction  \n1500     728           4  \n1512     291           2  \n1526     785           4  \n1535     551           4  \n1540      84           1  \n...      ...         ...  \n2202     515           4  \n2203     337           4  \n2208     587           4  \n2220     614           4  \n2239     315           4  \n\n[108 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Category</th>\n      <th>Length</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1500</th>\n      <td>New research suggests that one of the more po...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>728</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1512</th>\n      <td>Tweet Eli Lilly treated the American public '...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>291</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1526</th>\n      <td>Tens of millions of Americans are obese, and ...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>785</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1535</th>\n      <td>Compared to land vegetables like broccoli and...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>551</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1540</th>\n      <td>Tweet (NewsTarget) In the third installment o...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>84</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2202</th>\n      <td>Winter is the season of the kidney according ...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>515</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2203</th>\n      <td>June is National Fresh Fruit and Vegetable Mo...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>337</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2208</th>\n      <td>As terrifying as a diagnosis of cancer can be...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>587</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2220</th>\n      <td>From happy childish squeals of delight during...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>614</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2239</th>\n      <td>Nearly all non-organic veggie burgers on the ...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>315</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>108 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 2. Visualizing attention","metadata":{}},{"cell_type":"code","source":"class AttnVizPreprocessorHcl():\n\n    def __init__(self, data_vocab):\n        self.vocab = data_vocab\n        print(\"Vocab created: {} unique tokens\".format(len(self.vocab)))\n        \n    @classmethod\n    def from_pretrained_embeds(cls, embed_path, embed_dim, sep=\" \",  specials=['<unk>']):\n        # start with all '0's for special tokens\n        embeds = [np.asarray([0]*embed_dim, dtype=np.float32)]*len(specials)\n        words = OrderedDict()\n        with open(embed_path, encoding=\"utf-8\") as f:\n            for i, line in enumerate(f):\n                if i == 38522 and 'twitter.27B.100d' in embed_path:\n                    continue\n                splitline = line.split()\n                \n                word = splitline[0]\n                if word not in words:\n                    words[word] = 0\n                words[word]+=1\n                embeds.append(np.asarray(splitline[1:], dtype=np.float32))\n                \n        embeds = torch.tensor(np.array(embeds))\n        data_vocab = vocab(words, specials=specials)\n        data_vocab.set_default_index(data_vocab['<unk>'])\n        return cls(data_vocab)\n\n    def get_vocab_size(self):\n        return len(self.vocab)\n    \n    def preprocess_single_row(self, row, max_sent_len, max_num_sents, preprocess_label=False):\n        '''\n        Converts text into integers that index the vocab,\n        and converts labels into the range [0,num_classes-1]\n        \n        Return tokens by sentence (unpadded), idx by sentence (padded), label, num_sentences, num_tokens\n        '''\n        text = row['Text']\n        label = row['Label']\n        \n        words = [word_tokenize(sent.lower()) for sent in sent_tokenize(text.replace(\"'\",\"\"))]\n        token_idxs = [self.vocab(sent) for sent in words]\n        num_sentences = min(max_num_sents, len(words))\n        num_tokens = [min(max_sent_len, len(sent)) for sent in words][:max_num_sents]\n        num_tokens = num_tokens + [0 for _ in range(max_sent_len-len(num_tokens))] #padding\n        \n        tokens_padded = np.zeros((1, max_num_sents, max_sent_len), dtype='int32')\n        for j, sent in enumerate(token_idxs):\n            if j >= max_num_sents:\n                break\n            k = min(max_sent_len, len(sent))\n            tokens_padded[0,j,:k] = sent[:k]\n                \n        if preprocess_label:\n            label -= 1\n        return words, torch.tensor(tokens_padded, dtype=torch.long), label,\\\n                torch.tensor(num_sentences, dtype=torch.long).unsqueeze(0),\\\n                torch.tensor(num_tokens, dtype=torch.long).unsqueeze(0)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:08:43.493790Z","iopub.execute_input":"2024-04-17T12:08:43.494771Z","iopub.status.idle":"2024-04-17T12:08:43.517131Z","shell.execute_reply.started":"2024-04-17T12:08:43.494717Z","shell.execute_reply":"2024-04-17T12:08:43.515384Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"MAX_SENT_LEN = 30\nMAX_NUM_SENTS = 30\nNUM_CLASSES = 4\nEMBED_DIM = 100\nHIDDEN_DIM = 100\nNUM_LSTM_LAYERS = 1\n\nVOCAB_LEN = 400001 #harcoded for convenience; see below for how it was obtained\n# glove, _ = DataPreprocessorHcl.from_pretrained_embeds(NUM_CLASSES,'/kaggle/input/lun-glove/glove.6B.100d.txt', EMBED_DIM)\n# VOCAB_LEN = len(glove.vocab)\n\nMODEL_PATH = '/kaggle/input/bilstmheattnewsclassifier/pytorch/best_performing/1/glounfro_clean_msl30_mns30_batch256_embed100hidden100layers1classes4_ep10lr0.0005wd5e-06_af0.5_ap2.pt'\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodelhan = BiLSTMHeAttFCNNClassifier(VOCAB_LEN, EMBED_DIM, HIDDEN_DIM, NUM_LSTM_LAYERS, NUM_CLASSES)\nmodelhan.to(DEVICE)\nmodelhan.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\nmodelhan.eval()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:29:09.862080Z","iopub.execute_input":"2024-04-17T07:29:09.862587Z","iopub.status.idle":"2024-04-17T07:29:10.497473Z","shell.execute_reply.started":"2024-04-17T07:29:09.862554Z","shell.execute_reply":"2024-04-17T07:29:10.496225Z"},"trusted":true},"execution_count":159,"outputs":[{"execution_count":159,"output_type":"execute_result","data":{"text/plain":"BiLSTMHeAttFCNNClassifier(\n  (embedding): Embedding(400001, 100)\n  (word_encoder): LSTM(100, 100, batch_first=True, bidirectional=True)\n  (word_attn): AttentionUnit(\n    (hidden): Linear(in_features=200, out_features=200, bias=True)\n    (query): Linear(in_features=200, out_features=1, bias=False)\n  )\n  (sent_encoder): LSTM(200, 100, batch_first=True, bidirectional=True)\n  (sent_attn): AttentionUnit(\n    (hidden): Linear(in_features=200, out_features=200, bias=True)\n    (query): Linear(in_features=200, out_features=1, bias=False)\n  )\n  (decoder): Linear(in_features=200, out_features=4, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"EMBED_PATH = '/kaggle/input/lun-glove/glove.6B.100d.txt'\nEMBED_DIM = 100\nMAX_SENT_LEN = 30\nMAX_NUM_SENT = 30\npp = AttnVizPreprocessorHcl.from_pretrained_embeds(EMBED_PATH, EMBED_DIM)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:08:53.410761Z","iopub.execute_input":"2024-04-17T12:08:53.411265Z","iopub.status.idle":"2024-04-17T12:09:10.423637Z","shell.execute_reply.started":"2024-04-17T12:08:53.411225Z","shell.execute_reply":"2024-04-17T12:09:10.422139Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Vocab created: 400001 unique tokens\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/lun-glove/fulltrain.csv', header=None, names=['Label','Text'])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:38:50.648075Z","iopub.execute_input":"2024-04-17T06:38:50.648599Z","iopub.status.idle":"2024-04-17T06:38:53.683413Z","shell.execute_reply.started":"2024-04-17T06:38:50.648562Z","shell.execute_reply":"2024-04-17T06:38:53.682284Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import re\nHEDGE_REGEX = r\"may|might|possib|probab|assum|likely|perhap|seem\"\n\ntrain_df['lengths'] = train_df['Text'].apply(lambda s: len(s.split()))\ntrain_df['has_hedge'] = train_df['Text'].apply(lambda text : len(re.findall(HEDGE_REGEX, text)))\ntrain_df['has_2p'] = train_df['Text'].apply(lambda text : len(re.findall(\"you\",text)))\ntrain_df['has_1ps'] = train_df['Text'].apply(lambda text : len(re.findall(r\"\\b(I|i)\\b\", text)))\ntrain_df['has_nums'] = train_df['Text'].apply(lambda text : len(re.findall(r\"[0-9]|millio|trillio|billio|dollar|\\$|\\%\", text)))\n\ntrain_df['has_bri_ire_afh_am_hondu'] = train_df['Text'].apply(lambda text : len(re.findall(r\"brit|afgha|america|u.s|hondur|ire\", text)))","metadata":{"execution":{"iopub.status.busy":"2024-04-17T03:23:57.235338Z","iopub.execute_input":"2024-04-17T03:23:57.235810Z","iopub.status.idle":"2024-04-17T03:24:27.754575Z","shell.execute_reply.started":"2024-04-17T03:23:57.235774Z","shell.execute_reply":"2024-04-17T03:24:27.753146Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_df[train_df.has_hedge > 0]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T03:25:03.100589Z","iopub.execute_input":"2024-04-17T03:25:03.101021Z","iopub.status.idle":"2024-04-17T03:25:03.123623Z","shell.execute_reply.started":"2024-04-17T03:25:03.100987Z","shell.execute_reply":"2024-04-17T03:25:03.122463Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"       Label                                               Text  lengths  \\\n0          1  A little less than a decade ago, hockey fans w...      146   \n1          1  The writers of the HBO series The Sopranos too...      122   \n2          1  Despite claims from the TV news outlet to offe...      705   \n3          1  After receiving 'subpar' service and experienc...      705   \n5          1  At a cafeteria-table press conference Monday, ...       93   \n...      ...                                                ...      ...   \n48829      4  Opposition Democratic Progressive Party (DPP) ...      319   \n48833      4  Taiwan is likely to be affected by a dust stor...      147   \n48838      4  President Ma Ying-jeou said Wednesday that a s...      368   \n48842      4  A preliminary report on the cause of the April...      476   \n48852      4  The families of the four people who were kille...      245   \n\n       has_hedge  has_2p  has_1ps  has_nums  has_bri_ire_afh_am_hondu  \n0              2       0        0         0                         2  \n1              1       0        1         3                         0  \n2              2       3        0        35                        15  \n3              2       3       15        18                         2  \n5              1       0        1         7                         0  \n...          ...     ...      ...       ...                       ...  \n48829          1       0        0        11                         2  \n48833          1       0        0         7                         4  \n48838          1       0        0        19                         4  \n48842          1       0        0         5                         7  \n48852          1       0        0         8                         0  \n\n[24750 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Text</th>\n      <th>lengths</th>\n      <th>has_hedge</th>\n      <th>has_2p</th>\n      <th>has_1ps</th>\n      <th>has_nums</th>\n      <th>has_bri_ire_afh_am_hondu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>A little less than a decade ago, hockey fans w...</td>\n      <td>146</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>The writers of the HBO series The Sopranos too...</td>\n      <td>122</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Despite claims from the TV news outlet to offe...</td>\n      <td>705</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>35</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>After receiving 'subpar' service and experienc...</td>\n      <td>705</td>\n      <td>2</td>\n      <td>3</td>\n      <td>15</td>\n      <td>18</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>At a cafeteria-table press conference Monday, ...</td>\n      <td>93</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48829</th>\n      <td>4</td>\n      <td>Opposition Democratic Progressive Party (DPP) ...</td>\n      <td>319</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>48833</th>\n      <td>4</td>\n      <td>Taiwan is likely to be affected by a dust stor...</td>\n      <td>147</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>48838</th>\n      <td>4</td>\n      <td>President Ma Ying-jeou said Wednesday that a s...</td>\n      <td>368</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>19</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>48842</th>\n      <td>4</td>\n      <td>A preliminary report on the cause of the April...</td>\n      <td>476</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>48852</th>\n      <td>4</td>\n      <td>The families of the four people who were kille...</td>\n      <td>245</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>24750 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_test = np.load('./HAN_prepro_data/X_test_prep.npy')\nylens_test = pd.read_csv('./HAN_prepro_data/ylens_test_prep.csv')\nimport ast\nylens_test['Num_Tokens'] = ylens_test['Num_Tokens'].apply(ast.literal_eval)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T03:21:40.408726Z","iopub.execute_input":"2024-04-17T03:21:40.409350Z","iopub.status.idle":"2024-04-17T03:21:40.805905Z","shell.execute_reply.started":"2024-04-17T03:21:40.409316Z","shell.execute_reply":"2024-04-17T03:21:40.804871Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"test_df_categorised = pd.read_csv('./HAN_prepro_data/balancedtestwithclass_new_cleaned.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T06:14:38.380764Z","iopub.execute_input":"2024-04-16T06:14:38.381078Z","iopub.status.idle":"2024-04-16T06:14:38.610961Z","shell.execute_reply.started":"2024-04-16T06:14:38.381053Z","shell.execute_reply":"2024-04-16T06:14:38.609704Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import re\nHEDGE_REGEX = r\"may|might|possib|probab|assum|likely|perhap|seem\"\n\ntest_df_categorised['lengths'] = test_df_categorised['Text'].apply(lambda s: len(s.split()))\ntest_df_categorised['has_hedge'] = test_df_categorised['Text'].apply(lambda text : len(re.findall(HEDGE_REGEX, text)))\ntest_df_categorised['has_2p'] = test_df_categorised['Text'].apply(lambda text : len(re.findall(\"you\",text)))\ntest_df_categorised['has_1ps'] = test_df_categorised['Text'].apply(lambda text : len(re.findall(r\"\\b(I|i)\\b\", text)))\ntest_df_categorised['has_nums'] = test_df_categorised['Text'].apply(lambda text : len(re.findall(r\"[0-9]|millio|trillio|billio|dollar|\\$|\\%\", text)))\n\ntest_df_categorised['has_bri_ire_afh_am_hondu'] = test_df_categorised['Text'].apply(lambda text : len(re.findall(r\"brit|afgha|america|u.s|hondur|ire\", text)))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:26:28.660317Z","iopub.execute_input":"2024-04-16T07:26:28.660757Z","iopub.status.idle":"2024-04-16T07:26:30.418112Z","shell.execute_reply.started":"2024-04-16T07:26:28.660726Z","shell.execute_reply":"2024-04-16T07:26:30.417059Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"\nimport torch\nimport json\nfrom IPython.display import Markdown, display\n\nlabelid2label = ['Satire', 'Hoax', 'Propaganda', 'Trusted']\n\nclass AttentionVisualizerHcl():\n    def __init__(self, model, preprocessor):\n\n        class Struct:\n            def __init__(self, **entries):\n                self.__dict__.update(entries)\n        \n        self.model = model\n        self.preprocessor = preprocessor\n\n    def visualize_attention(self, doc_and_label_row, max_sent_len, max_num_sents, device='cpu', preprocess_label=False, sents_only=False):\n        # doc_and_label_row should contain a row of the df with columns ['Text'] and ['Label']\n        \n        words, X, y, num_sentences, num_tokens = self.preprocessor.preprocess_single_row(doc_and_label_row, max_sent_len, max_num_sents, preprocess_label)\n        pred, word_weights, sent_weights = self.model(X, num_sentences, num_tokens, return_attn_weights=True)\n        pred = torch.argmax(pred, dim = -1).cpu().item()\n        # remove the padding elements (which have 0 weight)\n        sent_weights = sent_weights.squeeze(0,2)[:num_sentences]\n        word_weights = word_weights[0].squeeze(2).tolist()\n        word_weights = [weights[:num] for num, weights in zip(num_tokens[0], word_weights)]\n        \n        display(Markdown('<p style=\"font-size:18px\"> Ground Truth: '+ labelid2label[y] + '&emsp;&emsp;&emsp;Prediction: '+labelid2label[pred] +'</p>'))\n        i = 0\n        if sents_only:\n            line = []\n            for sent_weight in sent_weights:\n                sent_weight = sent_weight.item()\n                line.append('<span style=\"background-color:rgba(255,0,0,' +\\\n                        str(sent_weight) +\\\n                        ');font-size:16px;color:rgba(255,0,0,0);\">' + '_____' + '</span>')\n            display(Markdown(\" \".join(line)))\n            return words, word_weights, sent_weights\n        max_weight_sent = max(map(max, word_weights))\n        min_weight_sent = min(map(min, word_weights))\n        \n        for sent, word_weights_sent, sent_weight in zip(words, word_weights, sent_weights):\n            i += 1\n            sent_weight = sent_weight.item()\n            line = [self.__make_sent(sent_weight)]\n            line_length = 5\n            for word, word_weight in zip(sent, word_weights_sent):\n                line_length += len(word) + 1\n                line.append(self.__make_word(word, self.__scale_weight(word_weight,\n                                                                       max_weight_sent,\n                                                                       min_weight_sent),\n                                             sent_weight))\n                \n                if line_length > 60:\n                    display(Markdown(\" \".join(line)))\n                    line = [self.__make_blank()]\n                    line_length = 5\n                    \n            display(Markdown(\" \".join(line)))\n        return words, word_weights, sent_weights\n\n    def __make_blank(self):\n        return '<span style=\"color:rgba(255,255,255,0);font-size:16px\">' + '_____' + '</span>'\n    \n    def __make_sent(self, sent_weight):\n        return '<span style=\"background-color:rgba(255,0,0,' +\\\n                    str(sent_weight) +\\\n                    ');font-size:16px;color:rgba(255,0,0,0);\">' + '_____' + '</span>'\n    \n    def __make_word(self, word, word_weight, sent_weight):\n        return '<span style=\"background-color:rgba(0,0,255,' +\\\n                        str(word_weight*sent_weight) + ');font-size:16px;\">' +\\\n                        word.replace('$', '\\$').replace(\"'\", \"\\'\") + '</span>'\n    \n    def __scale_weight(self, orig_weight, max_weight, min_weight):\n        out = (orig_weight-min_weight)/(max_weight-min_weight)\n        if type(out) == torch.Tensor:\n            out = out.item()\n        return out\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:50:51.001046Z","iopub.execute_input":"2024-04-17T07:50:51.001524Z","iopub.status.idle":"2024-04-17T07:50:51.025667Z","shell.execute_reply.started":"2024-04-17T07:50:51.001492Z","shell.execute_reply":"2024-04-17T07:50:51.024222Z"},"trusted":true},"execution_count":214,"outputs":[]},{"cell_type":"code","source":"avhan =AttentionVisualizerHcl(modelhan, pp)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:51:10.065234Z","iopub.execute_input":"2024-04-17T07:51:10.066347Z","iopub.status.idle":"2024-04-17T07:51:10.071556Z","shell.execute_reply.started":"2024-04-17T07:51:10.066279Z","shell.execute_reply":"2024-04-17T07:51:10.070369Z"},"trusted":true},"execution_count":216,"outputs":[]},{"cell_type":"code","source":"a,b,c = av.visualize_attention(test_df_categorised.loc[925], MAX_SENT_LEN, MAX_NUM_SENT, preprocess_label=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T09:34:03.242141Z","iopub.execute_input":"2024-04-16T09:34:03.242860Z","iopub.status.idle":"2024-04-16T09:34:03.278040Z","shell.execute_reply.started":"2024-04-16T09:34:03.242815Z","shell.execute_reply":"2024-04-16T09:34:03.276665Z"},"trusted":true},"execution_count":287,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<p style=\"font-size:18px\"> Ground Truth: Hoax&emsp;&emsp;&emsp;Prediction: Hoax</p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.38874557614326477);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.016056856978135723);font-size:16px;\">5</span> <span style=\"background-color:rgba(0,0,255,0.020698486688090607);font-size:16px;\">fast</span> <span style=\"background-color:rgba(0,0,255,0.02129833752830908);font-size:16px;\">facts</span> <span style=\"background-color:rgba(0,0,255,0.011524553205517521);font-size:16px;\">you</span> <span style=\"background-color:rgba(0,0,255,0.016486570148576907);font-size:16px;\">probably</span> <span style=\"background-color:rgba(0,0,255,0.03097247692137667);font-size:16px;\">didnt</span> <span style=\"background-color:rgba(0,0,255,0.016011315827400934);font-size:16px;\">know</span> <span style=\"background-color:rgba(0,0,255,0.0171647435457063);font-size:16px;\">about</span> <span style=\"background-color:rgba(0,0,255,0.05146342352472175);font-size:16px;\">melania</span> <span style=\"background-color:rgba(0,0,255,0.041566688314819945);font-size:16px;\">trump</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.04591509591271989);font-size:16px;\">melania</span> <span style=\"background-color:rgba(0,0,255,0.028355713106230727);font-size:16px;\">trump</span> <span style=\"background-color:rgba(0,0,255,0.012247979738759828);font-size:16px;\">put</span> <span style=\"background-color:rgba(0,0,255,0.013013152133284144);font-size:16px;\">herself</span> <span style=\"background-color:rgba(0,0,255,0.009197132015150808);font-size:16px;\">in</span> <span style=\"background-color:rgba(0,0,255,0.010008817029084101);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.01834613074796995);font-size:16px;\">spotlight</span> <span style=\"background-color:rgba(0,0,255,0.00870751180335951);font-size:16px;\">for</span> <span style=\"background-color:rgba(0,0,255,0.008723928056131775);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.010647690366518863);font-size:16px;\">first</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.008847746471155497);font-size:16px;\">time</span> <span style=\"background-color:rgba(0,0,255,0.011365597006624983);font-size:16px;\">in</span> <span style=\"background-color:rgba(0,0,255,0.016603707321182683);font-size:16px;\">husband</span> <span style=\"background-color:rgba(0,0,255,0.03700650170729606);font-size:16px;\">donalds</span> <span style=\"background-color:rgba(0,0,255,0.01621257881927857);font-size:16px;\">campaign</span> <span style=\"background-color:rgba(0,0,255,0.014686968851251658);font-size:16px;\">for</span> <span style=\"background-color:rgba(0,0,255,0.016837381248815574);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.0252438916419563);font-size:16px;\">us</span> <span style=\"background-color:rgba(0,0,255,0.04378042908871803);font-size:16px;\">presidency</span> <span style=\"background-color:rgba(0,0,255,0.024503234169420577);font-size:16px;\">last</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.22007574141025543);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.02273649267632144);font-size:16px;\">no</span> <span style=\"background-color:rgba(0,0,255,0.03821373473479856);font-size:16px;\">sooner</span> <span style=\"background-color:rgba(0,0,255,0.018649093130474206);font-size:16px;\">than</span> <span style=\"background-color:rgba(0,0,255,0.014499200555871734);font-size:16px;\">she</span> <span style=\"background-color:rgba(0,0,255,0.018259406043645718);font-size:16px;\">left</span> <span style=\"background-color:rgba(0,0,255,0.018866790258637245);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.030778401239769125);font-size:16px;\">stage</span> <span style=\"background-color:rgba(0,0,255,0.020357442717770652);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.024849845463984527);font-size:16px;\">critics</span> <span style=\"background-color:rgba(0,0,255,0.015349968370589944);font-size:16px;\">were</span> <span style=\"background-color:rgba(0,0,255,0.019294035377876557);font-size:16px;\">looking</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.018778214049307275);font-size:16px;\">for</span> <span style=\"background-color:rgba(0,0,255,0.026431328558105618);font-size:16px;\">anything</span> <span style=\"background-color:rgba(0,0,255,0.023157477832222818);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.05776415248607784);font-size:16px;\">bash</span> <span style=\"background-color:rgba(0,0,255,0.02682186673431031);font-size:16px;\">her</span> <span style=\"background-color:rgba(0,0,255,0.030701174053866447);font-size:16px;\">one</span> <span style=\"background-color:rgba(0,0,255,0.04361369235567004);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.3911786675453186);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.031957847680044546);font-size:16px;\">but</span> <span style=\"background-color:rgba(0,0,255,0.03599790734979267);font-size:16px;\">here</span> <span style=\"background-color:rgba(0,0,255,0.0296223557946747);font-size:16px;\">are</span> <span style=\"background-color:rgba(0,0,255,0.023020838125524853);font-size:16px;\">some</span> <span style=\"background-color:rgba(0,0,255,0.03905215102418634);font-size:16px;\">facts</span> <span style=\"background-color:rgba(0,0,255,0.01846301448845027);font-size:16px;\">that</span> <span style=\"background-color:rgba(0,0,255,0.02310931820121194);font-size:16px;\">you</span> <span style=\"background-color:rgba(0,0,255,0.029764580963340698);font-size:16px;\">may</span> <span style=\"background-color:rgba(0,0,255,0.028613988156066132);font-size:16px;\">never</span> <span style=\"background-color:rgba(0,0,255,0.027366275796589727);font-size:16px;\">have</span> <span style=\"background-color:rgba(0,0,255,0.040575180293827035);font-size:16px;\">known</span> <span style=\"background-color:rgba(0,0,255,0.04628526382162988);font-size:16px;\">about</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.1690829805142743);font-size:16px;\">melania</span> <span style=\"background-color:rgba(0,0,255,0.082531055180701);font-size:16px;\">.</span>"},"metadata":{}}]},{"cell_type":"code","source":"a,b,c = av.visualize_attention(test_df_categorised.loc[1890], MAX_SENT_LEN, MAX_NUM_SENT, preprocess_label=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T10:05:05.388771Z","iopub.execute_input":"2024-04-16T10:05:05.389310Z","iopub.status.idle":"2024-04-16T10:05:05.455075Z","shell.execute_reply.started":"2024-04-16T10:05:05.389267Z","shell.execute_reply":"2024-04-16T10:05:05.453934Z"},"trusted":true},"execution_count":306,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<p style=\"font-size:18px\"> Ground Truth: Propaganda&emsp;&emsp;&emsp;Prediction: Propaganda</p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.09338170289993286);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.02092750562633254);font-size:16px;\">even</span> <span style=\"background-color:rgba(0,0,255,0.02368837651080304);font-size:16px;\">obama</span> <span style=\"background-color:rgba(0,0,255,0.04979552181771765);font-size:16px;\">doesnt</span> <span style=\"background-color:rgba(0,0,255,0.01527078041893253);font-size:16px;\">have</span> <span style=\"background-color:rgba(0,0,255,0.01447282377451875);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.025939287446273517);font-size:16px;\">buy</span> <span style=\"background-color:rgba(0,0,255,0.05893300377786621);font-size:16px;\">obamacare</span> <span style=\"background-color:rgba(0,0,255,0.010631760941267998);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.013529857892208407);font-size:16px;\">it</span> <span style=\"background-color:rgba(0,0,255,0.027426691691069198);font-size:16px;\">turns</span> <span style=\"background-color:rgba(0,0,255,0.020298586214447824);font-size:16px;\">out</span> <span style=\"background-color:rgba(0,0,255,0.02467000552769924);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.1411142796278);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.008329520109437348);font-size:16px;\">and</span> <span style=\"background-color:rgba(0,0,255,0.00803010261123373);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.008891861238929802);font-size:16px;\">very</span> <span style=\"background-color:rgba(0,0,255,0.013397972173326961);font-size:16px;\">fact</span> <span style=\"background-color:rgba(0,0,255,0.008930756496887834);font-size:16px;\">that</span> <span style=\"background-color:rgba(0,0,255,0.045641123647989196);font-size:16px;\">obamacare</span> <span style=\"background-color:rgba(0,0,255,0.015450093763923579);font-size:16px;\">forces</span> <span style=\"background-color:rgba(0,0,255,0.01288559984918485);font-size:16px;\">citizens</span> <span style=\"background-color:rgba(0,0,255,0.007020857850592278);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.01278941126331217);font-size:16px;\">purchase</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.007016186613236593);font-size:16px;\">a</span> <span style=\"background-color:rgba(0,0,255,0.012094125990982666);font-size:16px;\">private</span> <span style=\"background-color:rgba(0,0,255,0.011755189796761711);font-size:16px;\">insurance</span> <span style=\"background-color:rgba(0,0,255,0.012629792927773888);font-size:16px;\">product</span> <span style=\"background-color:rgba(0,0,255,0.00847571108654909);font-size:16px;\">or</span> <span style=\"background-color:rgba(0,0,255,0.008087956403666339);font-size:16px;\">be</span> <span style=\"background-color:rgba(0,0,255,0.016707451478635803);font-size:16px;\">fined</span> <span style=\"background-color:rgba(0,0,255,0.008619499972911568);font-size:16px;\">by</span> <span style=\"background-color:rgba(0,0,255,0.008260855159368027);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.023645554399136078);font-size:16px;\">irs</span> <span style=\"background-color:rgba(0,0,255,0.008413722031568233);font-size:16px;\">is</span> <span style=\"background-color:rgba(0,0,255,0.01737559795347016);font-size:16px;\">blatantly</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.012869389060230909);font-size:16px;\">unconstitutional</span> <span style=\"background-color:rgba(0,0,255,0.004814714523017811);font-size:16px;\">and</span> <span style=\"background-color:rgba(0,0,255,0.005071731585981598);font-size:16px;\">an</span> <span style=\"background-color:rgba(0,0,255,0.01329769450550302);font-size:16px;\">outlandish</span> <span style=\"background-color:rgba(0,0,255,0.01374621585695854);font-size:16px;\">interpretation</span> <span style=\"background-color:rgba(0,0,255,0.008014191996160195);font-size:16px;\">of</span> <span style=\"background-color:rgba(0,0,255,0.009145837029699688);font-size:16px;\">the</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.02424311453118411);font-size:16px;\">commerce</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.11197298020124435);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.086220334175198);font-size:16px;\">obamacare</span> <span style=\"background-color:rgba(0,0,255,0.019757235127196304);font-size:16px;\">is</span> <span style=\"background-color:rgba(0,0,255,0.016195168264801284);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.022681242540419908);font-size:16px;\">biggest</span> <span style=\"background-color:rgba(0,0,255,0.020808622350178628);font-size:16px;\">government</span> <span style=\"background-color:rgba(0,0,255,0.027173111154929926);font-size:16px;\">boondoggle</span> <span style=\"background-color:rgba(0,0,255,0.013781338403809842);font-size:16px;\">our</span> <span style=\"background-color:rgba(0,0,255,0.012855061952215807);font-size:16px;\">nation</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.006376685247572061);font-size:16px;\">has</span> <span style=\"background-color:rgba(0,0,255,0.006612188536016596);font-size:16px;\">ever</span> <span style=\"background-color:rgba(0,0,255,0.005607169361417602);font-size:16px;\">seen</span> <span style=\"background-color:rgba(0,0,255,0.003732506977548856);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.004618592759377537);font-size:16px;\">and</span> <span style=\"background-color:rgba(0,0,255,0.004657084665605073);font-size:16px;\">it</span> <span style=\"background-color:rgba(0,0,255,0.006399652680191761);font-size:16px;\">is</span> <span style=\"background-color:rgba(0,0,255,0.013107637019526896);font-size:16px;\">doomed</span> <span style=\"background-color:rgba(0,0,255,0.006729884707865038);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.011967809380681461);font-size:16px;\">crash</span> <span style=\"background-color:rgba(0,0,255,0.008513768421821099);font-size:16px;\">and</span> <span style=\"background-color:rgba(0,0,255,0.02102474271860885);font-size:16px;\">burn</span> <span style=\"background-color:rgba(0,0,255,0.015803798825034496);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.10022211819887161);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.015915433330761394);font-size:16px;\">nobody</span> <span style=\"background-color:rgba(0,0,255,0.008048285271199994);font-size:16px;\">who</span> <span style=\"background-color:rgba(0,0,255,0.015511796820600278);font-size:16px;\">understands</span> <span style=\"background-color:rgba(0,0,255,0.007280429003525972);font-size:16px;\">it</span> <span style=\"background-color:rgba(0,0,255,0.009542483583794817);font-size:16px;\">wants</span> <span style=\"background-color:rgba(0,0,255,0.006004604041091346);font-size:16px;\">it</span> <span style=\"background-color:rgba(0,0,255,0.005313362335782852);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.007124336422278201);font-size:16px;\">and</span> <span style=\"background-color:rgba(0,0,255,0.008431416460744925);font-size:16px;\">even</span> <span style=\"background-color:rgba(0,0,255,0.011003799910034308);font-size:16px;\">those</span> <span style=\"background-color:rgba(0,0,255,0.01061402545419669);font-size:16px;\">who</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.03237498000839386);font-size:16px;\">foolishly</span> <span style=\"background-color:rgba(0,0,255,0.012226791858974708);font-size:16px;\">were</span> <span style=\"background-color:rgba(0,0,255,0.03336381362622351);font-size:16px;\">mind-tricked</span> <span style=\"background-color:rgba(0,0,255,0.013896092660392632);font-size:16px;\">into</span> <span style=\"background-color:rgba(0,0,255,0.017509849083397706);font-size:16px;\">supporting</span> <span style=\"background-color:rgba(0,0,255,0.006759423797918685);font-size:16px;\">it</span> <span style=\"background-color:rgba(0,0,255,0.006032398910607779);font-size:16px;\">have</span> <span style=\"background-color:rgba(0,0,255,0.005710984761715393);font-size:16px;\">no</span> <span style=\"background-color:rgba(0,0,255,0.013186921330115607);font-size:16px;\">clue</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.005587469895084356);font-size:16px;\">just</span> <span style=\"background-color:rgba(0,0,255,0.006932721884571039);font-size:16px;\">how</span> <span style=\"background-color:rgba(0,0,255,0.008559021305629654);font-size:16px;\">badly</span> <span style=\"background-color:rgba(0,0,255,0.006484713002205196);font-size:16px;\">its</span> <span style=\"background-color:rgba(0,0,255,0.006661195327982396);font-size:16px;\">going</span> <span style=\"background-color:rgba(0,0,255,0.006297318760686278);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.011073751746868053);font-size:16px;\">hurt</span> <span style=\"background-color:rgba(0,0,255,0.008929161978893038);font-size:16px;\">them</span> <span style=\"background-color:rgba(0,0,255,0.010202124074484863);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.10944917798042297);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.021775225553672284);font-size:16px;\">every</span> <span style=\"background-color:rgba(0,0,255,0.045344738284564534);font-size:16px;\">rational</span> <span style=\"background-color:rgba(0,0,255,0.019074477528823894);font-size:16px;\">person</span> <span style=\"background-color:rgba(0,0,255,0.01908953057137037);font-size:16px;\">wants</span> <span style=\"background-color:rgba(0,0,255,0.013248761499762013);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.01569730882365263);font-size:16px;\">be</span> <span style=\"background-color:rgba(0,0,255,0.04961821005312744);font-size:16px;\">exempted</span> <span style=\"background-color:rgba(0,0,255,0.02456105642158917);font-size:16px;\">from</span> <span style=\"background-color:rgba(0,0,255,0.09696883588996431);font-size:16px;\">obamacare</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.025452915300322017);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.09913370013237);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.014735476153195768);font-size:16px;\">any</span> <span style=\"background-color:rgba(0,0,255,0.020452794701408747);font-size:16px;\">lawmakers</span> <span style=\"background-color:rgba(0,0,255,0.010194783464121298);font-size:16px;\">who</span> <span style=\"background-color:rgba(0,0,255,0.021042886960401314);font-size:16px;\">continue</span> <span style=\"background-color:rgba(0,0,255,0.013112348863892167);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.03231812335239214);font-size:16px;\">defend</span> <span style=\"background-color:rgba(0,0,255,0.04572311267363345);font-size:16px;\">obamacare</span> <span style=\"background-color:rgba(0,0,255,0.009534331452688715);font-size:16px;\">will</span> <span style=\"background-color:rgba(0,0,255,0.009883563851818126);font-size:16px;\">likely</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.007562506032253274);font-size:16px;\">find</span> <span style=\"background-color:rgba(0,0,255,0.008336097356041329);font-size:16px;\">themselves</span> <span style=\"background-color:rgba(0,0,255,0.004892056882025155);font-size:16px;\">out</span> <span style=\"background-color:rgba(0,0,255,0.005098033909291541);font-size:16px;\">of</span> <span style=\"background-color:rgba(0,0,255,0.005233893393429653);font-size:16px;\">a</span> <span style=\"background-color:rgba(0,0,255,0.0074683581584986955);font-size:16px;\">job</span> <span style=\"background-color:rgba(0,0,255,0.006497470636094177);font-size:16px;\">when</span> <span style=\"background-color:rgba(0,0,255,0.01097637590568201);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.03423641171798404);font-size:16px;\">2014</span> <span style=\"background-color:rgba(0,0,255,0.014720929519373807);font-size:16px;\">elections</span> <span style=\"background-color:rgba(0,0,255,0.00972228235982183);font-size:16px;\">come</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.011211980468589892);font-size:16px;\">around</span> <span style=\"background-color:rgba(0,0,255,0.011901230756664445);font-size:16px;\">.</span>"},"metadata":{}}]},{"cell_type":"code","source":"short_trusted = (test_df_categorised['Label'] == 3) & (test_df_categorised['Text'].apply(lambda t: re.search(r'obama|trump|melania|biden', t.lower())))\ntest_df_categorised[short_trusted].sort_values('lengths').head(20)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T10:01:48.534432Z","iopub.execute_input":"2024-04-16T10:01:48.534944Z","iopub.status.idle":"2024-04-16T10:01:48.775723Z","shell.execute_reply.started":"2024-04-16T10:01:48.534886Z","shell.execute_reply":"2024-04-16T10:01:48.774533Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":299,"outputs":[{"execution_count":299,"output_type":"execute_result","data":{"text/plain":"                                                   Text  Label  Category  \\\n1890   Top lawmakers on Capitol Hill are negotiating...      3         4   \n2191   After months of collecting signatures to get ...      3         4   \n2143   The battle continues to rage between the indi...      3         4   \n1727   With preparations being made for the massive ...      3         4   \n1896   Thank you to all those who voted in our selfn...      3         4   \n2007   In what is quickly shaping up to be the bigge...      3         4   \n1587   The Law of Attraction, made popular by 'The S...      3         2   \n1775   Tweet (NewsTarget) California governor Arnold...      3         4   \n1756   If you're 'Ready for Hillary' in 2016, you mi...      3         4   \n1644   With a sad twist of irony, corporate and gove...      3         3   \n1863   It recently went public that the Obama admini...      3         2   \n1987   He was widely panned for it, but former Texas...      3         4   \n2156   Army Veteran Donald Siefkin wasn't asking for...      3         2   \n2104   The number of illegal immigrants arriving via...      3         4   \n1754   In Brave New America, simply acknowledging th...      3         2   \n2051   In approximately 25 years, fresh water may be...      3         3   \n1683   During his first campaign for president, then...      3         4   \n1786   In the wake of revelations - thanks in every ...      3         4   \n1814   The White House has been caught in yet anothe...      3         4   \n1641   The president of the United States has his pr...      3         4   \n\n      lengths  has_hedge  has_2p  has_1ps  has_nums  has_bri_ire_afh_am_hondu  \\\n1890      321          1       0        1         4                         2   \n2191      322          0       0        0        30                         2   \n2143      380          0       0        1        10                         4   \n1727      423          0       0        0         8                         1   \n1896      510          5       4        2        57                         5   \n2007      531          3       0        0        11                         5   \n1587      534          0       7        7        20                         7   \n1775      565          0       0        2        20                         3   \n1756      574          4       6        0        18                         4   \n1644      576          0       1        0         8                         3   \n1863      583          1       2        0        20                         6   \n1987      596          4       3        4        14                        13   \n2156      597          0       2        2        21                        10   \n2104      604          2       1        0        30                         3   \n1754      606          4      10        0         3                         8   \n2051      615          5       0        0        49                         8   \n1683      618          0       0        1        32                         6   \n1786      621          0       3        3        29                         4   \n1814      624          1       4        1         9                         9   \n1641      625          1       1        0         0                         2   \n\n      has_days  \n1890         0  \n2191         0  \n2143         0  \n1727         0  \n1896         0  \n2007         0  \n1587        12  \n1775         0  \n1756         0  \n1644         0  \n1863         0  \n1987         0  \n2156         0  \n2104         0  \n1754         0  \n2051         3  \n1683         0  \n1786         0  \n1814         0  \n1641         3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Category</th>\n      <th>lengths</th>\n      <th>has_hedge</th>\n      <th>has_2p</th>\n      <th>has_1ps</th>\n      <th>has_nums</th>\n      <th>has_bri_ire_afh_am_hondu</th>\n      <th>has_days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1890</th>\n      <td>Top lawmakers on Capitol Hill are negotiating...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>321</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2191</th>\n      <td>After months of collecting signatures to get ...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>322</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2143</th>\n      <td>The battle continues to rage between the indi...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>380</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>10</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1727</th>\n      <td>With preparations being made for the massive ...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>423</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1896</th>\n      <td>Thank you to all those who voted in our selfn...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>510</td>\n      <td>5</td>\n      <td>4</td>\n      <td>2</td>\n      <td>57</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2007</th>\n      <td>In what is quickly shaping up to be the bigge...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>531</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1587</th>\n      <td>The Law of Attraction, made popular by 'The S...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>534</td>\n      <td>0</td>\n      <td>7</td>\n      <td>7</td>\n      <td>20</td>\n      <td>7</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>1775</th>\n      <td>Tweet (NewsTarget) California governor Arnold...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>565</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>20</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1756</th>\n      <td>If you're 'Ready for Hillary' in 2016, you mi...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>574</td>\n      <td>4</td>\n      <td>6</td>\n      <td>0</td>\n      <td>18</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1644</th>\n      <td>With a sad twist of irony, corporate and gove...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>576</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1863</th>\n      <td>It recently went public that the Obama admini...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>583</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>20</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1987</th>\n      <td>He was widely panned for it, but former Texas...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>596</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>14</td>\n      <td>13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2156</th>\n      <td>Army Veteran Donald Siefkin wasn't asking for...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>597</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>21</td>\n      <td>10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2104</th>\n      <td>The number of illegal immigrants arriving via...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>604</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>30</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1754</th>\n      <td>In Brave New America, simply acknowledging th...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>606</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0</td>\n      <td>3</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2051</th>\n      <td>In approximately 25 years, fresh water may be...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>615</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>49</td>\n      <td>8</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1683</th>\n      <td>During his first campaign for president, then...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>618</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>32</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1786</th>\n      <td>In the wake of revelations - thanks in every ...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>621</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>29</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1814</th>\n      <td>The White House has been caught in yet anothe...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>624</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>9</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1641</th>\n      <td>The president of the United States has his pr...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>625</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"a,b,c = avhan.visualize_attention(test_df.loc[561], MAX_SENT_LEN, MAX_NUM_SENT, preprocess_label=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:53:19.884434Z","iopub.execute_input":"2024-04-17T07:53:19.884917Z","iopub.status.idle":"2024-04-17T07:53:19.927009Z","shell.execute_reply.started":"2024-04-17T07:53:19.884883Z","shell.execute_reply":"2024-04-17T07:53:19.926178Z"},"trusted":true},"execution_count":222,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<p style=\"font-size:18px\"> Ground Truth: Satire&emsp;&emsp;&emsp;Prediction: Satire</p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.24200034141540527);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.12800093275906924);font-size:16px;\">cnn</span> <span style=\"background-color:rgba(0,0,255,0.0686656732192339);font-size:16px;\">apologized</span> <span style=\"background-color:rgba(0,0,255,0.023735232263345278);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.03139357901777049);font-size:16px;\">its</span> <span style=\"background-color:rgba(0,0,255,0.04592112639376344);font-size:16px;\">viewers</span> <span style=\"background-color:rgba(0,0,255,0.03297088506997794);font-size:16px;\">today</span> <span style=\"background-color:rgba(0,0,255,0.02809632537479983);font-size:16px;\">for</span> <span style=\"background-color:rgba(0,0,255,0.04498048909980942);font-size:16px;\">briefly</span> <span style=\"background-color:rgba(0,0,255,0.05424646468441979);font-size:16px;\">airing</span> <span style=\"background-color:rgba(0,0,255,0.011694496760459914);font-size:16px;\">a</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.013522807299843266);font-size:16px;\">story</span> <span style=\"background-color:rgba(0,0,255,0.006186737586989254);font-size:16px;\">on</span> <span style=\"background-color:rgba(0,0,255,0.006035391070540488);font-size:16px;\">sunday</span> <span style=\"background-color:rgba(0,0,255,0.000594714139850972);font-size:16px;\">that</span> <span style=\"background-color:rgba(0,0,255,0.0);font-size:16px;\">had</span> <span style=\"background-color:rgba(0,0,255,0.006083250916267387);font-size:16px;\">nothing</span> <span style=\"background-color:rgba(0,0,255,0.0011575253685266321);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.004128781753417192);font-size:16px;\">do</span> <span style=\"background-color:rgba(0,0,255,0.007408141100190395);font-size:16px;\">with</span> <span style=\"background-color:rgba(0,0,255,0.011685815890008213);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.023447332433060464);font-size:16px;\">missing</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.05884020775388262);font-size:16px;\">malaysia</span> <span style=\"background-color:rgba(0,0,255,0.053390606686742885);font-size:16px;\">airlines</span> <span style=\"background-color:rgba(0,0,255,0.0688980601869735);font-size:16px;\">flight</span> <span style=\"background-color:rgba(0,0,255,0.04763412665826261);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.1594906896352768);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.020649687691945987);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.01806528332357854);font-size:16px;\">story</span> <span style=\"background-color:rgba(0,0,255,0.008646701176333989);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.01616890932158344);font-size:16px;\">which</span> <span style=\"background-color:rgba(0,0,255,0.029477051111571808);font-size:16px;\">caused</span> <span style=\"background-color:rgba(0,0,255,0.019445070525178833);font-size:16px;\">thousands</span> <span style=\"background-color:rgba(0,0,255,0.013894376726604674);font-size:16px;\">of</span> <span style=\"background-color:rgba(0,0,255,0.022729155530379585);font-size:16px;\">viewers</span> <span style=\"background-color:rgba(0,0,255,0.011627106412791006);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.027408742458556182);font-size:16px;\">contact</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.012749780262664837);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.024212070591006957);font-size:16px;\">network</span> <span style=\"background-color:rgba(0,0,255,0.011138855219376497);font-size:16px;\">in</span> <span style=\"background-color:rgba(0,0,255,0.019359907712518405);font-size:16px;\">anger</span> <span style=\"background-color:rgba(0,0,255,0.003234946891362784);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.0027125262895308574);font-size:16px;\">had</span> <span style=\"background-color:rgba(0,0,255,0.004640105857272176);font-size:16px;\">something</span> <span style=\"background-color:rgba(0,0,255,0.005116338466443487);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.007460621025571788);font-size:16px;\">do</span> <span style=\"background-color:rgba(0,0,255,0.011782907475781665);font-size:16px;\">with</span> <span style=\"background-color:rgba(0,0,255,0.03097433474280984);font-size:16px;\">crimea</span> <span style=\"background-color:rgba(0,0,255,0.011159797107724308);font-size:16px;\">,</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.03868795194976976);font-size:16px;\">ukraine</span> <span style=\"background-color:rgba(0,0,255,0.012694811958309184);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.023550440378798432);font-size:16px;\">and</span> <span style=\"background-color:rgba(0,0,255,0.04992943166600428);font-size:16px;\">russia</span> <span style=\"background-color:rgba(0,0,255,0.03472092075275935);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.12299803644418716);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.010093119473519926);font-size:16px;\">in</span> <span style=\"background-color:rgba(0,0,255,0.009448084967218757);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.012868296658751758);font-size:16px;\">official</span> <span style=\"background-color:rgba(0,0,255,0.014594173455341478);font-size:16px;\">apology</span> <span style=\"background-color:rgba(0,0,255,0.00643498179435829);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.02652403866875466);font-size:16px;\">cnn</span> <span style=\"background-color:rgba(0,0,255,0.02058838454793205);font-size:16px;\">chief</span> <span style=\"background-color:rgba(0,0,255,0.023513236783770788);font-size:16px;\">jeff</span> <span style=\"background-color:rgba(0,0,255,0.02006761178976706);font-size:16px;\">zucker</span> <span style=\"background-color:rgba(0,0,255,0.004801311342946055);font-size:16px;\">wrote</span> <span style=\"background-color:rgba(0,0,255,9.357809542919335e-05);font-size:16px;\">,</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.0006071479116512968);font-size:16px;\">on</span> <span style=\"background-color:rgba(0,0,255,0.0014025631151565775);font-size:16px;\">sunday</span> <span style=\"background-color:rgba(0,0,255,0.0006888246952133639);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.002859542331954672);font-size:16px;\">we</span> <span style=\"background-color:rgba(0,0,255,0.007937976743716902);font-size:16px;\">briefly</span> <span style=\"background-color:rgba(0,0,255,0.004674681473790687);font-size:16px;\">cut</span> <span style=\"background-color:rgba(0,0,255,0.007356644247277597);font-size:16px;\">away</span> <span style=\"background-color:rgba(0,0,255,0.00613151254378937);font-size:16px;\">from</span> <span style=\"background-color:rgba(0,0,255,0.011810869359970423);font-size:16px;\">our</span> <span style=\"background-color:rgba(0,0,255,0.02522546625264316);font-size:16px;\">nonstop</span> <span style=\"background-color:rgba(0,0,255,0.015550009921839653);font-size:16px;\">coverage</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.008925258203804763);font-size:16px;\">of</span> <span style=\"background-color:rgba(0,0,255,0.016238086085855984);font-size:16px;\">flight</span> <span style=\"background-color:rgba(0,0,255,0.022970723204320517);font-size:16px;\">370</span> <span style=\"background-color:rgba(0,0,255,0.006366211604516508);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.010686967589795354);font-size:16px;\">talk</span> <span style=\"background-color:rgba(0,0,255,0.007798670855183193);font-size:16px;\">about</span> <span style=\"background-color:rgba(0,0,255,0.014694351880544517);font-size:16px;\">something</span> <span style=\"background-color:rgba(0,0,255,0.03439082976146793);font-size:16px;\">else</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.20533621311187744);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.046498688702378346);font-size:16px;\">were</span> <span style=\"background-color:rgba(0,0,255,0.03024411137347906);font-size:16px;\">not</span> <span style=\"background-color:rgba(0,0,255,0.03886646819640896);font-size:16px;\">going</span> <span style=\"background-color:rgba(0,0,255,0.036200423050911534);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.1218194811302222);font-size:16px;\">sugarcoat</span> <span style=\"background-color:rgba(0,0,255,0.03433919140873926);font-size:16px;\">it</span> <span style=\"background-color:rgba(0,0,255,0.05036888212525839);font-size:16px;\">:</span> <span style=\"background-color:rgba(0,0,255,0.0552907778666426);font-size:16px;\">we</span> <span style=\"background-color:rgba(0,0,255,0.20533621311187744);font-size:16px;\">messed</span> <span style=\"background-color:rgba(0,0,255,0.11446427415928825);font-size:16px;\">up</span> <span style=\"background-color:rgba(0,0,255,0.11636646054406043);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.2701747417449951);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.18462358252074268);font-size:16px;\">cnn</span> <span style=\"background-color:rgba(0,0,255,0.12192390469922851);font-size:16px;\">regrets</span> <span style=\"background-color:rgba(0,0,255,0.04734815943184023);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.06829797851267416);font-size:16px;\">error</span> <span style=\"background-color:rgba(0,0,255,0.032604771279978684);font-size:16px;\">and</span> <span style=\"background-color:rgba(0,0,255,0.08450575802784707);font-size:16px;\">promises</span> <span style=\"background-color:rgba(0,0,255,0.052300251325189916);font-size:16px;\">our</span> <span style=\"background-color:rgba(0,0,255,0.050560102972480515);font-size:16px;\">viewers</span> <span style=\"background-color:rgba(0,0,255,0.020283860226074278);font-size:16px;\">that</span> <span style=\"background-color:rgba(0,0,255,0.03089278975774513);font-size:16px;\">it</span> <span style=\"background-color:rgba(0,0,255,0.11843866558609938);font-size:16px;\">wont</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.09777943071779445);font-size:16px;\">happen</span> <span style=\"background-color:rgba(0,0,255,0.07655611543207946);font-size:16px;\">again</span> <span style=\"background-color:rgba(0,0,255,0.07871297236991769);font-size:16px;\">.</span>"},"metadata":{}}]},{"cell_type":"code","source":"short_trusted = (test_df_categorised['lengths'] < 100) & (test_df_categorised['Label'] == 4)\ntest_df_categorised[(test_df_categorised['has_nums'] > 0) & short_trusted].head(20)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T08:20:45.389472Z","iopub.execute_input":"2024-04-16T08:20:45.389876Z","iopub.status.idle":"2024-04-16T08:20:45.411233Z","shell.execute_reply.started":"2024-04-16T08:20:45.389847Z","shell.execute_reply":"2024-04-16T08:20:45.410041Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":190,"outputs":[{"execution_count":190,"output_type":"execute_result","data":{"text/plain":"                                                   Text  Label  Category  \\\n2268  British American Tobacco announced Tuesday tha...      4         3   \n2318  The plaintiff in the lawsuit that legalized ab...      4         4   \n2334  Gold for current delivery closed at $1,107.80 ...      4         0   \n2399  Triple Olympic gold medalist Stephanie Rice sa...      4         5   \n2401  Singapore exchange to buy Australian bourse fo...      4         3   \n2407  West Indies beat England by five wickets under...      4         5   \n2413  Eurozone recovery falters in Q4 as economy gro...      4         0   \n2467  Coast Guard Adm. Thad Allen: cap now funneling...      4         3   \n2487  Spanish bank BBVA reported Wednesday its fourt...      4         3   \n2526  Results Thursday from the St. Petersburg Open ...      4         5   \n2542  Brome Howard Inn 18281 Rosecroft Rd., St. Mary...      4         3   \n2544  Results Sunday from the Japan Open, a $1.2 mil...      4         5   \n2556  Simone Hauswald of Germany mastered windy and ...      4         5   \n2563  Consumers increased their spending in June for...      4         0   \n2566  The United Network for Organ Sharing (UNOS) co...      4         2   \n2609  America picked up its first victory of the Mex...      4         5   \n2612  Norway's Marit Bjoergen has won the women's 10...      4         5   \n2629  A federal judge has sentenced former Democrati...      4         4   \n2666  Gold for current delivery closed at $1,159.70 ...      4         0   \n2686  Serbia coach Radomir Antic has reduced his squ...      4         5   \n\n      lengths  has_hedge  has_2p  has_1ps  has_nums  has_bri_ire_afh_am_hondu  \\\n2268       55          0       0        0         9                         3   \n2318       98          2       0        0         6                         2   \n2334       22          0       0        0        14                         1   \n2399       91          0       1        0         4                         0   \n2401       13          0       0        0         4                         1   \n2407       74          0       0        0        25                         0   \n2413       15          0       0        0         4                         0   \n2467       20          0       0        0         9                         0   \n2487       99          0       0        0        45                         0   \n2526       53          0       0        0        18                         7   \n2542       35          0       0        0        31                         1   \n2544       51          0       0        0        16                         1   \n2556       84          0       0        0        12                         0   \n2563       99          0       0        0         9                         0   \n2566       55          0       0        0        37                         0   \n2609       89          0       0        0        12                         2   \n2612       73          0       0        0        14                         2   \n2629       95          0       0        0        19                         2   \n2666       22          0       0        0        14                         1   \n2686       88          0       0        0         7                         0   \n\n      has_days  \n2268         1  \n2318         0  \n2334         2  \n2399         1  \n2401         0  \n2407         1  \n2413         0  \n2467         0  \n2487         1  \n2526         1  \n2542         3  \n2544         1  \n2556         1  \n2563         0  \n2566         0  \n2609         2  \n2612         2  \n2629         1  \n2666         2  \n2686         1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Category</th>\n      <th>lengths</th>\n      <th>has_hedge</th>\n      <th>has_2p</th>\n      <th>has_1ps</th>\n      <th>has_nums</th>\n      <th>has_bri_ire_afh_am_hondu</th>\n      <th>has_days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2268</th>\n      <td>British American Tobacco announced Tuesday tha...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>55</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2318</th>\n      <td>The plaintiff in the lawsuit that legalized ab...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>98</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2334</th>\n      <td>Gold for current delivery closed at $1,107.80 ...</td>\n      <td>4</td>\n      <td>0</td>\n      <td>22</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2399</th>\n      <td>Triple Olympic gold medalist Stephanie Rice sa...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>91</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2401</th>\n      <td>Singapore exchange to buy Australian bourse fo...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2407</th>\n      <td>West Indies beat England by five wickets under...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>74</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>25</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2413</th>\n      <td>Eurozone recovery falters in Q4 as economy gro...</td>\n      <td>4</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2467</th>\n      <td>Coast Guard Adm. Thad Allen: cap now funneling...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2487</th>\n      <td>Spanish bank BBVA reported Wednesday its fourt...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>99</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>45</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2526</th>\n      <td>Results Thursday from the St. Petersburg Open ...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>53</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2542</th>\n      <td>Brome Howard Inn 18281 Rosecroft Rd., St. Mary...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>35</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>31</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2544</th>\n      <td>Results Sunday from the Japan Open, a $1.2 mil...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>51</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2556</th>\n      <td>Simone Hauswald of Germany mastered windy and ...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2563</th>\n      <td>Consumers increased their spending in June for...</td>\n      <td>4</td>\n      <td>0</td>\n      <td>99</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2566</th>\n      <td>The United Network for Organ Sharing (UNOS) co...</td>\n      <td>4</td>\n      <td>2</td>\n      <td>55</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2609</th>\n      <td>America picked up its first victory of the Mex...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>89</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2612</th>\n      <td>Norway's Marit Bjoergen has won the women's 10...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>73</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2629</th>\n      <td>A federal judge has sentenced former Democrati...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>95</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>19</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2666</th>\n      <td>Gold for current delivery closed at $1,159.70 ...</td>\n      <td>4</td>\n      <td>0</td>\n      <td>22</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2686</th>\n      <td>Serbia coach Radomir Antic has reduced his squ...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>88</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"a,b,c = av.visualize_attention(test_df_categorised.loc[2467], MAX_SENT_LEN, MAX_NUM_SENT, preprocess_label=True)\na,b,c = av.visualize_attention(test_df_categorised.loc[2334], MAX_SENT_LEN, MAX_NUM_SENT, preprocess_label=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T09:34:37.166425Z","iopub.execute_input":"2024-04-16T09:34:37.166836Z","iopub.status.idle":"2024-04-16T09:34:37.204477Z","shell.execute_reply.started":"2024-04-16T09:34:37.166806Z","shell.execute_reply":"2024-04-16T09:34:37.203358Z"},"trusted":true},"execution_count":290,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<p style=\"font-size:18px\"> Ground Truth: Trusted&emsp;&emsp;&emsp;Prediction: Trusted</p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,1.0);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.04612308740615845);font-size:16px;\">coast</span> <span style=\"background-color:rgba(0,0,255,0.04704555124044418);font-size:16px;\">guard</span> <span style=\"background-color:rgba(0,0,255,0.0670442059636116);font-size:16px;\">adm.</span> <span style=\"background-color:rgba(0,0,255,0.07110335677862167);font-size:16px;\">thad</span> <span style=\"background-color:rgba(0,0,255,0.04284561425447464);font-size:16px;\">allen</span> <span style=\"background-color:rgba(0,0,255,0.02684144489467144);font-size:16px;\">:</span> <span style=\"background-color:rgba(0,0,255,0.04974472522735596);font-size:16px;\">cap</span> <span style=\"background-color:rgba(0,0,255,0.03876177594065666);font-size:16px;\">now</span> <span style=\"background-color:rgba(0,0,255,0.1004386618733406);font-size:16px;\">funneling</span> <span style=\"background-color:rgba(0,0,255,0.07699908316135406);font-size:16px;\">462,000</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.04530829191207886);font-size:16px;\">gallons</span> <span style=\"background-color:rgba(0,0,255,0.034812189638614655);font-size:16px;\">(</span> <span style=\"background-color:rgba(0,0,255,0.045579664409160614);font-size:16px;\">1.7</span> <span style=\"background-color:rgba(0,0,255,0.026468364521861076);font-size:16px;\">million</span> <span style=\"background-color:rgba(0,0,255,0.0351150780916214);font-size:16px;\">liters</span> <span style=\"background-color:rgba(0,0,255,0.019862961024045944);font-size:16px;\">)</span> <span style=\"background-color:rgba(0,0,255,0.01809554174542427);font-size:16px;\">of</span> <span style=\"background-color:rgba(0,0,255,0.023657288402318954);font-size:16px;\">oil</span> <span style=\"background-color:rgba(0,0,255,0.01755109801888466);font-size:16px;\">a</span> <span style=\"background-color:rgba(0,0,255,0.01983649656176567);font-size:16px;\">day</span> <span style=\"background-color:rgba(0,0,255,0.023630375042557716);font-size:16px;\">from</span> <span style=\"background-color:rgba(0,0,255,0.04681131988763809);font-size:16px;\">gulf</span> <span style=\"background-color:rgba(0,0,255,0.043448325246572495);font-size:16px;\">spill</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.03287554532289505);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<p style=\"font-size:18px\"> Ground Truth: Trusted&emsp;&emsp;&emsp;Prediction: Trusted</p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,1.0);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.035253413021564484);font-size:16px;\">gold</span> <span style=\"background-color:rgba(0,0,255,0.021404463797807693);font-size:16px;\">for</span> <span style=\"background-color:rgba(0,0,255,0.028654640540480614);font-size:16px;\">current</span> <span style=\"background-color:rgba(0,0,255,0.02937629260122776);font-size:16px;\">delivery</span> <span style=\"background-color:rgba(0,0,255,0.03306358680129051);font-size:16px;\">closed</span> <span style=\"background-color:rgba(0,0,255,0.0252033993601799);font-size:16px;\">at</span> <span style=\"background-color:rgba(0,0,255,0.03220895305275917);font-size:16px;\">\\$</span> <span style=\"background-color:rgba(0,0,255,0.07705462723970413);font-size:16px;\">1,107.80</span> <span style=\"background-color:rgba(0,0,255,0.04180104285478592);font-size:16px;\">per</span> <span style=\"background-color:rgba(0,0,255,0.03937329351902008);font-size:16px;\">troy</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.032713644206523895);font-size:16px;\">ounce</span> <span style=\"background-color:rgba(0,0,255,0.02076738514006138);font-size:16px;\">thursday</span> <span style=\"background-color:rgba(0,0,255,0.020397823303937912);font-size:16px;\">on</span> <span style=\"background-color:rgba(0,0,255,0.021511899307370186);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.02474067360162735);font-size:16px;\">new</span> <span style=\"background-color:rgba(0,0,255,0.030498450621962547);font-size:16px;\">york</span> <span style=\"background-color:rgba(0,0,255,0.04653860628604889);font-size:16px;\">mercantile</span> <span style=\"background-color:rgba(0,0,255,0.03625035658478737);font-size:16px;\">exchange</span> <span style=\"background-color:rgba(0,0,255,0.019604403525590897);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.030437614768743515);font-size:16px;\">up</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.031183507293462753);font-size:16px;\">from</span> <span style=\"background-color:rgba(0,0,255,0.04347136616706848);font-size:16px;\">\\$</span> <span style=\"background-color:rgba(0,0,255,0.09160143882036209);font-size:16px;\">1,096.50</span> <span style=\"background-color:rgba(0,0,255,0.04823124781250954);font-size:16px;\">late</span> <span style=\"background-color:rgba(0,0,255,0.092160165309906);font-size:16px;\">wedensday</span> <span style=\"background-color:rgba(0,0,255,0.04649776220321655);font-size:16px;\">.</span>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 2. FAN Analysis","metadata":{}},{"cell_type":"markdown","source":"First, define the model:","metadata":{}},{"cell_type":"code","source":"class AttentionUnit(nn.Module):\n    def __init__(self, input_dim, hidden_dim=None, num_outputs=1, attn_dropout=0.0):\n        super(AttentionUnit, self).__init__()\n        if hidden_dim is None:\n            hidden_dim = input_dim\n        self.hidden = nn.Linear(input_dim, hidden_dim)\n        self.query = nn.Linear(hidden_dim, num_outputs, bias=False)\n    def forward(self, encoder_output, padding_positions=None, return_weights=False):\n        #Calculate u_{i} = tanh(Wh_{i}+b) [B,L,H]-->[B,L,H]\n        hidden_rep = F.tanh(self.hidden(encoder_output))\n        #Calculate a_{i} = softmax(u_{i}^Tc) with masking [B,L,H]-->[B,L,1]\n        similarity = self.query(hidden_rep)\n        if padding_positions is not None:\n            similarity = similarity.masked_fill(padding_positions, -float('inf'))\n        attention_weights = F.softmax(similarity, dim=1)\n        #Return weighted sum [B,L,1], [B,L,H]-->[B,H]\n        if return_weights:\n            return torch.bmm(attention_weights.transpose(1,2), hidden_rep).squeeze(1), attention_weights\n        return torch.bmm(attention_weights.transpose(1,2), hidden_rep).squeeze(1)\n\nclass LSTMFlatAttentionFCNNClassifier(torch.nn.Module):\n    '''\n    Classifier that uses an LSTM as an encoder followed by an attention block\n    and a Fully-Connected Neural Network(FCNN) as a decoder.\n    '''\n    def __init__(self, vocab_len, embed_dim, hidden_dim, num_lstm_layers, num_classes, attn_dropout=0.0, pretrained_embeddings=None, freeze_embeds=False):\n        super(LSTMFlatAttentionFCNNClassifier, self).__init__()\n        if pretrained_embeddings is not None:\n            self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=freeze_embeds)\n        else:\n            self.embedding = nn.Embedding(num_embeddings=vocab_len, embedding_dim=embed_dim)\n\n        self.encoder = nn.LSTM(input_size=embed_dim, hidden_size=hidden_dim, num_layers=num_lstm_layers, batch_first=True, bidirectional=True)\n        self.attn = AttentionUnit(2*hidden_dim)\n        self.decoder = nn.Linear(2*hidden_dim, num_classes)\n\n    def forward(self, X_batch, lengths, return_attn_weights=False):\n        embeddings = self.embedding(X_batch)\n\n        embeddings = nn.utils.rnn.pack_padded_sequence(embeddings, lengths.cpu(), enforce_sorted=False, batch_first=True)\n        output, (_, _) = self.encoder(embeddings)\n        output, _ = nn.utils.rnn.pad_packed_sequence(output,batch_first=True)\n\n        padding_positions = self.__get_padding_masks(lengths).to(output.device)\n        doc_embeddings = self.attn(output,padding_positions=padding_positions,return_weights=return_attn_weights)\n        \n        if return_attn_weights:\n            return self.decoder(doc_embeddings[0]), doc_embeddings[1]\n        else:\n            return self.decoder(doc_embeddings)\n    \n    def __get_padding_masks(self, lengths):\n        '''\n        Returns a mask (shape BxLx1) that indicates the position of pad tokens\n        '''\n        max_len = lengths.max()\n        return torch.tensor([[False]*i + [True]*(max_len-i) for i in lengths]).unsqueeze(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:35:40.104136Z","iopub.execute_input":"2024-04-17T06:35:40.104761Z","iopub.status.idle":"2024-04-17T06:35:40.130936Z","shell.execute_reply.started":"2024-04-17T06:35:40.104709Z","shell.execute_reply":"2024-04-17T06:35:40.128394Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 1. Categorized evals","metadata":{}},{"cell_type":"markdown","source":"Set hyperparameters and load model","metadata":{}},{"cell_type":"code","source":"MODEL_MAX_LEN = 500\nNUM_CLASSES = 4\nEMBED_DIM = 100\nHIDDEN_DIM = 100\nNUM_LSTM_LAYERS = 1\n\nVOCAB_LEN = 400001 #harcoded for convenience; see below for how it was obtained\n# glove, _ = DataPreprocessorFlat.from_pretrained_embeds(NUM_CLASSES,'/kaggle/input/lun-glove/glove.6B.100d.txt', EMBED_DIM)\n# VOCAB_LEN = len(glove.vocab)\n\nMODEL_PATH = './outputs/model/bestFAN_ml500_ba256_emb100hid100lay1cla4_ep10lr0.0005wd5e-06_af0.5ap2_model.pt'\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ncollate_fn = make_flat_collate_function(MODEL_MAX_LEN)\nmodel = LSTMFlatAttentionFCNNClassifier(VOCAB_LEN, EMBED_DIM, HIDDEN_DIM, NUM_LSTM_LAYERS, NUM_CLASSES)\nmodel.to(DEVICE)\nmodel.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:21:30.203887Z","iopub.execute_input":"2024-04-16T17:21:30.204288Z","iopub.status.idle":"2024-04-16T17:21:33.830329Z","shell.execute_reply.started":"2024-04-16T17:21:30.204257Z","shell.execute_reply":"2024-04-16T17:21:33.829088Z"},"trusted":true},"execution_count":115,"outputs":[{"execution_count":115,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"Load Preprocessed test data and sub-categorized test data","metadata":{"execution":{"iopub.status.busy":"2024-04-11T12:15:02.320834Z","iopub.execute_input":"2024-04-11T12:15:02.321256Z","iopub.status.idle":"2024-04-11T12:15:04.003140Z","shell.execute_reply.started":"2024-04-11T12:15:02.321225Z","shell.execute_reply":"2024-04-11T12:15:04.002122Z"}}},{"cell_type":"code","source":"X_test = pd.read_parquet('./FAN_prepro_data/X_test_prep_flat.parquet')['Text']\ny_test = pd.read_parquet('./FAN_prepro_data/y_test_prep_flat.parquet')['Label']\nembeds = torch.tensor(np.load('./glove_embs.npy'))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:22:17.171551Z","iopub.execute_input":"2024-04-16T17:22:17.171935Z","iopub.status.idle":"2024-04-16T17:22:19.658270Z","shell.execute_reply.started":"2024-04-16T17:22:17.171905Z","shell.execute_reply":"2024-04-16T17:22:19.657318Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"test_df_categorised = pd.read_csv('/kaggle/input/lun-glove/balancedtestwithclass_new_cleaned.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:04:56.921848Z","iopub.execute_input":"2024-04-17T07:04:56.922388Z","iopub.status.idle":"2024-04-17T07:04:57.143552Z","shell.execute_reply.started":"2024-04-17T07:04:56.922351Z","shell.execute_reply":"2024-04-17T07:04:57.142409Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\ndef categorised_eval_flat(categories_df, X, ylens, model, device, category_list=[0,1,2,3,4,5]):\n    records = {'category':[], 'support':[], 'acc':[], 'f1':[], 'precision':[], 'recall':[]}\n    all_preds = []\n    all_truths = []\n    idxes = []\n    for cat in category_list:\n        idx = categories_df[categories_df['Category']==cat].index\n        ylens_cat = ylens.loc[idx]\n        X_cat = X.loc[idx]\n        loader = DataLoader(WrapperDatasetFlat(X_cat, ylens_cat),\n                          batch_size=128,\n                          collate_fn=collate_fn,\n                          shuffle=False)\n        model.to(device)\n        preds=[]\n        truths=[]\n        for X_batch, lengths, y_batch in tqdm(loader):\n            #Move to correct device\n            X_batch = X_batch.to(device)\n\n            #Forward pass\n            outputs = model(X_batch, lengths)\n            if type(outputs)==tuple:\n                logits = outputs[0]\n            else:\n                logits = outputs\n\n            #Logging\n            preds.append(torch.argmax(logits, dim=-1).cpu())\n            truths.append(y_batch)\n        preds = torch.cat(preds)\n        truths = torch.cat(truths)\n        records['category'].append(cat)\n        records['support'].append(len(X_cat))\n        records['acc'].append(accuracy_score(truths, preds))\n        records['f1'].append(f1_score(truths, preds, average='macro'))\n        records['precision'].append(precision_score(truths, preds, average='macro'))\n        records['recall'].append(recall_score(truths, preds, average='macro'))\n        all_preds.append(preds)\n        all_truths.append(truths)\n        idxes.append(idx)\n    return records, all_preds, all_truths, idxes","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:04:20.886093Z","iopub.execute_input":"2024-04-17T07:04:20.886780Z","iopub.status.idle":"2024-04-17T07:04:20.903767Z","shell.execute_reply.started":"2024-04-17T07:04:20.886738Z","shell.execute_reply":"2024-04-17T07:04:20.902603Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"results = categorised_eval_flat(test_df_categorised, X_test_flat, y_test_flat, model, DEVICE, category_list=[0,1,2,3,4,5])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:05:25.314144Z","iopub.execute_input":"2024-04-17T07:05:25.314617Z","iopub.status.idle":"2024-04-17T07:05:44.449047Z","shell.execute_reply.started":"2024-04-17T07:05:25.314585Z","shell.execute_reply":"2024-04-17T07:05:44.447750Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stderr","text":"100%|██████████| 2/2 [00:00<00:00,  2.10it/s]\n100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n100%|██████████| 5/5 [00:03<00:00,  1.26it/s]\n100%|██████████| 8/8 [00:05<00:00,  1.37it/s]\n100%|██████████| 9/9 [00:06<00:00,  1.33it/s]\n100%|██████████| 2/2 [00:00<00:00,  2.15it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(results)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T07:48:01.353422Z","iopub.execute_input":"2024-04-15T07:48:01.353786Z","iopub.status.idle":"2024-04-15T07:48:01.368995Z","shell.execute_reply.started":"2024-04-15T07:48:01.353757Z","shell.execute_reply":"2024-04-15T07:48:01.368156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(results).to_csv('./outputs/FAN_categorized_eval_results.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T07:48:25.792374Z","iopub.execute_input":"2024-04-15T07:48:25.792776Z","iopub.status.idle":"2024-04-15T07:48:25.800877Z","shell.execute_reply.started":"2024-04-15T07:48:25.792745Z","shell.execute_reply":"2024-04-15T07:48:25.799641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(test_df_categorised[test_df_categorised['Category']==2]['Label'], test_df_categorised[test_df_categorised['Category']==2]['pred_fan']))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:27:19.731707Z","iopub.execute_input":"2024-04-16T17:27:19.732140Z","iopub.status.idle":"2024-04-16T17:27:19.749990Z","shell.execute_reply.started":"2024-04-16T17:27:19.732102Z","shell.execute_reply":"2024-04-16T17:27:19.748861Z"},"trusted":true},"execution_count":144,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           1       0.41      0.69      0.51        16\n           2       0.33      0.22      0.27        18\n           3       0.96      0.70      0.81       493\n           4       0.18      0.88      0.29        32\n\n    accuracy                           0.70       559\n   macro avg       0.47      0.62      0.47       559\nweighted avg       0.88      0.70      0.75       559\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Visualize attention","metadata":{}},{"cell_type":"code","source":"class AttnVizPreprocessorFlat():\n\n    def __init__(self, data_vocab):\n        self.vocab = data_vocab\n        print(\"Vocab created: {} unique tokens\".format(len(self.vocab)))\n        \n    @classmethod\n    def from_pretrained_embeds(cls, embed_path, embed_dim, sep=\" \",  specials=['<unk>']):\n        # start with all '0's for special tokens\n        embeds = [np.asarray([0]*embed_dim, dtype=np.float32)]*len(specials)\n        words = OrderedDict()\n        with open(embed_path, encoding=\"utf-8\") as f:\n            for i, line in enumerate(f):\n                if i == 38522 and 'twitter.27B.100d' in embed_path:\n                    continue\n                splitline = line.split()\n                \n                word = splitline[0]\n                if word not in words:\n                    words[word] = 0\n                words[word]+=1\n                embeds.append(np.asarray(splitline[1:], dtype=np.float32))\n                \n        embeds = torch.tensor(np.array(embeds))\n        data_vocab = vocab(words, specials=specials)\n        data_vocab.set_default_index(data_vocab['<unk>'])\n        return cls(data_vocab)\n\n    def get_vocab_size(self):\n        return len(self.vocab)\n    \n    def preprocess_single_row(self, row, model_max_len, preprocess_label=False):\n        '''\n        Converts text into integers that index the vocab,\n        and converts labels into the range [0,num_classes-1]\n        \n        Return tokens by sentence (unpadded), idx by sentence (padded), label, num_sentences, num_tokens\n        '''\n        text = row['Text']\n        label = row['Label']\n        \n        words = [word_tokenize(sent.lower()) for sent in sent_tokenize(text.replace(\"'\",\"\"))]\n        words = [word for sent in words for word in sent][:model_max_len] # flatten and truncate\n        token_idxs = self.vocab(words)\n        num_tokens = len(token_idxs)\n        \n        if preprocess_label:\n            label -= 1\n        return words, torch.tensor(token_idxs, dtype=torch.long), label,\\\n                torch.tensor(num_tokens, dtype=torch.long).unsqueeze(0)\n                \n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:44:24.546115Z","iopub.execute_input":"2024-04-17T06:44:24.547321Z","iopub.status.idle":"2024-04-17T06:44:24.563610Z","shell.execute_reply.started":"2024-04-17T06:44:24.547255Z","shell.execute_reply":"2024-04-17T06:44:24.561703Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"MODEL_MAX_LEN = 500\nNUM_CLASSES = 4\nEMBED_DIM = 100\nHIDDEN_DIM = 100\nNUM_LSTM_LAYERS = 1\n\nVOCAB_LEN = 400001 #harcoded for convenience; see below for how it was obtained\n# glove, _ = DataPreprocessorFlat.from_pretrained_embeds(NUM_CLASSES,'/kaggle/input/lun-glove/glove.6B.100d.txt', EMBED_DIM)\n# VOCAB_LEN = len(glove.vocab)\n\nEMBED_PATH = '../glove.6B.100d.txt'\nMODEL_PATH = './outputs/model/bestFAN_ml500_ba256_emb100hid100lay1cla4_ep10lr0.0005wd5e-06_af0.5ap2_model.pt'\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ncollate_fn = make_flat_collate_function(MODEL_MAX_LEN)\nmodel = LSTMFlatAttentionFCNNClassifier(VOCAB_LEN, EMBED_DIM, HIDDEN_DIM, NUM_LSTM_LAYERS, NUM_CLASSES)\nmodel.to(DEVICE)\nmodel.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\nppflat = AttnVizPreprocessorFlat.from_pretrained_embeds(EMBED_PATH, EMBED_DIM)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:21:13.703391Z","iopub.execute_input":"2024-04-17T07:21:13.704127Z","iopub.status.idle":"2024-04-17T07:21:29.193648Z","shell.execute_reply.started":"2024-04-17T07:21:13.704092Z","shell.execute_reply":"2024-04-17T07:21:29.192194Z"},"trusted":true},"execution_count":144,"outputs":[{"name":"stdout","text":"Vocab created: 400001 unique tokens\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport torch\nimport json\nfrom IPython.display import Markdown, display\n\nlabelid2label = ['Satire', 'Hoax', 'Propaganda', 'Trusted']\n\nclass AttentionVisualizerFlat():\n    def __init__(self, model, preprocessor):\n        \n        self.model = model\n        self.preprocessor = preprocessor\n\n    def visualize_attention(self, doc_and_label_row, model_max_len, device='cpu', preprocess_label=False):\n        # doc_and_label_row should contain a row of the df with columns ['Text'] and ['Label']\n        \n        words, X, y, num_tokens = self.preprocessor.preprocess_single_row(doc_and_label_row, model_max_len, preprocess_label)\n        pred, word_weights = self.model(X.unsqueeze(0), num_tokens, return_attn_weights=True)\n        pred = torch.argmax(pred, dim = -1).cpu().item()\n        word_weights = word_weights.squeeze(0,2).cpu()\n        \n        max_weight = word_weights.max()\n        min_weight = word_weights.min()\n        line = []\n        line_length = 0\n        \n        display(Markdown('<p style=\"font-size:18px\"> Ground Truth: '+ labelid2label[y] + '&emsp;&emsp;&emsp;Prediction: '+labelid2label[pred] +'</p>'))\n        \n        for word, weight in zip(words, word_weights):\n            line_length += len(word)\n            line.append(self.__make_word(word, self.__scale_weight(weight, max_weight, min_weight)))\n            if line_length > 60:\n                display(Markdown(\" \".join(line)))\n                line = []\n                line_length = 0\n        if len(line) > 0:\n            display(Markdown(\" \".join(line)))\n        return words, pred, word_weights\n    \n    def __make_word(self, word, word_weight):\n        return '<span style=\"background-color:rgba(0,0,255,' +\\\n                        str(word_weight.item()) + ');font-size:16px;\">' +\\\n                        word.replace('$', '\\$').replace(\"'\", \"\\'\") + '</span>'\n\n    def __scale_weight(self, orig_weight, max_weight, min_weight):\n        return (orig_weight-min_weight)/(max_weight-min_weight) * 0.5\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:01:03.208836Z","iopub.execute_input":"2024-04-17T07:01:03.209303Z","iopub.status.idle":"2024-04-17T07:01:03.225836Z","shell.execute_reply.started":"2024-04-17T07:01:03.209257Z","shell.execute_reply":"2024-04-17T07:01:03.224150Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"avflat = AttentionVisualizerFlat(model, ppflat)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:01:04.366396Z","iopub.execute_input":"2024-04-17T07:01:04.366861Z","iopub.status.idle":"2024-04-17T07:01:04.373121Z","shell.execute_reply.started":"2024-04-17T07:01:04.366829Z","shell.execute_reply":"2024-04-17T07:01:04.371745Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/lun-glove/balancedtest.csv', header=None, names=['Label', 'Text'])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:07:22.933117Z","iopub.execute_input":"2024-04-17T12:07:22.933588Z","iopub.status.idle":"2024-04-17T12:07:23.181339Z","shell.execute_reply.started":"2024-04-17T12:07:22.933556Z","shell.execute_reply":"2024-04-17T12:07:23.179857Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X_test_flat = pd.read_parquet('./FAN_prepro_data/X_test_prep_flat.parquet')['Text']\ny_test_flat = pd.read_parquet('./FAN_prepro_data/y_test_prep_flat.parquet')['Label']","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:03:50.563859Z","iopub.execute_input":"2024-04-17T07:03:50.564356Z","iopub.status.idle":"2024-04-17T07:03:50.871165Z","shell.execute_reply.started":"2024-04-17T07:03:50.564319Z","shell.execute_reply":"2024-04-17T07:03:50.869685Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"def predic(te):\n    w, tok, lab, pad = ppflat.preprocess_single_row({'Text':te, 'Label':1}, 500, False)\n    pred = model(tok.unsqueeze(0), pad, return_attn_weights=False)\n    return torch.argmax(pred, dim = -1).cpu().item()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:21:39.041396Z","iopub.execute_input":"2024-04-17T07:21:39.043972Z","iopub.status.idle":"2024-04-17T07:21:39.051650Z","shell.execute_reply.started":"2024-04-17T07:21:39.043925Z","shell.execute_reply":"2024-04-17T07:21:39.049771Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"code","source":"test_df['pred_flat_2'] = -1\ntest_df['pred_flat_2'] = test_df['Text'].apply(predic)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:21:39.550946Z","iopub.execute_input":"2024-04-17T07:21:39.551402Z","iopub.status.idle":"2024-04-17T07:25:35.375005Z","shell.execute_reply.started":"2024-04-17T07:21:39.551371Z","shell.execute_reply":"2024-04-17T07:25:35.373752Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"test_df['pred_flat'] = -1\ntest_df['truths'] = -1\nfor p, t, i in zip(results[1],results[2],results[3]):\n    test_df.loc[i, 'pred_flat'] = p.tolist()\n    test_df.loc[i, 'truths'] = t.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:08:32.545705Z","iopub.execute_input":"2024-04-17T07:08:32.546935Z","iopub.status.idle":"2024-04-17T07:08:32.564228Z","shell.execute_reply.started":"2024-04-17T07:08:32.546894Z","shell.execute_reply":"2024-04-17T07:08:32.562948Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"test_df['length'] = test_df['Text'].apply(lambda s: len(s.split()))","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:26:50.357285Z","iopub.execute_input":"2024-04-17T07:26:50.357804Z","iopub.status.idle":"2024-04-17T07:26:50.481103Z","shell.execute_reply.started":"2024-04-17T07:26:50.357771Z","shell.execute_reply":"2024-04-17T07:26:50.479762Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"test_df[(test_df['pred_hier']==test_df['pred_flat']) & (test_df['pred_hier']==test_df['truths'])  & (test_df['length'] < 100) & (test_df['pred_flat'] == 3) & (test_df['Text'].apply(lambda t: re.search(r'[0-9]', t) is not None))]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T08:31:12.157644Z","iopub.execute_input":"2024-04-17T08:31:12.158139Z","iopub.status.idle":"2024-04-17T08:31:12.237273Z","shell.execute_reply.started":"2024-04-17T08:31:12.158107Z","shell.execute_reply":"2024-04-17T08:31:12.235812Z"},"trusted":true},"execution_count":258,"outputs":[{"execution_count":258,"output_type":"execute_result","data":{"text/plain":"      Label                                               Text  pred_flat  \\\n2268      4  British American Tobacco announced Tuesday tha...          3   \n2334      4  Gold for current delivery closed at $1,107.80 ...          3   \n2399      4  Triple Olympic gold medalist Stephanie Rice sa...          3   \n2401      4  Singapore exchange to buy Australian bourse fo...          3   \n2407      4  West Indies beat England by five wickets under...          3   \n2413      4  Eurozone recovery falters in Q4 as economy gro...          3   \n2467      4  Coast Guard Adm. Thad Allen: cap now funneling...          3   \n2487      4  Spanish bank BBVA reported Wednesday its fourt...          3   \n2526      4  Results Thursday from the St. Petersburg Open ...          3   \n2542      4  Brome Howard Inn 18281 Rosecroft Rd., St. Mary...          3   \n2544      4  Results Sunday from the Japan Open, a $1.2 mil...          3   \n2556      4  Simone Hauswald of Germany mastered windy and ...          3   \n2563      4  Consumers increased their spending in June for...          3   \n2609      4  America picked up its first victory of the Mex...          3   \n2612      4  Norway's Marit Bjoergen has won the women's 10...          3   \n2629      4  A federal judge has sentenced former Democrati...          3   \n2666      4  Gold for current delivery closed at $1,159.70 ...          3   \n2686      4  Serbia coach Radomir Antic has reduced his squ...          3   \n2702      4  Unemployment in Britain for the three months e...          3   \n2731      4  German consumer goods company Beiersdorf repor...          3   \n2760      4  Share prices on the London Stock Exchange were...          3   \n2825      4  Scores at lunch Tuesday on the first day of th...          3   \n2830      4  Sevilla's Diego Perotti will be sidelined for ...          3   \n2833      4  Attacking midfielder Marek Hamsik has extended...          3   \n2877      4  The United States beat Russia 4-3 on Sunday fo...          3   \n2879      4  Pakistan has been bowled out for 296 on the fo...          3   \n2884      4  Netherlands becomes first team to qualify for ...          3   \n2892      4  Death toll from Indonesian volcano climbs to 9...          3   \n2930      4  Montenegro's government on Thursday canceled a...          3   \n2967      4  Barbados international and former Millwall for...          3   \n2981      4  Dominican Republic cyclist Leonardo Grullon ha...          3   \n2997      4  River Plate midfielder Diego Buonanotte has un...          3   \n\n      truths  pred_hier  pred_flat_2  length  \n2268       3          3            3      55  \n2334       3          3            3      22  \n2399       3          3            3      91  \n2401       3          3            3      13  \n2407       3          3            3      74  \n2413       3          3            3      15  \n2467       3          3            3      20  \n2487       3          3            3      99  \n2526       3          3            3      53  \n2542       3          3            3      35  \n2544       3          3            3      51  \n2556       3          3            3      84  \n2563       3          3            3      99  \n2609       3          3            3      89  \n2612       3          3            3      73  \n2629       3          3            3      95  \n2666       3          3            3      22  \n2686       3          3            3      88  \n2702       3          3            3      87  \n2731       3          3            3      86  \n2760       3          3            3      24  \n2825       3          3            3      40  \n2830       3          3            3      86  \n2833       3          3            3      86  \n2877       3          3            3      71  \n2879       3          3            3      74  \n2884       3          3            3      13  \n2892       3          3            3      11  \n2930       3          3            3      98  \n2967       3          3            3      75  \n2981       3          3            3      96  \n2997       3          3            3      96  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Text</th>\n      <th>pred_flat</th>\n      <th>truths</th>\n      <th>pred_hier</th>\n      <th>pred_flat_2</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2268</th>\n      <td>4</td>\n      <td>British American Tobacco announced Tuesday tha...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>2334</th>\n      <td>4</td>\n      <td>Gold for current delivery closed at $1,107.80 ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>2399</th>\n      <td>4</td>\n      <td>Triple Olympic gold medalist Stephanie Rice sa...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>91</td>\n    </tr>\n    <tr>\n      <th>2401</th>\n      <td>4</td>\n      <td>Singapore exchange to buy Australian bourse fo...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2407</th>\n      <td>4</td>\n      <td>West Indies beat England by five wickets under...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>2413</th>\n      <td>4</td>\n      <td>Eurozone recovery falters in Q4 as economy gro...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>2467</th>\n      <td>4</td>\n      <td>Coast Guard Adm. Thad Allen: cap now funneling...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2487</th>\n      <td>4</td>\n      <td>Spanish bank BBVA reported Wednesday its fourt...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>99</td>\n    </tr>\n    <tr>\n      <th>2526</th>\n      <td>4</td>\n      <td>Results Thursday from the St. Petersburg Open ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>2542</th>\n      <td>4</td>\n      <td>Brome Howard Inn 18281 Rosecroft Rd., St. Mary...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>2544</th>\n      <td>4</td>\n      <td>Results Sunday from the Japan Open, a $1.2 mil...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>2556</th>\n      <td>4</td>\n      <td>Simone Hauswald of Germany mastered windy and ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>2563</th>\n      <td>4</td>\n      <td>Consumers increased their spending in June for...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>99</td>\n    </tr>\n    <tr>\n      <th>2609</th>\n      <td>4</td>\n      <td>America picked up its first victory of the Mex...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>89</td>\n    </tr>\n    <tr>\n      <th>2612</th>\n      <td>4</td>\n      <td>Norway's Marit Bjoergen has won the women's 10...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>2629</th>\n      <td>4</td>\n      <td>A federal judge has sentenced former Democrati...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>2666</th>\n      <td>4</td>\n      <td>Gold for current delivery closed at $1,159.70 ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>2686</th>\n      <td>4</td>\n      <td>Serbia coach Radomir Antic has reduced his squ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>2702</th>\n      <td>4</td>\n      <td>Unemployment in Britain for the three months e...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>2731</th>\n      <td>4</td>\n      <td>German consumer goods company Beiersdorf repor...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>2760</th>\n      <td>4</td>\n      <td>Share prices on the London Stock Exchange were...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>2825</th>\n      <td>4</td>\n      <td>Scores at lunch Tuesday on the first day of th...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>2830</th>\n      <td>4</td>\n      <td>Sevilla's Diego Perotti will be sidelined for ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>2833</th>\n      <td>4</td>\n      <td>Attacking midfielder Marek Hamsik has extended...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>2877</th>\n      <td>4</td>\n      <td>The United States beat Russia 4-3 on Sunday fo...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>2879</th>\n      <td>4</td>\n      <td>Pakistan has been bowled out for 296 on the fo...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>2884</th>\n      <td>4</td>\n      <td>Netherlands becomes first team to qualify for ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2892</th>\n      <td>4</td>\n      <td>Death toll from Indonesian volcano climbs to 9...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2930</th>\n      <td>4</td>\n      <td>Montenegro's government on Thursday canceled a...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>98</td>\n    </tr>\n    <tr>\n      <th>2967</th>\n      <td>4</td>\n      <td>Barbados international and former Millwall for...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>2981</th>\n      <td>4</td>\n      <td>Dominican Republic cyclist Leonardo Grullon ha...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>96</td>\n    </tr>\n    <tr>\n      <th>2997</th>\n      <td>4</td>\n      <td>River Plate midfielder Diego Buonanotte has un...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>96</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}