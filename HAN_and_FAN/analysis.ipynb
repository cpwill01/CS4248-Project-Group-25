{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8081439,"sourceType":"datasetVersion","datasetId":4749401},{"sourceId":8122822,"sourceType":"datasetVersion","datasetId":4747496},{"sourceId":28272,"sourceType":"modelInstanceVersion","modelInstanceId":23804},{"sourceId":29043,"sourceType":"modelInstanceVersion","modelInstanceId":24461}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-08T06:03:34.507242Z","iopub.execute_input":"2024-04-08T06:03:34.507917Z","iopub.status.idle":"2024-04-08T06:03:35.400808Z","shell.execute_reply.started":"2024-04-08T06:03:34.507875Z","shell.execute_reply":"2024-04-08T06:03:35.399888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchinfo\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchinfo import summary\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator, GloVe, vocab\nfrom tqdm import tqdm\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom collections import OrderedDict","metadata":{"execution":{"iopub.status.busy":"2024-04-17T17:14:59.491536Z","iopub.execute_input":"2024-04-17T17:14:59.492248Z","iopub.status.idle":"2024-04-17T17:15:26.725099Z","shell.execute_reply.started":"2024-04-17T17:14:59.492213Z","shell.execute_reply":"2024-04-17T17:15:26.723285Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchinfo in /opt/conda/lib/python3.10/site-packages (1.8.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Define Classes and Functions","metadata":{}},{"cell_type":"markdown","source":"### Data-Related Classes and Functions","metadata":{}},{"cell_type":"code","source":"###### Uncomment this cell to run data preprocessing for HAN ############\n# SAVE_FOLDER_PATH = '/kaggle/working/'\n# FULL_TRAIN_DATA_PATH = '/kaggle/input/lun-glove/fulltrain.csv'\n# FULL_TEST_DATA_PATH = '/kaggle/input/lun-glove/balancedtest.csv'\n\n# MAX_SENT_LEN = 30\n# MAX_NUM_SENTS = 30\n# NUM_CLASSES = 4\n# EMBED_DIM = 100\n\n# glove, embeds = DataPreprocessorHcl.from_pretrained_embeds(NUM_CLASSES,'/kaggle/input/lun-glove/glove.6B.100d.txt', EMBED_DIM)\n# train_df = pd.read_csv(FULL_TRAIN_DATA_PATH, header=None, names=['Label', 'Text'])\n# test_df = pd.read_csv(FULL_TEST_DATA_PATH, header=None, names=['Label', 'Text'])\n# X, ylens = glove.preprocess_data(train_df, MAX_SENT_LEN, MAX_NUM_SENTS)\n# X_test, ylens_test = glove.preprocess_data(test_df, MAX_SENT_LEN, MAX_NUM_SENTS)\n\n# VOCAB_LEN = len(glove.vocab)\n\n# np.save(SAVE_FOLDER_PATH+'X_train_prep.npy',X)\n# np.save(SAVE_FOLDER_PATH+'X_test_prep.npy',X_test)\n# ylens.to_csv(SAVE_FOLDER_PATH+'ylens_train_prep.csv', index=False)\n# ylens_test.to_csv(SAVE_FOLDER_PATH+'ylens_test_prep.csv', index=False)\n# np.save(SAVE_FOLDER_PATH+'glove_embs.npy',embeds)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T18:37:58.209522Z","iopub.execute_input":"2024-04-17T18:37:58.210096Z","iopub.status.idle":"2024-04-17T18:38:02.441369Z","shell.execute_reply.started":"2024-04-17T18:37:58.210063Z","shell.execute_reply":"2024-04-17T18:38:02.439836Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"MAX_SENT_LEN = 30\nMAX_NUM_SENTS = 30\nNUM_CLASSES = 4\nEMBED_DIM = 100\nVOCAB_SIZE = 400001 #hardcoded for convenience; see prev cell for how it was obtained\n\nX = np.load('/kaggle/input/lun-preprocessed-for-heatt/newModelCleanedGlove6b/X_train_prep.npy')\nylens = pd.read_csv('/kaggle/input/lun-preprocessed-for-heatt/newModelCleanedGlove6b/ylens_train_prep.csv')\nX_test = np.load('/kaggle/input/lun-preprocessed-for-heatt/newModelCleanedGlove6b/X_test_prep.npy')\nylens_test = pd.read_csv('/kaggle/input/lun-preprocessed-for-heatt/newModelCleanedGlove6b/ylens_test_prep.csv')\nembeds = torch.tensor(np.load('/kaggle/input/lun-glove/glove_embs.npy'))\n\nimport ast\nylens['Num_Tokens'] = ylens['Num_Tokens'].apply(ast.literal_eval)\nylens_test['Num_Tokens'] = ylens_test['Num_Tokens'].apply(ast.literal_eval)\n\nX_train, X_val, ylens_train, ylens_val = train_test_split(X, ylens, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T06:39:10.546598Z","iopub.execute_input":"2024-04-16T06:39:10.547050Z","iopub.status.idle":"2024-04-16T06:39:16.876242Z","shell.execute_reply.started":"2024-04-16T06:39:10.547016Z","shell.execute_reply":"2024-04-16T06:39:16.875019Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def check_for_bugs(ylens, num_classes, max_num_sent, max_sent_len):\n    if (ylens['Label'] < num_classes).all():\n        print(\"Num classes correct\")\n    if (ylens['Num_Sentences'] <= max_num_sent).all():\n        print(\"Num sentences correct\")\n    if (ylens['Num_Tokens'].apply(lambda ls : all([le <= max_sent_len for le in ls]))).all():\n        print(\"Num tokenss correct\")\n    return\ncheck_for_bugs(ylens, NUM_CLASSES, MAX_NUM_SENTS, MAX_SENT_LEN)\ncheck_for_bugs(ylens_test, NUM_CLASSES, MAX_NUM_SENTS, MAX_SENT_LEN)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T06:39:16.878397Z","iopub.execute_input":"2024-04-16T06:39:16.878726Z","iopub.status.idle":"2024-04-16T06:39:17.052053Z","shell.execute_reply.started":"2024-04-16T06:39:16.878701Z","shell.execute_reply":"2024-04-16T06:39:17.050857Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Num classes correct\nNum sentences correct\nNum tokenss correct\nNum classes correct\nNum sentences correct\nNum tokenss correct\n","output_type":"stream"}]},{"cell_type":"code","source":"TRAIN_BATCH_SIZE = 256\nVALID_BATCH_SIZE = 512\ntrain_loader = DataLoader(WrapperDatasetHcl(X_train, ylens_train),\n                          batch_size=TRAIN_BATCH_SIZE,\n                          collate_fn=collate_fnHcl,\n                          shuffle=True)\n\nval_loader = DataLoader(WrapperDatasetHcl(X_val, ylens_val),\n                          batch_size=VALID_BATCH_SIZE,\n                          collate_fn=collate_fnHcl,\n                          shuffle=False)\n\ntest_loader = DataLoader(WrapperDatasetHcl(X_test, ylens_test),\n                          batch_size=VALID_BATCH_SIZE,\n                          collate_fn=collate_fnHcl,\n                          shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T06:39:42.921745Z","iopub.execute_input":"2024-04-16T06:39:42.922148Z","iopub.status.idle":"2024-04-16T06:39:42.943803Z","shell.execute_reply.started":"2024-04-16T06:39:42.922117Z","shell.execute_reply":"2024-04-16T06:39:42.942866Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"## 2way inside here","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nembed_dim_space = [100]\nhidden_dim_space = [100, 75]\nnum_lstm_layers_space = [1]\n\nnum_epochs_space = [10]\nlr_space = [5e-04]\nwd_space = [5e-06]\nfactor_space = [0.5]\npatience_space = [2]\n\nRANDOM_SEED = 42\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nSAVE_FOLDER_PATH=\"/kaggle/working/\"\nFILES_NAME_FORMAT=\"2wayHeAttBiLSTM_msl{}_mns{}_batch{}_emb{}hid{}lay{}cla{}_ep{}lr{}wd{}_af{}ap{}_gloveclean_unfro\"\n\nrecords = {\"path\": [], \"precision\":[], \"recall\": [], \"f1\": [], \"acc\":[]}\ncheckpoint = 0\n\nfor NUM_EPOCHS in num_epochs_space:\n    for WEIGHT_DECAY in wd_space:\n        for LR_ANNEAL_FACTOR in factor_space:\n            for LR_ANNEAL_PATIENCE in patience_space:\n                for LOSS_WEIGHTS in [None]:\n                    for NUM_LSTM_LAYERS in num_lstm_layers_space:\n#                         LOSS_WEIGHT_STRING = 'Weighted' if LOSS_WEIGHTS else 'Unweighted'\n                        for HIDDEN_DIM in hidden_dim_space:\n                            for EMBED_DIM in embed_dim_space:\n                                for LEARNING_RATE in lr_space:\n                                    torch.manual_seed(RANDOM_SEED)\n                                    model = BiLSTMHeAttFCNNClassifier(VOCAB_SIZE,\n                                                                  EMBED_DIM,\n                                                                  HIDDEN_DIM,\n                                                                  NUM_LSTM_LAYERS,\n                                                                  NUM_CLASSES,\n                                                                  pretrained_embeddings = embeds.to(torch.float32))\n                                    trainer = Trainer(model, train_loader, val_loader,\n                                                      NUM_EPOCHS, LEARNING_RATE,\n                                                      weight_decay=WEIGHT_DECAY,\n                                                      lr_anneal_factor=LR_ANNEAL_FACTOR,\n                                                      lr_anneal_patience=LR_ANNEAL_PATIENCE,\n                                                      loss_weights=LOSS_WEIGHTS,\n                                                      save_loss_acc_plots=True)\n                                    model_path, _ = trainer.train(SAVE_FOLDER_PATH,\n                                                  FILES_NAME_FORMAT.format(MAX_SENT_LEN,MAX_NUM_SENTS, TRAIN_BATCH_SIZE, EMBED_DIM,\n                                                                           HIDDEN_DIM, NUM_LSTM_LAYERS, NUM_CLASSES,\n                                                                          NUM_EPOCHS, LEARNING_RATE, WEIGHT_DECAY,\n                                                                          LR_ANNEAL_FACTOR, LR_ANNEAL_PATIENCE),\n                                                  verbose=checkpoint<2,\n                                                     test_loader=test_loader)\n\n                                    model.load_state_dict(torch.load(model_path))\n                                    preds = []\n                                    truths = []\n                                    model.eval()\n                                    with torch.no_grad():\n                                        for X, y, num_sent, sent_len in test_loader:\n                                            #Move to correct device\n                                            X = X.to(DEVICE)\n\n                                            #Forward pass\n                                            outputs = model(X, num_sent, sent_len)\n                                            logits = outputs[0] if type(outputs)==tuple else outputs\n                                            #Logging\n                                            preds.append(torch.argmax(logits, dim=-1).cpu())\n                                            truths.append(y)\n                                    preds = torch.cat(preds)\n                                    truths = torch.cat(truths)\n                                    records['path'].append(model_path)\n                                    records['acc'].append(accuracy_score(truths, preds))\n                                    records['f1'].append(f1_score(truths, preds, average='macro'))\n                                    records['precision'].append(precision_score(truths, preds, average='macro'))\n                                    records['recall'].append(recall_score(truths, preds, average='macro'))\n                                    if checkpoint < 2:\n                                        print(records)\n                                    checkpoint = checkpoint + 1\n                                    if checkpoint % 3 == 0:\n                                        print(records)\n                                        pd.DataFrame(records).to_csv(SAVE_FOLDER_PATH + 'tuning_metrics.csv')\n\npd.DataFrame(records).to_csv(SAVE_FOLDER_PATH + 'final_tuning_metrics.csv')\nprint(\"======================All done======================\")\nprint(records)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T06:03:56.639273Z","iopub.execute_input":"2024-04-10T06:03:56.640153Z","iopub.status.idle":"2024-04-10T06:41:18.012829Z","shell.execute_reply.started":"2024-04-10T06:03:56.640117Z","shell.execute_reply":"2024-04-10T06:41:18.011796Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nHIDDEN_DIM = 100\nNUM_LSTM_LAYERS = 1\n\nNUM_EPOCHS = 10\nLEARNING_RATE = 5e-04\nWEIGHT_DECAY = 5e-06\nLR_ANNEAL_FACTOR = 0.5\nLR_ANNEAL_PATIENCE = 2\n\nRANDOM_SEED = 42\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nSAVE_FOLDER_PATH=\"/kaggle/working/\"\nFILES_NAME_FORMAT=\"HAN_msl{}_mns{}_ba{}_emb{}hid{}lay{}cla{}_ep{}lr{}wd{}_af{}ap{}_glove_unfrozen\"\n\nrecords = {\"path\": [], \"precision\":[], \"recall\": [], \"f1\": [], \"acc\":[]}\n\ntorch.manual_seed(RANDOM_SEED)\nmodel = BiLSTMHeAttFCNNClassifier(VOCAB_SIZE,\n                              EMBED_DIM,\n                              HIDDEN_DIM,\n                              NUM_LSTM_LAYERS,\n                              NUM_CLASSES,\n                              pretrained_embeddings = embeds.to(torch.float32))\ntrainer = Trainer(model, train_loader, val_loader,\n                  NUM_EPOCHS, LEARNING_RATE,\n                  weight_decay=WEIGHT_DECAY,\n                  lr_anneal_factor=LR_ANNEAL_FACTOR,\n                  lr_anneal_patience=LR_ANNEAL_PATIENCE\n                  save_loss_acc_plots=True)\nmodel_path, _ = trainer.train(\n    SAVE_FOLDER_PATH,\n    FILES_NAME_FORMAT.format(MAX_SENT_LEN,MAX_NUM_SENTS, TRAIN_BATCH_SIZE, EMBED_DIM,\n                             HIDDEN_DIM, NUM_LSTM_LAYERS, NUM_CLASSES,\n                             NUM_EPOCHS, LEARNING_RATE, WEIGHT_DECAY,\n                             LR_ANNEAL_FACTOR, LR_ANNEAL_PATIENCE),\n    verbose=True)\n\nmodel.load_state_dict(torch.load(model_path))\npreds = []\ntruths = []\nmodel.eval()\nwith torch.no_grad():\n    for X, y, num_sent, sent_len in test_loader:\n        #Move to correct device\n        X = X.to(DEVICE)\n\n        #Forward pass\n        outputs = model(X, num_sent, sent_len, return_attn_weights=False)\n        #Logging\n        preds.append(torch.argmax(outputs, dim=-1).cpu())\n        truths.append(y)\npreds = torch.cat(preds)\ntruths = torch.cat(truths)\nrecords['path'].append(model_path)\nrecords['acc'].append(accuracy_score(truths, preds))\nrecords['f1'].append(f1_score(truths, preds, average='macro'))\nrecords['precision'].append(precision_score(truths, preds, average='macro'))\nrecords['recall'].append(recall_score(truths, preds, average='macro'))\n\nprint(records)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T13:38:01.404861Z","iopub.execute_input":"2024-04-09T13:38:01.405250Z","iopub.status.idle":"2024-04-09T14:56:23.521892Z","shell.execute_reply.started":"2024-04-09T13:38:01.405221Z","shell.execute_reply":"2024-04-09T14:56:23.520888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\nMODEL_PATH='/kaggle/input/bilstmheattnewsclassifier/pytorch/best_performing/1/glounfro_clean_msl30_mns30_batch256_embed100hidden100layers1classes4_ep10lr0.0005wd5e-06_af0.5_ap2.pt'\nmodel = BiLSTMHeAttFCNNClassifier(VOCAB_SIZE,\n                                                            100,\n                                        100,\n                                                            1,\n                                                            NUM_CLASSES,\n                                                            pretrained_embeddings = embeds.to(torch.float32))\n        model.to('cuda')\n        model.load_state_dict(torch.load(MODEL_PATH))\n\nrecords = {'split':[], 'acc':[],'f1':[],'precision':[], 'recall':[]}\nfor i, loader in enumerate([train_loader, val_loader, test_loader]):\n    \n        records['split'].append('train' if i == 0 else 'val' if i==1 else 'test')\n        \n        preds = []\n        truths = []\n        model.eval()\n        with torch.no_grad():\n            for X, y, num_sent, sent_len in loader:\n                #Move to correct device\n                X = X.to('cuda')\n\n                #Forward pass\n                outputs = model(X, num_sent, sent_len)\n\n                #Logging\n                preds.append(torch.argmax(outputs, dim=-1).cpu())\n                truths.append(y)\n        preds = torch.cat(preds)\n        truths = torch.cat(truths)\n        records['acc'].append(accuracy_score(truths, preds))\n        records['f1'].append(f1_score(truths, preds, average='macro'))\n        records['precision'].append(precision_score(truths, preds, average='macro'))\n        records['recall'].append(recall_score(truths, preds, average='macro'))\n        if i == 0:\n            print(\"TRAINING DATA\")\n        elif i == 1:\n            print(\"VALIDATION DATA\")\n        elif i == 2:\n            print(\"TEST DATA\")\n        print(classification_report(truths, preds))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:47:02.313183Z","iopub.execute_input":"2024-04-14T15:47:02.313542Z","iopub.status.idle":"2024-04-14T15:48:42.191188Z","shell.execute_reply.started":"2024-04-14T15:47:02.313513Z","shell.execute_reply":"2024-04-14T15:48:42.190197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\nMODEL_PATH='/kaggle/input/bilstmheattnewsclassifier/pytorch/best_performing/1/glounfro_clean_msl30_mns30_batch256_embed100hidden100layers1classes4_ep10lr0.0005wd5e-06_af0.5_ap2.pt'\nmodel = BiLSTMHeAttFCNNClassifier(VOCAB_SIZE,\n                                                            100,\n                                        100,\n                                                            1,\n                                                            NUM_CLASSES,\n                                                            pretrained_embeddings = embeds.to(torch.float32))\nmodel.to('cpu')\nmodel.load_state_dict(torch.load(MODEL_PATH, map_location='cpu'))\n\nrecords = {'split':[], 'acc':[],'f1':[],'precision':[], 'recall':[]}\nfor i, loader in enumerate([test_loader]):\n    \n        records['split'].append('train' if i == 0 else 'val' if i==1 else 'test')\n        \n        preds = []\n        truths = []\n        model.eval()\n        with torch.no_grad():\n            for X, y, num_sent, sent_len in loader:\n                #Move to correct device\n                X = X.to('cpu')\n\n                #Forward pass\n                outputs = model(X, num_sent, sent_len)\n\n                #Logging\n                preds.append(torch.argmax(outputs, dim=-1).cpu())\n                truths.append(y)\n        preds = torch.cat(preds)\n        truths = torch.cat(truths)\n        records['acc'].append(accuracy_score(truths, preds))\n        records['f1'].append(f1_score(truths, preds, average='macro'))\n        records['precision'].append(precision_score(truths, preds, average='macro'))\n        records['recall'].append(recall_score(truths, preds, average='macro'))\n        if i == 0:\n#             print(\"TRAINING DATA\")\n#         elif i == 1:\n#             print(\"VALIDATION DATA\")\n#         elif i == 2:\n            print(\"TEST DATA\")\n        print(classification_report(truths, preds))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T06:39:49.356848Z","iopub.execute_input":"2024-04-16T06:39:49.357490Z","iopub.status.idle":"2024-04-16T06:40:15.774810Z","shell.execute_reply.started":"2024-04-16T06:39:49.357449Z","shell.execute_reply":"2024-04-16T06:40:15.773628Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/2069489799.py:100: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n  X = torch.tensor(X, dtype=torch.long)\n","output_type":"stream"},{"name":"stdout","text":"TEST DATA\n              precision    recall  f1-score   support\n\n           0       0.93      0.78      0.85       750\n           1       0.77      0.54      0.64       750\n           2       0.64      0.79      0.71       750\n           3       0.75      0.92      0.83       750\n\n    accuracy                           0.76      3000\n   macro avg       0.77      0.76      0.76      3000\nweighted avg       0.77      0.76      0.76      3000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(records)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:49:08.078375Z","iopub.execute_input":"2024-04-14T15:49:08.079226Z","iopub.status.idle":"2024-04-14T15:49:08.096763Z","shell.execute_reply.started":"2024-04-14T15:49:08.079193Z","shell.execute_reply":"2024-04-14T15:49:08.095876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## HEAtt Alternative Implementation","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-09T07:58:00.998572Z","iopub.execute_input":"2024-04-09T07:58:00.999144Z","iopub.status.idle":"2024-04-09T07:58:01.013051Z","shell.execute_reply.started":"2024-04-09T07:58:00.999101Z","shell.execute_reply":"2024-04-09T07:58:01.010696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DO NOT TOUCH THIS CELL THIS IS THE FINAL IMPLEMENTATION!\nclass DataPreprocessorHcl():\n\n    def __init__(self, num_classes, data_vocab):\n        self.num_classes = num_classes\n        self.vocab = data_vocab\n        print(\"Vocab created: {} unique tokens\".format(len(self.vocab)))\n        \n    @classmethod\n    def from_train_df(cls, num_classes, train_df, specials=['<unk>']):\n        data_vocab = build_vocab_from_iterator(cls.__yield_tokens(train_df), specials=specials)\n        data_vocab.set_default_index(data_vocab['<unk>'])\n        return cls(num_classes, data_vocab)\n    \n    @classmethod\n    def from_pretrained_embeds(cls, num_classes, embed_path, embed_dim, sep=\" \",  specials=['<unk>']):\n        # start with all '0's for special tokens\n        embeds = [np.asarray([0]*embed_dim, dtype=np.float32)]*len(specials)\n        words = OrderedDict()\n        with open(embed_path, encoding=\"utf-8\") as f:\n            for i, line in enumerate(f):\n                if i == 38522 and 'twitter.27B.100d' in embed_path:\n                    continue\n                splitline = line.split()\n                \n                word = splitline[0]\n                words[word] = 1\n                \n                embeds.append(np.asarray(splitline[1:], dtype=np.float32))\n                \n        embeds = torch.tensor(np.array(embeds))\n        data_vocab = vocab(words, min_freq=1, specials=specials)\n        data_vocab.set_default_index(data_vocab['<unk>'])\n        return cls(num_classes, data_vocab), embeds\n\n    @classmethod\n    def __yield_tokens(cls, df):\n        for row in df.itertuples(index=False):\n            yield word_tokenize(row.Text.lower())\n\n    def get_vocab_size(self):\n        return len(self.vocab)\n    \n    def preprocess_data(self, df, max_sent_len, max_num_sents, clean=True):\n        '''\n        Converts text into integers that index the vocab,\n        and converts labels into the range [0,num_classes-1]\n        '''\n        if clean:\n            X = df['Text'].apply(lambda t: [self.vocab(word_tokenize(s.lower())) for s in sent_tokenize(t.replace(\"'\",\"\"))])\n        else:\n            X = df['Text'].apply(lambda t: [self.vocab(word_tokenize(s.lower())) for s in sent_tokenize(t)])\n        num_sentences = X.apply(lambda sentences : min(max_num_sents, len(sentences)))\n        num_sentences.name = 'Num_Sentences'\n        num_tokens = X.apply(lambda sentences : list(map(lambda s: min(max_sent_len, len(s)), sentences))[:max_num_sents])\n        num_tokens = num_tokens.apply(lambda num_ls : num_ls + [0 for _ in range(max_num_sents-len(num_ls))]) #padding\n        num_tokens.name = 'Num_Tokens'\n        \n        X_padded = np.zeros((len(X), max_num_sents, max_sent_len), dtype='int32')\n        for i, sentences in X.items():\n            for j, sent in enumerate(sentences):\n                if j >= max_num_sents:\n                    break\n                k = min(max_sent_len, len(sent))\n                X_padded[i,j,:k] = sent[:k]\n                \n        if self.num_classes == 4:\n            y = df['Label'].apply(lambda l: l-1)\n        else: #num_classes == 2\n            y = df['Label'].apply(lambda l: 0 if l<4 else 1)\n        return X_padded, pd.concat([y, num_sentences, num_tokens], axis=1)\n\nclass WrapperDatasetHcl(Dataset):\n    '''\n    Wrapper for use with dataloader\n    '''\n    def __init__(self, X, y_and_lens):\n        self.X = X\n        self.y = y_and_lens['Label']\n        self.num_sents = y_and_lens['Num_Sentences']\n        self.num_tokens = y_and_lens['Num_Tokens']\n    \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        return self.X[idx], self.y.iloc[idx], self.num_sents.iloc[idx],  self.num_tokens.iloc[idx]\n\ndef collate_fnHcl(batch):\n    X = []\n    y = []\n    num_sent = []\n    sent_len = []\n    for row in batch:\n        X.append(row[0])\n        y.append(row[1])\n        num_sent.append(row[2])\n        sent_len.append(row[3])\n    X = torch.tensor(X, dtype=torch.long)\n    y = torch.tensor(y, dtype=torch.long)\n    num_sent = torch.tensor(num_sent, dtype=torch.long)\n    sent_len = torch.tensor(sent_len, dtype=torch.long)\n    return X, y, num_sent, sent_len\n                 \n","metadata":{"execution":{"iopub.status.busy":"2024-04-09T16:54:37.827278Z","iopub.execute_input":"2024-04-09T16:54:37.827585Z","iopub.status.idle":"2024-04-09T16:54:37.851216Z","shell.execute_reply.started":"2024-04-09T16:54:37.827560Z","shell.execute_reply":"2024-04-09T16:54:37.850188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-09T11:45:10.901498Z","iopub.execute_input":"2024-04-09T11:45:10.902440Z","iopub.status.idle":"2024-04-09T11:45:10.908374Z","shell.execute_reply.started":"2024-04-09T11:45:10.902399Z","shell.execute_reply":"2024-04-09T11:45:10.907459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn.utils.rnn import pack_padded_sequence\nfrom torch.nn.utils.rnn import pad_packed_sequence\nfrom torch.nn.utils.rnn import PackedSequence\n\n\nclass BiLSTMHeAttClassifier(nn.Module):\n    '''\n    An implementation of the network described in: \n    https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf\n    \n    This implementation was made with heavy reference to:\n    https://github.com/JoungheeKim/Pytorch-Hierarchical-Attention-Network/blob/master/model.py\n    with some modifications.\n    '''\n\n    def __init__(self, vocab_len, embed_dim, hidden_dim, num_lstm_layers, num_classes,\n                 attn_dropout=0.0, pretrained_embeddings=None, freeze_embeds=True):\n        super(BiLSTMHeAttClassifier, self).__init__()\n        if pretrained_embeddings is not None:\n            self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=freeze_embeds)\n        else:\n            self.embedding = nn.Embedding(num_embeddings=vocab_len, embedding_dim=embed_dim)\n        \n        self.word_encoder = nn.LSTM(input_size=embed_dim, hidden_size=hidden_dim, num_layers=num_lstm_layers, batch_first=True, bidirectional=True)\n        self.word_attn = AttentionUnit(2*hidden_dim, 2*hidden_dim)\n        \n        self.sent_encoder = nn.LSTM(input_size=2*hidden_dim, hidden_size=hidden_dim, num_layers=num_lstm_layers, batch_first=True, bidirectional=True)\n        self.sent_attn = AttentionUnit(2*hidden_dim, 2*hidden_dim)\n        \n        self.output = nn.Linear(2*hidden_dim, num_classes)\n\n    def forward(self, X_batch, num_sents, sent_lens):\n        # Batch consists of several padded documents consisting of padded sentences\n    \n        ##### EMBEDDING PHASE #####\n        # Pack the padded documents --> each row in packed_docs.data is a padded sentence\n        packed_docs = pack_padded_sequence(X_batch, lengths=num_sents,\n                                           batch_first=True, enforce_sorted=False)\n        word_embs = self.embedding(packed_docs.data)\n        \n        ##### WORD LSTM+ATTENTION PHASE #####\n        # Pack the padded sentence lengths\n        packed_sent_lens = pack_padded_sequence(sent_lens, lengths=num_sents,\n                                                batch_first=True, enforce_sorted=False)\n        # Pack the padded sentences\n        packed_word_embs = pack_padded_sequence(word_embs, lengths=packed_sent_lens.data,\n                                                batch_first=True, enforce_sorted=False)\n        output, (_, _) = self.word_encoder(packed_word_embs)\n        output, _ = pad_packed_sequence(output, batch_first=True)\n        # Pass packed sentences of word hidden states through attention with masking\n        mask = self.__get_padding_masks(packed_sent_lens.data).to(output.device)\n        sent_embs, word_attn_weights = self.word_attn(output, mask)\n        ##### SENTENCE LSTM+ATTENTION PHASE #####\n        # sent_embs is already \"packed\"; need to input packing information for LSTM\n        packed_sent_embs = PackedSequence(data=sent_embs, \n                                          batch_sizes=packed_docs.batch_sizes,\n                                          sorted_indices=packed_docs.sorted_indices,\n                                          unsorted_indices=packed_docs.unsorted_indices)\n        output, (_, _) = self.sent_encoder(packed_sent_embs)\n        output, _ = pad_packed_sequence(output, batch_first=True)\n        # Pass (unpacked) batch of sentence hidden states through attention with masking\n        mask = self.__get_padding_masks(num_sents).to(output.device)\n        doc_embs, sent_attn_weights = self.sent_attn(output, mask)\n\n        return self.output(doc_embs), sent_attn_weights, word_attn_weights\n\n    def __get_padding_masks(self, lengths):\n        '''\n        Returns a mask (shape BxLx1) that indicates the position of pad tokens as True\n        '''\n        max_len = max(lengths)\n        return torch.tensor([[False]*i + [True]*(max_len-i) for i in lengths]).unsqueeze(2)\n\nclass AttentionUnit(nn.Module):\n\n    def __init__(self, input_size, hidden_size):\n        super(AttentionUnit, self).__init__()\n        self.hidden = nn.Linear(input_size, hidden_size)\n        self.query = nn.Linear(hidden_size, 1, bias=False)\n\n    def forward(self, encoder_output, mask=None):\n        #See steps in eqn 5,6,7 or 8,9,10 of the original paper\n        hidden_rep = self.hidden(encoder_output)\n        hidden_rep = F.tanh(hidden_rep)\n        \n        similarity = self.query(hidden_rep)\n        if mask is not None:\n            #Note: mask should indicate padding positions as True\n            # fill with -inf so that softmax gives 0 for the masked parts\n            similarity.masked_fill(mask, -float('inf'))\n        weights = F.softmax(similarity, 1)\n        \n        return torch.bmm(weights.transpose(1,2),encoder_output).squeeze(1), weights","metadata":{"execution":{"iopub.status.busy":"2024-04-09T11:41:18.927714Z","iopub.execute_input":"2024-04-09T11:41:18.928184Z","iopub.status.idle":"2024-04-09T11:41:18.949052Z","shell.execute_reply.started":"2024-04-09T11:41:18.928152Z","shell.execute_reply":"2024-04-09T11:41:18.948168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### OLD THINGS","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nbase='/kaggle/working/model/tryownHeAttBiLSTM_msl{}_mns{}_batch{}_embed{}hidden{}layers{}classes{}_ep{}lr{}wd{}_af{}ap{}_gloveclean_unfro_model{}.pt'\nfor i in [4,'_test','']:\n    for HIDDEN_DIM in [100]:\n        if HIDDEN_DIM == 50:\n            continue\n        path = base.format(MAX_SENT_LEN, MAX_NUM_SENTS, TRAIN_BATCH_SIZE, EMBED_DIM,HIDDEN_DIM,NUM_LSTM_LAYERS,NUM_CLASSES,NUM_EPOCHS,LEARNING_RATE,WEIGHT_DECAY,\n                                                    LR_ANNEAL_FACTOR, LR_ANNEAL_PATIENCE,i)\n        model = LSTMHeAttFCNNClassifier(VOCAB_SIZE,\n                                                            EMBED_DIM,\n                                                            HIDDEN_DIM,\n                                                            NUM_LSTM_LAYERS,\n                                                            NUM_CLASSES,\n                                                            pretrained_embeddings = embeds.to(torch.float32))\n        model.to(DEVICE)\n        model.load_state_dict(torch.load(path))\n        preds = []\n        truths = []\n        model.eval()\n        with torch.no_grad():\n            for X, y, num_sent, sent_len in test_loader:\n                #Move to correct device\n                X = X.to(DEVICE)\n\n                #Forward pass\n                outputs = model(X, num_sent, sent_len)\n                \n                #Logging\n                preds.append(torch.argmax(outputs, dim=-1).cpu())\n                truths.append(y)\n        preds = torch.cat(preds)\n        truths = torch.cat(truths)\n        records['path'].append(path)\n        records['acc'].append(accuracy_score(truths, preds))\n        records['f1'].append(f1_score(truths, preds, average='macro'))\n        records['precision'].append(precision_score(truths, preds, average='macro'))\n        records['recall'].append(recall_score(truths, preds, average='macro'))\n        print(i, HIDDEN_DIM)\n        print(classification_report(truths, preds))\n        #         except:\n        #             print(\"Skipped Epoch {}\".format(i))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-09T13:32:46.205917Z","iopub.execute_input":"2024-04-09T13:32:46.206617Z","iopub.status.idle":"2024-04-09T13:33:05.658769Z","shell.execute_reply.started":"2024-04-09T13:32:46.206586Z","shell.execute_reply":"2024-04-09T13:33:05.657755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pad_packed_sequence(packed_sent_embs, batch_first=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T07:03:10.606469Z","iopub.execute_input":"2024-04-09T07:03:10.607050Z","iopub.status.idle":"2024-04-09T07:03:10.621310Z","shell.execute_reply.started":"2024-04-09T07:03:10.607007Z","shell.execute_reply":"2024-04-09T07:03:10.618815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dp, embeds = DataPreprocessorFlat.from_pretrained_embeds(4, '/kaggle/input/lun-glove/glove.6B.100d.txt', 100, sep=\" \",  specials=['<unk>'])","metadata":{"execution":{"iopub.status.busy":"2024-04-09T17:10:09.049727Z","iopub.execute_input":"2024-04-09T17:10:09.050128Z","iopub.status.idle":"2024-04-09T17:10:16.795126Z","shell.execute_reply.started":"2024-04-09T17:10:09.050101Z","shell.execute_reply":"2024-04-09T17:10:16.794209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = dp.preprocess_data_flat(train_df, clean=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T17:10:16.796605Z","iopub.execute_input":"2024-04-09T17:10:16.797717Z","iopub.status.idle":"2024-04-09T17:14:27.482369Z","shell.execute_reply.started":"2024-04-09T17:10:16.797688Z","shell.execute_reply":"2024-04-09T17:14:27.480418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, y_test = dp.preprocess_data_flat(test_df, clean=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T17:16:52.695288Z","iopub.execute_input":"2024-04-09T17:16:52.695596Z","iopub.status.idle":"2024-04-09T17:17:06.940142Z","shell.execute_reply.started":"2024-04-09T17:16:52.695574Z","shell.execute_reply":"2024-04-09T17:17:06.939192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.to_csv('X_train_prep_flat.csv')\ny.to_csv('y_train_prep_flat.csv')\nX_test.to_csv('X_test_prep_flat.csv')\ny_test.to_csv('y_test_prep_flat.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-09T17:17:12.711757Z","iopub.execute_input":"2024-04-09T17:17:12.712455Z","iopub.status.idle":"2024-04-09T17:17:17.672831Z","shell.execute_reply.started":"2024-04-09T17:17:12.712419Z","shell.execute_reply":"2024-04-09T17:17:17.670591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dp2 = DataPreprocessorFlat.from_train_df(4, train_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T16:35:41.562228Z","iopub.execute_input":"2024-04-09T16:35:41.562788Z","iopub.status.idle":"2024-04-09T16:38:56.957336Z","shell.execute_reply.started":"2024-04-09T16:35:41.562740Z","shell.execute_reply":"2024-04-09T16:38:56.956153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"z = {**dp2.vocab.get_stoi(), **dp.vocab.get_stoi()}","metadata":{"execution":{"iopub.status.busy":"2024-04-09T16:41:04.946248Z","iopub.execute_input":"2024-04-09T16:41:04.946710Z","iopub.status.idle":"2024-04-09T16:41:06.132299Z","shell.execute_reply.started":"2024-04-09T16:41:04.946669Z","shell.execute_reply":"2024-04-09T16:41:06.130865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataPreprocessorFlat():\n\n    def __init__(self, num_classes, data_vocab):\n        self.num_classes = num_classes\n        self.vocab = data_vocab\n        print(\"Vocab created: {} unique tokens\".format(len(self.vocab)))\n        \n    @classmethod\n    def from_train_df(cls, num_classes, train_df, specials=['<unk>']):\n        data_vocab = build_vocab_from_iterator(cls.__yield_tokens(train_df), specials=specials)\n        data_vocab.set_default_index(data_vocab['<unk>'])\n        return cls(num_classes, data_vocab)\n    \n    @classmethod\n    def from_pretrained_embeds(cls, num_classes, embed_path, embed_dim, sep=\" \",  specials=['<unk>']):\n        # start with all '0's for special tokens\n        embeds = [np.asarray([0]*embed_dim, dtype=np.float32)]*len(specials)\n        words = OrderedDict()\n        with open(embed_path, encoding=\"utf-8\") as f:\n            for i, line in enumerate(f):\n                if i == 38522 and 'twitter.27B.100d' in embed_path:\n                    continue\n                splitline = line.split()\n                \n                word = splitline[0]\n                words[word] = 1\n                \n                embeds.append(np.asarray(splitline[1:], dtype=np.float32))\n                \n        embeds = torch.tensor(np.array(embeds))\n        data_vocab = vocab(words, min_freq=1, specials=specials)\n        data_vocab.set_default_index(data_vocab['<unk>'])\n        return cls(num_classes, data_vocab), embeds\n\n    @classmethod\n    def __yield_tokens(cls, df):\n        for row in df.itertuples(index=False):\n            yield word_tokenize(row.Text.replace(\"'\",\"\").lower())\n\n    def get_vocab_size(self):\n        return len(self.vocab)\n    \n    def preprocess_data_flat(self, df, clean=True):\n        '''\n        Converts text into integers that index the vocab,\n        and converts labels into the range [0,num_classes-1]\n        '''\n        if clean:\n            X = df['Text'].apply(lambda t: [self.vocab(word_tokenize(s.lower())) for s in sent_tokenize(t.replace(\"'\",\"\"))])\n            X = X.apply(lambda ls_of_ls: [token for ls in ls_of_ls for token in ls])\n        else:\n            X = df['Text'].apply(lambda t: self.vocab(word_tokenize(t)))\n\n        if self.num_classes == 4:\n            y = df['Label'].apply(lambda l: l-1)\n        else: #num_classes == 2\n            # assume test.xlsx\n            y = df['Label']\n        return X, y\n    \nclass WrapperDatasetFlat(Dataset):\n    '''\n    Wrapper for use with dataloader\n    '''\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n    \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        return self.X.iloc[idx], self.y.iloc[idx]\n                 \ndef make_flat_collate_function(model_max_len):\n    '''\n    Returns a function that pads and truncates sequences\n    in each batch up to min(batch's max length, model_max_len).\n    '''\n    def collate(batch):\n        '''\n        Returns the batch of padded sequences\n        and corresponding lengths and labels\n        '''\n        batch_max_len = max([len(tids) for tids, _ in batch])\n        output_len = min(model_max_len, batch_max_len)\n\n        X_padded = torch.zeros((len(batch), output_len), dtype=torch.long)\n        lengths = torch.empty((len(batch)), dtype=torch.long)\n        labels = torch.empty((len(batch)), dtype=torch.long)\n        for i, (tids, label) in enumerate(batch):\n            if len(tids) > output_len:\n                # sequence longer than output_len --> truncate\n                X_padded[i, :] = torch.tensor(tids[:output_len], dtype=torch.long)\n                lengths[i] = output_len\n            else:\n                # sequence shorter than output_len --> pad\n                X_padded[i, :len(tids)] = torch.tensor(tids, dtype=torch.long)\n                lengths[i] = len(tids)\n            labels[i] = label\n        return X_padded, lengths, labels\n                 \n    return collate\n\nclass FlatTrainer():\n    def __init__(self, model, train_loader, val_loader, num_epochs, lr, weight_decay = 0,\n               lr_anneal_factor=None, lr_anneal_patience=None,\n               loss_weights=None,\n               save_loss_acc_plots=True):\n        #Data\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n\n        #Model\n        self.model=model.to(DEVICE)\n\n        #Training\n        self.num_epochs = num_epochs\n        self.loss_fn = nn.CrossEntropyLoss()\n        if loss_weights is not None:\n            self.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(loss_weights, dtype=torch.float32, device=DEVICE))\n        self.optimizer = Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n        self.to_anneal_lr = lr_anneal_factor and lr_anneal_patience\n        if self.to_anneal_lr:\n            self.scheduler = ReduceLROnPlateau(self.optimizer,\n                                             factor=lr_anneal_factor,\n                                             patience=lr_anneal_patience)\n\n    def train(self, save_folder_root_path, file_name_root,\n            plot_loss_acc=True, verbose=True, test_loader=None):\n        #account for earlier version\n        self.scheduler.verbose=verbose\n        #Set up logging\n        self.model_folder = save_folder_root_path+'model/'\n        self.plots_folder = save_folder_root_path+'plots/'\n        self.file_name_root = file_name_root\n        self.plot_loss_acc = plot_loss_acc\n        if not os.path.exists(self.model_folder):\n            os.makedirs(self.model_folder)\n        if self.plot_loss_acc and not os.path.exists(self.plots_folder):\n            os.makedirs(self.plots_folder)\n        self.train_metrics = {'loss':[], 'accuracy':[], 'f1':[]}\n        self.val_metrics = {'loss':[], 'accuracy':[], 'f1':[]}\n        if test_loader is not None:\n            self.test_metrics = {'loss':[], 'accuracy':[], 'f1':[]}\n            best_test_loss = float('inf')\n        best_val_loss = float('inf')\n        for i in range(1, self.num_epochs+1):\n            self.model.train()\n            train_loss = []\n            preds = []\n            truths = []\n            for X, lengths, y in tqdm(self.train_loader, disable = not verbose):\n                #Move to correct device\n                X = X.to(DEVICE)\n                y = y.to(DEVICE)\n\n                #Forward pass\n                outputs = self.model(X, lengths)\n                if type(outputs)==tuple:\n                    logits = outputs[0]\n                else:\n                    logits = outputs\n                loss = self.loss_fn(logits, y)\n\n                #Backprop\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n\n                #Logging\n                train_loss.append(loss.item())\n                preds.append(torch.argmax(logits, dim=-1).cpu())\n                truths.append(y.cpu())\n\n            #Validation\n            self.model.eval()\n            val_loss, val_acc, val_f1 = self.validate()\n\n            #Logging\n            train_loss = sum(train_loss)/len(train_loss)\n            preds = torch.cat(preds)\n            truths = torch.cat(truths)\n            train_acc = accuracy_score(truths, preds)\n            train_f1 = f1_score(truths, preds, average='macro')\n\n            self.train_metrics['loss'].append(train_loss)\n            self.train_metrics['accuracy'].append(train_acc)\n            self.train_metrics['f1'].append(train_f1)\n            self.val_metrics['loss'].append(val_loss)\n            self.val_metrics['accuracy'].append(val_acc)\n            self.val_metrics['f1'].append(val_f1)\n            if test_loader is not None:\n                test_loss, test_acc, test_f1 = self.validate(test_loader)\n                self.test_metrics['loss'].append(test_loss)\n                self.test_metrics['accuracy'].append(test_acc)\n                self.test_metrics['f1'].append(test_f1)\n            if verbose:\n                if test_loader is not None:\n                    tqdm.write(\"Epoch {} Complete:\\n Train: loss={}, acc={}, F1={}\\n Val  : loss={}, acc={}, F1={}\\n Test  :acc={}, F1={}\".format(\n                                i, train_loss, train_acc, train_f1, val_loss, val_acc, val_f1, test_acc, test_f1))\n                else:\n                    tqdm.write(\"Epoch {} Complete:\\n Train: loss={}, acc={}, F1={}\\n Val  : loss={}, acc={}, F1={}\\n\".format(\n                                i, train_loss, train_acc, train_f1, val_loss, val_acc, val_f1))\n            #Save model\n            if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                torch.save(self.model.state_dict(),\n                           self.model_folder + file_name_root + '_model.pt')\n                \n            torch.save(self.model.state_dict(),\n                       self.model_folder + file_name_root + '_model{}.pt'.format(i))\n\n            if test_loader is not None and test_loss <= best_test_loss:\n                best_test_loss = test_loss\n                torch.save(self.model.state_dict(),\n                           self.model_folder + file_name_root + '_model_test{}.pt'.format(i))\n            #LR Annealing\n            if self.to_anneal_lr:\n                self.scheduler.step(val_loss)\n        #Save plots\n        if self.plot_loss_acc:\n            self.plot_metrics(self.train_metrics, self.val_metrics)\n\n        return self.model_folder + file_name_root + '_model.pt', self.model_folder + file_name_root + 'plot.pt'\n\n    def validate(self, test_loader=None):\n        with torch.no_grad():\n            losses = []\n            preds = []\n            truths = []\n            val_loader = self.val_loader if test_loader is None else test_loader\n            for X, lengths, y in val_loader:\n                #Move to correct device\n                X = X.to(DEVICE)\n                y = y.to(DEVICE)\n\n                #Forward pass\n                outputs = self.model(X, lengths)\n                \n                if type(outputs)==tuple:\n                    logits = outputs[0]\n                else:\n                    logits = outputs\n                loss = self.loss_fn(logits, y)\n\n                #Logging\n                losses.append(loss.item())\n                preds.append(torch.argmax(logits, dim=-1).cpu())\n                truths.append(y.cpu())\n        preds = torch.cat(preds)\n        truths = torch.cat(truths)\n        return sum(losses)/len(losses), accuracy_score(truths, preds), f1_score(truths, preds, average='macro')\n\n    def plot_metrics(self, train_metrics, val_metrics):\n        fig, axs = plt.subplots(1, 3, figsize=(15,5))\n        axs[0].plot(range(1, self.num_epochs + 1), train_metrics['loss'], color='b', label='Train')\n        axs[0].plot(range(1, self.num_epochs + 1), val_metrics['loss'], color='r', label='Validation')\n        axs[0].set_ylabel('Loss')\n        axs[0].set_xlabel('Epochs')\n        axs[0].set_ylim(bottom=0)\n        axs[0].set_xticks(range(0, self.num_epochs + 1, 2))\n        axs[0].grid(visible=True, which='major', axis='both')\n\n        axs[1].plot(range(1, self.num_epochs + 1), train_metrics['accuracy'], color='b', label='Train')\n        axs[1].plot(range(1, self.num_epochs + 1), val_metrics['accuracy'], color='r', label='Validation')\n        axs[1].set_ylabel('Accuracy')\n        axs[1].set_xlabel('Epochs')\n        axs[1].set_ylim(bottom=0)\n        axs[1].set_xticks(range(0, self.num_epochs + 1, 2))\n        axs[1].grid(visible=True, which='major', axis='both')\n\n        axs[2].plot(range(1, self.num_epochs + 1), train_metrics['f1'], color='b', label='Train')\n        axs[2].plot(range(1, self.num_epochs + 1), val_metrics['f1'], color='r', label='Validation')\n        axs[2].set_ylabel('F1 (Macro-averaged)')\n        axs[2].set_xlabel('Epochs')\n        axs[2].set_ylim(bottom=0)\n        axs[2].set_xticks(range(0, self.num_epochs + 1, 2))\n        axs[2].grid(visible=True, which='major', axis='both')\n\n        fig.legend(*axs[2].get_legend_handles_labels(), loc='upper center')\n        fig.savefig(self.plots_folder + self.file_name_root + '_plot.png')\n        plt.show()\n        plt.close()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:35:38.804194Z","iopub.execute_input":"2024-04-17T06:35:38.804920Z","iopub.status.idle":"2024-04-17T06:35:38.881910Z","shell.execute_reply.started":"2024-04-17T06:35:38.804883Z","shell.execute_reply":"2024-04-17T06:35:38.880392Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class AttentionUnit(nn.Module):\n    def __init__(self, input_dim, hidden_dim=None, num_outputs=1, attn_dropout=0.0):\n        super(AttentionUnit, self).__init__()\n        if hidden_dim is None:\n            hidden_dim = input_dim\n        self.hidden = nn.Linear(input_dim, hidden_dim)\n        self.query = nn.Linear(hidden_dim, num_outputs, bias=False)\n    def forward(self, encoder_output, padding_positions=None, return_weights=False):\n        #Calculate u_{i} = tanh(Wh_{i}+b) [B,L,H]-->[B,L,H]\n        hidden_rep = F.tanh(self.hidden(encoder_output))\n        #Calculate a_{i} = softmax(u_{i}^Tc) with masking [B,L,H]-->[B,L,1]\n        similarity = self.query(hidden_rep)\n        if padding_positions is not None:\n            similarity = similarity.masked_fill(padding_positions, -float('inf'))\n        attention_weights = F.softmax(similarity, dim=1)\n        #Return weighted sum [B,L,1], [B,L,H]-->[B,H]\n        if return_weights:\n            return torch.bmm(attention_weights.transpose(1,2), hidden_rep).squeeze(1), attention_weights\n        return torch.bmm(attention_weights.transpose(1,2), hidden_rep).squeeze(1)\n\nclass LSTMFlatAttentionFCNNClassifier(torch.nn.Module):\n    '''\n    Classifier that uses an LSTM as an encoder followed by an attention block\n    and a Fully-Connected Neural Network(FCNN) as a decoder.\n    '''\n    def __init__(self, vocab_len, embed_dim, hidden_dim, num_lstm_layers, num_classes, attn_dropout=0.0, pretrained_embeddings=None, freeze_embeds=False):\n        super(LSTMFlatAttentionFCNNClassifier, self).__init__()\n        if pretrained_embeddings is not None:\n            self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=freeze_embeds)\n        else:\n            self.embedding = nn.Embedding(num_embeddings=vocab_len, embedding_dim=embed_dim)\n\n        self.encoder = nn.LSTM(input_size=embed_dim, hidden_size=hidden_dim, num_layers=num_lstm_layers, batch_first=True, bidirectional=True)\n        self.attn = AttentionUnit(2*hidden_dim)\n        self.decoder = nn.Linear(2*hidden_dim, num_classes)\n\n    def forward(self, X_batch, lengths, return_attn_weights=False):\n        embeddings = self.embedding(X_batch)\n\n        embeddings = nn.utils.rnn.pack_padded_sequence(embeddings, lengths.cpu(), enforce_sorted=False, batch_first=True)\n        output, (_, _) = self.encoder(embeddings)\n        output, _ = nn.utils.rnn.pad_packed_sequence(output,batch_first=True)\n\n        padding_positions = self.__get_padding_masks(lengths).to(output.device)\n        doc_embeddings = self.attn(output,padding_positions=padding_positions,return_weights=return_attn_weights)\n        \n        if return_attn_weights:\n            return self.decoder(doc_embeddings[0]), doc_embeddings[1]\n        else:\n            return self.decoder(doc_embeddings)\n    \n    def __get_padding_masks(self, lengths):\n        '''\n        Returns a mask (shape BxLx1) that indicates the position of pad tokens\n        '''\n        max_len = lengths.max()\n        return torch.tensor([[False]*i + [True]*(max_len-i) for i in lengths]).unsqueeze(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T06:27:38.102256Z","iopub.execute_input":"2024-04-16T06:27:38.102690Z","iopub.status.idle":"2024-04-16T06:27:38.122977Z","shell.execute_reply.started":"2024-04-16T06:27:38.102656Z","shell.execute_reply":"2024-04-16T06:27:38.121655Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/lun-glove/fulltrain.csv', header=None, names=['Label','Text'])\ntest_df = pd.read_excel('/kaggle/input/lun-glove/test.xlsx')","metadata":{"execution":{"iopub.status.busy":"2024-04-10T07:11:34.250646Z","iopub.execute_input":"2024-04-10T07:11:34.250908Z","iopub.status.idle":"2024-04-10T07:11:35.712153Z","shell.execute_reply.started":"2024-04-10T07:11:34.250885Z","shell.execute_reply":"2024-04-10T07:11:35.711121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flatdp, embs = DataPreprocessorFlat.from_pretrained_embeds(4, '/kaggle/input/lun-glove/glove.6B.100d.txt', 100)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T07:11:21.629885Z","iopub.execute_input":"2024-04-10T07:11:21.630249Z","iopub.status.idle":"2024-04-10T07:11:34.248841Z","shell.execute_reply.started":"2024-04-10T07:11:21.630221Z","shell.execute_reply":"2024-04-10T07:11:34.247855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X, y =flatdp.preprocess_data_flat(train_df)\n# X_test, y_test = flatdp.preprocess_data_flat(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T06:52:45.631985Z","iopub.execute_input":"2024-04-10T06:52:45.632364Z","iopub.status.idle":"2024-04-10T06:59:53.274518Z","shell.execute_reply.started":"2024-04-10T06:52:45.632335Z","shell.execute_reply":"2024-04-10T06:59:53.273677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pd.read_parquet('/kaggle/input/lun-preprocessed-for-heatt/forFlatGlove6b100d/X_train_prep_flat.parquet')['Text']\ny = pd.read_parquet('/kaggle/input/lun-preprocessed-for-heatt/forFlatGlove6b100d/y_train_prep_flat.parquet')['Label']\nX_test = pd.read_parquet('/kaggle/input/lun-preprocessed-for-heatt/forFlatGlove6b100d/X_test_prep_flat.parquet')['Text']\ny_test = pd.read_parquet('/kaggle/input/lun-preprocessed-for-heatt/forFlatGlove6b100d/y_test_prep_flat.parquet')['Label']\nembeds = torch.tensor(np.load('/kaggle/input/lun-glove/glove_embs.npy'))\nVOCAB_SIZE = 400001\n\ny\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T06:27:41.804614Z","iopub.execute_input":"2024-04-16T06:27:41.805539Z","iopub.status.idle":"2024-04-16T06:27:45.992195Z","shell.execute_reply.started":"2024-04-16T06:27:41.805504Z","shell.execute_reply":"2024-04-16T06:27:45.990980Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2024-04-10T07:14:17.460828Z","iopub.execute_input":"2024-04-10T07:14:17.461879Z","iopub.status.idle":"2024-04-10T07:14:17.468485Z","shell.execute_reply.started":"2024-04-10T07:14:17.461824Z","shell.execute_reply":"2024-04-10T07:14:17.467402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_CLASSES = 4\nTRAIN_BATCH_SIZE = 256\nVALID_BATCH_SIZE = 512\nMODEL_MAX_LEN = 500\ncollate_flat = make_flat_collate_function(MODEL_MAX_LEN)\ntrain_loader = DataLoader(WrapperDatasetFlat(X_train, y_train),\n                          batch_size=TRAIN_BATCH_SIZE,\n                          collate_fn=collate_flat,\n                          shuffle=True)\n\nval_loader = DataLoader(WrapperDatasetFlat(X_val, y_val),\n                          batch_size=VALID_BATCH_SIZE,\n                          collate_fn=collate_flat,\n                          shuffle=False)\n\ntest_loader = DataLoader(WrapperDatasetFlat(X_test, y_test),\n                          batch_size=VALID_BATCH_SIZE,\n                          collate_fn=collate_flat,\n                          shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T06:27:45.994363Z","iopub.execute_input":"2024-04-16T06:27:45.994720Z","iopub.status.idle":"2024-04-16T06:27:46.002860Z","shell.execute_reply.started":"2024-04-16T06:27:45.994691Z","shell.execute_reply":"2024-04-16T06:27:46.001962Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nembed_dim_space = [100]\nhidden_dim_space = [100]\nnum_lstm_layers_space = [1]\n\nnum_epochs_space = [10]\nlr_space = [5e-04]\nwd_space = [5e-06]\nfactor_space = [0.5]\npatience_space = [2]\n\nRANDOM_SEED = 42\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nSAVE_FOLDER_PATH=\"/kaggle/working/\"\nFILES_NAME_FORMAT=\"FlatAttBiLSTM_maxlen{}_batch{}_emb{}hid{}lay{}cla{}_ep{}lr{}wd{}_af{}ap{}_gloveclean_unfro\"\n\nrecords = {\"path\": [], \"precision\":[], \"recall\": [], \"f1\": [], \"acc\":[]}\ncheckpoint = 0\n\nfor NUM_EPOCHS in num_epochs_space:\n    for WEIGHT_DECAY in wd_space:\n        for LR_ANNEAL_FACTOR in factor_space:\n            for LR_ANNEAL_PATIENCE in patience_space:\n                for LOSS_WEIGHTS in [None]:\n                    for NUM_LSTM_LAYERS in num_lstm_layers_space:\n#                         LOSS_WEIGHT_STRING = 'Weighted' if LOSS_WEIGHTS else 'Unweighted'\n                        for HIDDEN_DIM in hidden_dim_space:\n                            for EMBED_DIM in embed_dim_space:\n                                for LEARNING_RATE in lr_space:\n                                    torch.manual_seed(RANDOM_SEED)\n                                    model = LSTMFlatAttentionFCNNClassifier(VOCAB_SIZE,\n                                                                  EMBED_DIM,\n                                                                  HIDDEN_DIM,\n                                                                  NUM_LSTM_LAYERS,\n                                                                  NUM_CLASSES,\n                                                                  pretrained_embeddings = embeds.to(torch.float32))\n                                    trainer = FlatTrainer(model, train_loader, val_loader,\n                                                      NUM_EPOCHS, LEARNING_RATE,\n                                                      weight_decay=WEIGHT_DECAY,\n                                                      lr_anneal_factor=LR_ANNEAL_FACTOR,\n                                                      lr_anneal_patience=LR_ANNEAL_PATIENCE,\n                                                      loss_weights=LOSS_WEIGHTS,\n                                                      save_loss_acc_plots=True)\n                                    model_path, _ = trainer.train(SAVE_FOLDER_PATH,\n                                                  FILES_NAME_FORMAT.format(MODEL_MAX_LEN, TRAIN_BATCH_SIZE, EMBED_DIM,\n                                                                           HIDDEN_DIM, NUM_LSTM_LAYERS, NUM_CLASSES,\n                                                                          NUM_EPOCHS, LEARNING_RATE, WEIGHT_DECAY,\n                                                                          LR_ANNEAL_FACTOR, LR_ANNEAL_PATIENCE),\n                                                  verbose=checkpoint<2,\n                                                                 test_loader=test_loader)\n\n                                    model.load_state_dict(torch.load(model_path))\n                                    preds = []\n                                    truths = []\n                                    model.eval()\n                                    with torch.no_grad():\n                                        for X, lengths, y in test_loader:\n                                            #Move to correct device\n                                            X = X.to(DEVICE)\n\n                                            #Forward pass\n                                            outputs = model(X, lengths)\n                                            logits = outputs[0] if type(outputs)==tuple else outputs\n                                            #Logging\n                                            preds.append(torch.argmax(logits, dim=-1).cpu())\n                                            truths.append(y)\n                                    preds = torch.cat(preds)\n                                    truths = torch.cat(truths)\n                                    records['path'].append(model_path)\n                                    records['acc'].append(accuracy_score(truths, preds))\n                                    records['f1'].append(f1_score(truths, preds, average='macro'))\n                                    records['precision'].append(precision_score(truths, preds, average='macro'))\n                                    records['recall'].append(recall_score(truths, preds, average='macro'))\n                                    if checkpoint < 2:\n                                        print(records)\n                                    checkpoint = checkpoint + 1\n                                    if checkpoint % 3 == 0:\n                                        print(records)\n                                        pd.DataFrame(records).to_csv(SAVE_FOLDER_PATH + 'tuning_metrics.csv')\n\npd.DataFrame(records).to_csv(SAVE_FOLDER_PATH + 'final_tuning_metrics.csv')\nprint(\"======================All done======================\")\nprint(records)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T16:24:41.685706Z","iopub.execute_input":"2024-04-14T16:24:41.686091Z","iopub.status.idle":"2024-04-14T16:46:47.380480Z","shell.execute_reply.started":"2024-04-14T16:24:41.686060Z","shell.execute_reply":"2024-04-14T16:46:47.379439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-09T18:37:41.090620Z","iopub.execute_input":"2024-04-09T18:37:41.090995Z","iopub.status.idle":"2024-04-09T18:37:41.516044Z","shell.execute_reply.started":"2024-04-09T18:37:41.090965Z","shell.execute_reply":"2024-04-09T18:37:41.515170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\nbase=\"/kaggle/input/bilstmheattnewsclassifier/pytorch/flat_best_performing/1/FlatAttBiLSTM_gloveunfro_clean_ml500_batch256_emb100hid100lay1cla4_ep20lr0.0005wd5e-06_af0.5ap2.pt\"\nrecords = {'split':[], 'acc':[],'f1':[],'precision':[], 'recall':[]}\nfor i, loader in enumerate([test_loader]):\n        model = LSTMFlatAttentionFCNNClassifier(VOCAB_SIZE,\n                                                            100,\n                                        100,\n                                                            1,\n                                                            4,\n                                                            pretrained_embeddings = embeds.to(torch.float32))\n        model.to('cpu')\n        model.load_state_dict(torch.load(base, map_location='cpu'))\n        preds = []\n        truths = []\n        model.eval()\n        with torch.no_grad():\n            for X, lengths, y in loader:\n                #Move to correct device\n                X = X.to('cpu')\n\n                #Forward pass\n                outputs = model(X, lengths)\n\n                #Logging\n                preds.append(torch.argmax(outputs, dim=-1).cpu())\n                truths.append(y)\n        preds = torch.cat(preds)\n        truths = torch.cat(truths)\n        records['split'].append('train' if i==0 else 'val' if i==1 else 'test')\n        records['acc'].append(accuracy_score(truths, preds))\n        records['f1'].append(f1_score(truths, preds, average='macro'))\n        records['precision'].append(precision_score(truths, preds, average='macro'))\n        records['recall'].append(recall_score(truths, preds, average='macro'))\n        if i == 0:\n#             print(\"TRAINING DATA\")\n#         elif i == 1:\n#             print(\"VALIDATION DATA\")\n#         elif i == 2:\n            print(\"TEST DATA\")\n        print(classification_report(truths, preds))\n        #         except:\n        #             print(\"Skipped Epoch {}\".format(i))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T06:28:59.546290Z","iopub.execute_input":"2024-04-16T06:28:59.546937Z","iopub.status.idle":"2024-04-16T06:29:13.774799Z","shell.execute_reply.started":"2024-04-16T06:28:59.546884Z","shell.execute_reply":"2024-04-16T06:29:13.773564Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"TEST DATA\n              precision    recall  f1-score   support\n\n           0       0.92      0.73      0.81       750\n           1       0.78      0.46      0.58       750\n           2       0.58      0.72      0.64       750\n           3       0.67      0.93      0.78       750\n\n    accuracy                           0.71      3000\n   macro avg       0.74      0.71      0.70      3000\nweighted avg       0.74      0.71      0.70      3000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(records)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:56:35.380845Z","iopub.execute_input":"2024-04-14T15:56:35.381305Z","iopub.status.idle":"2024-04-14T15:56:35.397136Z","shell.execute_reply.started":"2024-04-14T15:56:35.381273Z","shell.execute_reply":"2024-04-14T15:56:35.395887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LSTM Baseline","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/lun-glove/fulltrain.csv',header=None, names=['Label', 'Text'])\ntest_df = pd.read_csv('/kaggle/input/lun-glove/balancedtest.csv',header=None, names=['Label', 'Text'])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T11:16:08.940501Z","iopub.execute_input":"2024-04-17T11:16:08.941022Z","iopub.status.idle":"2024-04-17T11:16:12.283747Z","shell.execute_reply.started":"2024-04-17T11:16:08.940982Z","shell.execute_reply":"2024-04-17T11:16:12.282262Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"for d in train_df['Text']:\n    print(d)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:00:49.727547Z","iopub.execute_input":"2024-04-13T08:00:49.728156Z","iopub.status.idle":"2024-04-13T08:00:49.735802Z","shell.execute_reply.started":"2024-04-13T08:00:49.728124Z","shell.execute_reply":"2024-04-13T08:00:49.734513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_hits = set()\ntrain_misses = set()\ntrain_dict ={'hits':0, 'misses':0}\ntest_hits = set()\ntest_misses = set()\ntest_dict = {'hits':0, 'misses':0}\n\nfor d in train_df['Text']:\n    for s in sent_tokenize(d.replace(\"'\", \"\")):\n        for t in word_tokenize(s.lower()):\n            if t in vocab:\n                train_dict['hits'] += 1\n                train_hits.add(t)\n            else:\n                train_dict['misses'] += 1\n                train_misses.add(t)\n\nfor d in test_df['Text']:\n    for s in sent_tokenize(d.replace(\"'\", \"\")):\n        for t in word_tokenize(s.lower()):\n            if t in vocab:\n                test_dict['hits'] += 1\n                test_hits.add(t)\n            else:\n                test_dict['misses'] += 1\n                test_misses.add(t)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:13:52.404982Z","iopub.execute_input":"2024-04-13T08:13:52.405491Z","iopub.status.idle":"2024-04-13T08:22:40.880744Z","shell.execute_reply.started":"2024-04-13T08:13:52.405455Z","shell.execute_reply":"2024-04-13T08:22:40.879214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(\"Training Data only:\")\nprint(\"Total words   :\", train_dict['hits'] + train_dict['misses'])\nprint(\"Total hits    :\", train_dict['hits'])\nprint(\"Total missess :\", train_dict['misses'])\nprint(\"Total unique words   :\", len(train_hits) + len(train_misses))\nprint(\"Total unique hits    :\", len(train_hits))\nprint(\"Total unique missess :\", len(train_misses))\nprint()\nprint(\"Test Data only:\")\nprint(\"Total words   :\", test_dict['hits'] + test_dict['misses'])\nprint(\"Total hits    :\", test_dict['hits'])\nprint(\"Total missess :\", test_dict['misses'])\nprint(\"Total unique words   :\", len(test_hits) + len(test_misses))\nprint(\"Total unique hits    :\", len(test_hits))\nprint(\"Total unique missess :\", len(test_misses))\nprint()\n\nprint(\"Altogether:\")\nprint(\"Total words   :\", train_dict['hits'] + train_dict['misses'] + test_dict['hits'] + test_dict['misses'])\nprint(\"Total hits    :\", train_dict['hits'] + test_dict['hits'])\nprint(\"Total missess :\", train_dict['misses'] + test_dict['misses'])\nall_unique_hits = train_hits.union(test_hits)\nall_unique_misses = train_misses.union(test_misses)\nprint(\"Total unique words   :\", len(all_unique_hits) + len(all_unique_misses))\nprint(\"Total unique hits    :\", len(all_unique_hits))\nprint(\"Total unique missess :\", len(all_unique_misses))","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:22:40.883359Z","iopub.execute_input":"2024-04-13T08:22:40.884593Z","iopub.status.idle":"2024-04-13T08:22:40.930239Z","shell.execute_reply.started":"2024-04-13T08:22:40.884550Z","shell.execute_reply":"2024-04-13T08:22:40.928907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dp, _ = DataPreprocessorHcl.from_pretrained_embeds(4, '/kaggle/input/lun-glove/glove.6B.100d.txt', 100)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T07:59:16.123352Z","iopub.execute_input":"2024-04-13T07:59:16.123830Z","iopub.status.idle":"2024-04-13T07:59:32.055042Z","shell.execute_reply.started":"2024-04-13T07:59:16.123795Z","shell.execute_reply":"2024-04-13T07:59:32.053529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab = dp.vocab.get_stoi()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T07:59:51.169991Z","iopub.execute_input":"2024-04-13T07:59:51.170381Z","iopub.status.idle":"2024-04-13T07:59:51.807726Z","shell.execute_reply.started":"2024-04-13T07:59:51.170351Z","shell.execute_reply":"2024-04-13T07:59:51.806075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. HAN Analysis","metadata":{}},{"cell_type":"markdown","source":"This notebook corresponds to the discussion section of the report. First, define the model:","metadata":{}},{"cell_type":"code","source":"class AttentionUnit(nn.Module):\n    def __init__(self, input_dim, hidden_dim=None, num_outputs=1, attn_dropout=0.0):\n        super(AttentionUnit, self).__init__()\n        if hidden_dim is None:\n            hidden_dim = input_dim\n        self.hidden = nn.Linear(input_dim, hidden_dim)\n        self.query = nn.Linear(hidden_dim, num_outputs, bias=False)\n        \n    def forward(self, encoder_output, padding_positions=None, return_weights=False):\n        # [B,L,I]-->[B,L,H]\n        hidden_rep = F.tanh(self.hidden(encoder_output))\n        \n        # [B,L,H]-->[B,L,1]\n        similarity = self.query(hidden_rep)\n        if padding_positions is not None:\n            similarity = similarity.masked_fill(padding_positions, -float('inf'))\n        attention_weights = F.softmax(similarity, dim=1)\n        \n        #Return weighted sum [B,L,1], [B,L,H]-->[B,H]\n        if return_weights:\n            return torch.bmm(attention_weights.transpose(1,2), hidden_rep).squeeze(1), attention_weights\n        return torch.bmm(attention_weights.transpose(1,2), hidden_rep).squeeze(1)\n\nclass BiLSTMHeAttFCNNClassifier(nn.Module):\n    '''\n    Classifier that uses heirarchical attention to encode a document and \n    a Fully-Connected Neural Network(FCNN) as a decoder.\n\n    '''\n    def __init__(self, vocab_len, embed_dim, hidden_dim, num_lstm_layers, num_classes, attn_dropout=0.0, pretrained_embeddings=None, freeze_embeds=False):\n        super(BiLSTMHeAttFCNNClassifier, self).__init__()\n        if pretrained_embeddings is not None:\n            self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=freeze_embeds)\n        else:\n            self.embedding = nn.Embedding(num_embeddings=vocab_len, embedding_dim=embed_dim)\n        \n        self.word_encoder = nn.LSTM(input_size=embed_dim, hidden_size=hidden_dim, num_layers=num_lstm_layers, batch_first=True, bidirectional=True)\n        self.word_attn = AttentionUnit(2*hidden_dim)\n        \n        self.sent_encoder = nn.LSTM(input_size=2*hidden_dim, hidden_size=hidden_dim, num_layers=num_lstm_layers, batch_first=True, bidirectional=True)\n        self.sent_attn = AttentionUnit(2*hidden_dim)\n        \n        self.decoder = nn.Linear(2*hidden_dim, num_classes)\n\n\n    def forward(self, X_batch, num_sents, sent_lens, return_attn_weights=False):\n        '''\n        Returns logits if return_attn_weights is False,\n        else returns (logits, word-level attention weights, sentence-level attention weights)\n        '''\n        max_sent_len = X_batch.shape[2]\n        max_num_sent = X_batch.shape[1]\n        \n        # Use word embeddings to form sentence embeddings\n        word_attn_weights = []\n        docs = []\n        for doc, n, lens in zip(X_batch, num_sents, sent_lens):\n            words_batch = doc[:n]\n            embeddings = self.embedding(words_batch)\n            output, (_, _) = self.word_encoder(embeddings)\n            padding_positions = self.__get_padding_masks(lens[:n], max_sent_len).to(output.device)\n            sent_embeddings = self.word_attn(output, padding_positions=padding_positions, return_weights=return_attn_weights)\n            if return_attn_weights:\n                word_attn_weights.append(sent_embeddings[1])\n                sent_embeddings = sent_embeddings[0]\n            sent_embeddings = self.__repad_sentence_embeddings(sent_embeddings, max_num_sent)\n            docs.append(sent_embeddings)\n        \n        # Use sentence embeddings to form document embedding\n        sent_embeddings_batch = torch.stack(docs) \n        output, (_, _) = self.sent_encoder(sent_embeddings_batch)\n        padding_positions = self.__get_padding_masks(num_sents, max_num_sent).to(output.device)\n        doc_embeddings = self.word_attn(output, padding_positions=padding_positions, return_weights=return_attn_weights)\n        # Pass document embedding through output layer\n        if return_attn_weights:\n            return self.decoder(doc_embeddings[0]), word_attn_weights, doc_embeddings[1]\n        else:\n            return self.decoder(doc_embeddings)\n        \n    def __repad_sentence_embeddings(self, sents, max_num_sent):\n        return torch.cat([sents,\n                          torch.zeros((max_num_sent-sents.shape[0], \n                                       sents.shape[1]), device=sents.device)],dim=0)\n    \n    def __get_padding_masks(self, lengths, max_len):\n        '''\n        Returns a mask (shape BxLx1) that indicates the position of pad tokens as '1's\n        '''\n        return torch.tensor([[False]*i + [True]*(max_len-i) for i in lengths]).unsqueeze(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T11:13:59.299797Z","iopub.execute_input":"2024-04-17T11:13:59.300626Z","iopub.status.idle":"2024-04-17T11:13:59.332230Z","shell.execute_reply.started":"2024-04-17T11:13:59.300581Z","shell.execute_reply":"2024-04-17T11:13:59.330338Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## 1. Categorized evals","metadata":{}},{"cell_type":"markdown","source":"Set hyperparameters and load model","metadata":{}},{"cell_type":"code","source":"MAX_SENT_LEN = 30\nMAX_NUM_SENTS = 30\nNUM_CLASSES = 4\nEMBED_DIM = 100\nHIDDEN_DIM = 100\nNUM_LSTM_LAYERS = 1\n\nVOCAB_LEN = 400001 #harcoded for convenience; see below for how it was obtained\n# glove, _ = DataPreprocessorHcl.from_pretrained_embeds(NUM_CLASSES,'/kaggle/input/lun-glove/glove.6B.100d.txt', EMBED_DIM)\n# VOCAB_LEN = len(glove.vocab)\n\nMODEL_PATH = './outputs/model/bestHAN_msl30_mns30_ba256_emb100hid100lay1cla4_ep10lr0.0005wd5e-06_af0.5_ap2_model.pt'\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = BiLSTMHeAttFCNNClassifier(VOCAB_LEN, EMBED_DIM, HIDDEN_DIM, NUM_LSTM_LAYERS, NUM_CLASSES)\nmodel.to(DEVICE)\nmodel.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))","metadata":{"execution":{"iopub.status.busy":"2024-04-17T11:13:59.335016Z","iopub.execute_input":"2024-04-17T11:13:59.335563Z","iopub.status.idle":"2024-04-17T11:14:03.804449Z","shell.execute_reply.started":"2024-04-17T11:13:59.335522Z","shell.execute_reply":"2024-04-17T11:14:03.802749Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"Load Preprocessed test data and sub-categorized test data","metadata":{"execution":{"iopub.status.busy":"2024-04-11T12:15:02.320834Z","iopub.execute_input":"2024-04-11T12:15:02.321256Z","iopub.status.idle":"2024-04-11T12:15:04.003140Z","shell.execute_reply.started":"2024-04-11T12:15:02.321225Z","shell.execute_reply":"2024-04-11T12:15:04.002122Z"}}},{"cell_type":"code","source":"X_hier_test = np.load('./HAN_prepro_data/X_test_prep.npy')\nylens_test = pd.read_csv('./HAN_prepro_data/ylens_test_prep.csv')\nimport ast\nylens_test['Num_Tokens'] = ylens_test['Num_Tokens'].apply(ast.literal_eval)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:09:24.706770Z","iopub.execute_input":"2024-04-17T07:09:24.707200Z","iopub.status.idle":"2024-04-17T07:09:25.041161Z","shell.execute_reply.started":"2024-04-17T07:09:24.707168Z","shell.execute_reply":"2024-04-17T07:09:25.039750Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"test_df_categorised = pd.read_csv('/kaggle/input/lun-glove/balancedtestwithclass_new_cleaned.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T16:36:32.672581Z","iopub.execute_input":"2024-04-16T16:36:32.672997Z","iopub.status.idle":"2024-04-16T16:36:32.771911Z","shell.execute_reply.started":"2024-04-16T16:36:32.672959Z","shell.execute_reply":"2024-04-16T16:36:32.770801Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\ndef categorised_eval(categories_df, X, ylens, model, device, category_list=[0,1,2,3,4,5], batch_size=128, return_preds=False):\n    all_preds = []\n    records = {'category':[], 'support':[], 'acc':[], 'f1':[], 'precision':[], 'recall':[]}\n    for cat in category_list:\n        idx = categories_df[categories_df['Category']==cat].index\n        ylens_cat = ylens.loc[idx]\n        X_cat = X[idx]\n        \n        model.to(device)\n        preds=[]\n        truths=[]\n        \n        for tokens, (_, (label, num_sent, sent_len)) in tqdm(zip(X_cat, ylens_cat[['Label','Num_Sentences','Num_Tokens']].iterrows())):\n            \n            X_in = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n            num_sent = torch.tensor(num_sent, dtype=torch.long).unsqueeze(0)\n            sent_len = torch.tensor(sent_len, dtype=torch.long).unsqueeze(0)\n            \n            #Forward pass\n            outputs = model(X_in, num_sent, sent_len, return_attn_weights=False)\n\n            #Logging\n            preds.append(torch.argmax(outputs, dim=-1).cpu().item())\n            truths.append(label)\n        \n        records['category'].append(cat)\n        records['support'].append(len(X_cat))\n        records['acc'].append(accuracy_score(truths, preds))\n        records['f1'].append(f1_score(truths, preds, average='macro'))\n        records['precision'].append(precision_score(truths, preds, average='macro'))\n        records['recall'].append(recall_score(truths, preds, average='macro'))\n        all_preds.append((idx,preds,truths))\n    return records if not return_preds else (records, all_preds)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:09:35.562872Z","iopub.execute_input":"2024-04-17T07:09:35.563363Z","iopub.status.idle":"2024-04-17T07:09:35.579910Z","shell.execute_reply.started":"2024-04-17T07:09:35.563327Z","shell.execute_reply":"2024-04-17T07:09:35.578585Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"results, preds = categorised_eval(test_df_categorised, X_hier_test, ylens_test, model, DEVICE, category_list=[0,1,2,3,4,5], batch_size=128, return_preds=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:09:41.555962Z","iopub.execute_input":"2024-04-17T07:09:41.556431Z","iopub.status.idle":"2024-04-17T07:10:17.872005Z","shell.execute_reply.started":"2024-04-17T07:09:41.556398Z","shell.execute_reply":"2024-04-17T07:10:17.870198Z"},"trusted":true},"execution_count":120,"outputs":[{"name":"stderr","text":"179it [00:02, 77.85it/s]\n112it [00:01, 93.76it/s]\n559it [00:07, 72.61it/s]\n930it [00:11, 82.10it/s] \n1051it [00:11, 88.23it/s]\n169it [00:01, 95.39it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(results)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T15:05:50.098513Z","iopub.execute_input":"2024-04-15T15:05:50.099229Z","iopub.status.idle":"2024-04-15T15:05:50.116859Z","shell.execute_reply.started":"2024-04-15T15:05:50.099191Z","shell.execute_reply":"2024-04-15T15:05:50.115003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(results).to_csv('./outputs/HAN_categorized_eval_results.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-15T07:49:56.978768Z","iopub.execute_input":"2024-04-15T07:49:56.979281Z","iopub.status.idle":"2024-04-15T07:49:56.988593Z","shell.execute_reply.started":"2024-04-15T07:49:56.979241Z","shell.execute_reply":"2024-04-15T07:49:56.987028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# health propaganda articles\nprophealth = test_df_categorised[(test_df_categorised['Category']==2) & (test_df_categorised['Label'] == 3)]\nprophealth","metadata":{"execution":{"iopub.status.busy":"2024-04-16T16:35:42.932901Z","iopub.execute_input":"2024-04-16T16:35:42.934022Z","iopub.status.idle":"2024-04-16T16:35:42.948024Z","shell.execute_reply.started":"2024-04-16T16:35:42.933980Z","shell.execute_reply":"2024-04-16T16:35:42.946745Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                                   Text  Label  Category  \\\n1500   New research suggests that one of the more po...      3         2   \n1503   Infectious disease medicine and psychiatry ha...      3         2   \n1504   Water fluoridation may cause hypothyroidism a...      3         2   \n1507   As controversial as it may sound, botox has n...      3         2   \n1508   Having bad skin is something that millions of...      3         2   \n...                                                 ...    ...       ...   \n2242   There's a good chance that the vast majority ...      3         2   \n2245   Medicinal substances that can effectively hel...      3         2   \n2246   Tweet (NewsTarget) Viruses that cause winter ...      3         2   \n2247   Tweet (NewsTarget) The foundation of a health...      3         2   \n2249   There are plenty of good reasons why, in a wo...      3         2   \n\n      Length  \n1500     728  \n1503     618  \n1504     630  \n1507    1537  \n1508     473  \n...      ...  \n2242     525  \n2245     594  \n2246     489  \n2247     707  \n2249     706  \n\n[493 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Category</th>\n      <th>Length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1500</th>\n      <td>New research suggests that one of the more po...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>728</td>\n    </tr>\n    <tr>\n      <th>1503</th>\n      <td>Infectious disease medicine and psychiatry ha...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>618</td>\n    </tr>\n    <tr>\n      <th>1504</th>\n      <td>Water fluoridation may cause hypothyroidism a...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>630</td>\n    </tr>\n    <tr>\n      <th>1507</th>\n      <td>As controversial as it may sound, botox has n...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1537</td>\n    </tr>\n    <tr>\n      <th>1508</th>\n      <td>Having bad skin is something that millions of...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>473</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2242</th>\n      <td>There's a good chance that the vast majority ...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>525</td>\n    </tr>\n    <tr>\n      <th>2245</th>\n      <td>Medicinal substances that can effectively hel...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>594</td>\n    </tr>\n    <tr>\n      <th>2246</th>\n      <td>Tweet (NewsTarget) Viruses that cause winter ...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>489</td>\n    </tr>\n    <tr>\n      <th>2247</th>\n      <td>Tweet (NewsTarget) The foundation of a health...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>707</td>\n    </tr>\n    <tr>\n      <th>2249</th>\n      <td>There are plenty of good reasons why, in a wo...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>706</td>\n    </tr>\n  </tbody>\n</table>\n<p>493 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nprint(classification_report(test_df_categorised[test_df_categorised['Category'] == 2]['Label'], test_df_categorised[test_df_categorised['Category'] == 2]['prediction']))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:18:07.354071Z","iopub.execute_input":"2024-04-16T17:18:07.354461Z","iopub.status.idle":"2024-04-16T17:18:07.370833Z","shell.execute_reply.started":"2024-04-16T17:18:07.354433Z","shell.execute_reply":"2024-04-16T17:18:07.370009Z"},"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           1       0.48      0.62      0.54        16\n           2       0.35      0.33      0.34        18\n           3       0.96      0.78      0.86       493\n           4       0.21      0.81      0.34        32\n\n    accuracy                           0.76       559\n   macro avg       0.50      0.64      0.52       559\nweighted avg       0.89      0.76      0.81       559\n\n","output_type":"stream"}]},{"cell_type":"code","source":"prophealth[prophealth['Label'] != prophealth['prediction']]","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:39:43.188963Z","iopub.execute_input":"2024-04-16T17:39:43.189447Z","iopub.status.idle":"2024-04-16T17:39:43.205213Z","shell.execute_reply.started":"2024-04-16T17:39:43.189415Z","shell.execute_reply":"2024-04-16T17:39:43.203888Z"},"trusted":true},"execution_count":145,"outputs":[{"execution_count":145,"output_type":"execute_result","data":{"text/plain":"                                                   Text  Label  Category  \\\n1500   New research suggests that one of the more po...      3         2   \n1512   Tweet Eli Lilly treated the American public '...      3         2   \n1526   Tens of millions of Americans are obese, and ...      3         2   \n1535   Compared to land vegetables like broccoli and...      3         2   \n1540   Tweet (NewsTarget) In the third installment o...      3         2   \n...                                                 ...    ...       ...   \n2202   Winter is the season of the kidney according ...      3         2   \n2203   June is National Fresh Fruit and Vegetable Mo...      3         2   \n2208   As terrifying as a diagnosis of cancer can be...      3         2   \n2220   From happy childish squeals of delight during...      3         2   \n2239   Nearly all non-organic veggie burgers on the ...      3         2   \n\n      Length  prediction  \n1500     728           4  \n1512     291           2  \n1526     785           4  \n1535     551           4  \n1540      84           1  \n...      ...         ...  \n2202     515           4  \n2203     337           4  \n2208     587           4  \n2220     614           4  \n2239     315           4  \n\n[108 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Category</th>\n      <th>Length</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1500</th>\n      <td>New research suggests that one of the more po...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>728</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1512</th>\n      <td>Tweet Eli Lilly treated the American public '...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>291</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1526</th>\n      <td>Tens of millions of Americans are obese, and ...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>785</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1535</th>\n      <td>Compared to land vegetables like broccoli and...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>551</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1540</th>\n      <td>Tweet (NewsTarget) In the third installment o...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>84</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2202</th>\n      <td>Winter is the season of the kidney according ...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>515</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2203</th>\n      <td>June is National Fresh Fruit and Vegetable Mo...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>337</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2208</th>\n      <td>As terrifying as a diagnosis of cancer can be...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>587</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2220</th>\n      <td>From happy childish squeals of delight during...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>614</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2239</th>\n      <td>Nearly all non-organic veggie burgers on the ...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>315</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>108 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 2. Visualizing attention","metadata":{}},{"cell_type":"code","source":"class AttnVizPreprocessorHcl():\n\n    def __init__(self, data_vocab):\n        self.vocab = data_vocab\n        print(\"Vocab created: {} unique tokens\".format(len(self.vocab)))\n        \n    @classmethod\n    def from_pretrained_embeds(cls, embed_path, embed_dim, sep=\" \",  specials=['<unk>']):\n        # start with all '0's for special tokens\n        embeds = [np.asarray([0]*embed_dim, dtype=np.float32)]*len(specials)\n        words = OrderedDict()\n        with open(embed_path, encoding=\"utf-8\") as f:\n            for i, line in enumerate(f):\n                if i == 38522 and 'twitter.27B.100d' in embed_path:\n                    continue\n                splitline = line.split()\n                \n                word = splitline[0]\n                if word not in words:\n                    words[word] = 0\n                words[word]+=1\n                embeds.append(np.asarray(splitline[1:], dtype=np.float32))\n                \n        embeds = torch.tensor(np.array(embeds))\n        data_vocab = vocab(words, specials=specials)\n        data_vocab.set_default_index(data_vocab['<unk>'])\n        return cls(data_vocab)\n\n    def get_vocab_size(self):\n        return len(self.vocab)\n    \n    def preprocess_single_row(self, row, max_sent_len, max_num_sents, preprocess_label=False):\n        '''\n        Converts text into integers that index the vocab,\n        and converts labels into the range [0,num_classes-1]\n        \n        Return tokens by sentence (unpadded), idx by sentence (padded), label, num_sentences, num_tokens\n        '''\n        text = row['Text']\n        label = row['Label']\n        \n        words = [word_tokenize(sent.lower()) for sent in sent_tokenize(text.replace(\"'\",\"\"))]\n        token_idxs = [self.vocab(sent) for sent in words]\n        num_sentences = min(max_num_sents, len(words))\n        num_tokens = [min(max_sent_len, len(sent)) for sent in words][:max_num_sents]\n        num_tokens = num_tokens + [0 for _ in range(max_sent_len-len(num_tokens))] #padding\n        \n        tokens_padded = np.zeros((1, max_num_sents, max_sent_len), dtype='int32')\n        for j, sent in enumerate(token_idxs):\n            if j >= max_num_sents:\n                break\n            k = min(max_sent_len, len(sent))\n            tokens_padded[0,j,:k] = sent[:k]\n                \n        if preprocess_label:\n            label -= 1\n        return words, torch.tensor(tokens_padded, dtype=torch.long), label,\\\n                torch.tensor(num_sentences, dtype=torch.long).unsqueeze(0),\\\n                torch.tensor(num_tokens, dtype=torch.long).unsqueeze(0)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:08:43.493790Z","iopub.execute_input":"2024-04-17T12:08:43.494771Z","iopub.status.idle":"2024-04-17T12:08:43.517131Z","shell.execute_reply.started":"2024-04-17T12:08:43.494717Z","shell.execute_reply":"2024-04-17T12:08:43.515384Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"MAX_SENT_LEN = 30\nMAX_NUM_SENTS = 30\nNUM_CLASSES = 4\nEMBED_DIM = 100\nHIDDEN_DIM = 100\nNUM_LSTM_LAYERS = 1\n\nVOCAB_LEN = 400001 #harcoded for convenience; see below for how it was obtained\n# glove, _ = DataPreprocessorHcl.from_pretrained_embeds(NUM_CLASSES,'/kaggle/input/lun-glove/glove.6B.100d.txt', EMBED_DIM)\n# VOCAB_LEN = len(glove.vocab)\n\nMODEL_PATH = '/kaggle/input/bilstmheattnewsclassifier/pytorch/best_performing/1/glounfro_clean_msl30_mns30_batch256_embed100hidden100layers1classes4_ep10lr0.0005wd5e-06_af0.5_ap2.pt'\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodelhan = BiLSTMHeAttFCNNClassifier(VOCAB_LEN, EMBED_DIM, HIDDEN_DIM, NUM_LSTM_LAYERS, NUM_CLASSES)\nmodelhan.to(DEVICE)\nmodelhan.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\nmodelhan.eval()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:29:09.862080Z","iopub.execute_input":"2024-04-17T07:29:09.862587Z","iopub.status.idle":"2024-04-17T07:29:10.497473Z","shell.execute_reply.started":"2024-04-17T07:29:09.862554Z","shell.execute_reply":"2024-04-17T07:29:10.496225Z"},"trusted":true},"execution_count":159,"outputs":[{"execution_count":159,"output_type":"execute_result","data":{"text/plain":"BiLSTMHeAttFCNNClassifier(\n  (embedding): Embedding(400001, 100)\n  (word_encoder): LSTM(100, 100, batch_first=True, bidirectional=True)\n  (word_attn): AttentionUnit(\n    (hidden): Linear(in_features=200, out_features=200, bias=True)\n    (query): Linear(in_features=200, out_features=1, bias=False)\n  )\n  (sent_encoder): LSTM(200, 100, batch_first=True, bidirectional=True)\n  (sent_attn): AttentionUnit(\n    (hidden): Linear(in_features=200, out_features=200, bias=True)\n    (query): Linear(in_features=200, out_features=1, bias=False)\n  )\n  (decoder): Linear(in_features=200, out_features=4, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"EMBED_PATH = '/kaggle/input/lun-glove/glove.6B.100d.txt'\nEMBED_DIM = 100\nMAX_SENT_LEN = 30\nMAX_NUM_SENT = 30\npp = AttnVizPreprocessorHcl.from_pretrained_embeds(EMBED_PATH, EMBED_DIM)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:08:53.410761Z","iopub.execute_input":"2024-04-17T12:08:53.411265Z","iopub.status.idle":"2024-04-17T12:09:10.423637Z","shell.execute_reply.started":"2024-04-17T12:08:53.411225Z","shell.execute_reply":"2024-04-17T12:09:10.422139Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Vocab created: 400001 unique tokens\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/lun-glove/fulltrain.csv', header=None, names=['Label','Text'])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:38:50.648075Z","iopub.execute_input":"2024-04-17T06:38:50.648599Z","iopub.status.idle":"2024-04-17T06:38:53.683413Z","shell.execute_reply.started":"2024-04-17T06:38:50.648562Z","shell.execute_reply":"2024-04-17T06:38:53.682284Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import re\nHEDGE_REGEX = r\"may|might|possib|probab|assum|likely|perhap|seem\"\n\ntrain_df['lengths'] = train_df['Text'].apply(lambda s: len(s.split()))\ntrain_df['has_hedge'] = train_df['Text'].apply(lambda text : len(re.findall(HEDGE_REGEX, text)))\ntrain_df['has_2p'] = train_df['Text'].apply(lambda text : len(re.findall(\"you\",text)))\ntrain_df['has_1ps'] = train_df['Text'].apply(lambda text : len(re.findall(r\"\\b(I|i)\\b\", text)))\ntrain_df['has_nums'] = train_df['Text'].apply(lambda text : len(re.findall(r\"[0-9]|millio|trillio|billio|dollar|\\$|\\%\", text)))\n\ntrain_df['has_bri_ire_afh_am_hondu'] = train_df['Text'].apply(lambda text : len(re.findall(r\"brit|afgha|america|u.s|hondur|ire\", text)))","metadata":{"execution":{"iopub.status.busy":"2024-04-17T03:23:57.235338Z","iopub.execute_input":"2024-04-17T03:23:57.235810Z","iopub.status.idle":"2024-04-17T03:24:27.754575Z","shell.execute_reply.started":"2024-04-17T03:23:57.235774Z","shell.execute_reply":"2024-04-17T03:24:27.753146Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_df[train_df.has_hedge > 0]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T03:25:03.100589Z","iopub.execute_input":"2024-04-17T03:25:03.101021Z","iopub.status.idle":"2024-04-17T03:25:03.123623Z","shell.execute_reply.started":"2024-04-17T03:25:03.100987Z","shell.execute_reply":"2024-04-17T03:25:03.122463Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"       Label                                               Text  lengths  \\\n0          1  A little less than a decade ago, hockey fans w...      146   \n1          1  The writers of the HBO series The Sopranos too...      122   \n2          1  Despite claims from the TV news outlet to offe...      705   \n3          1  After receiving 'subpar' service and experienc...      705   \n5          1  At a cafeteria-table press conference Monday, ...       93   \n...      ...                                                ...      ...   \n48829      4  Opposition Democratic Progressive Party (DPP) ...      319   \n48833      4  Taiwan is likely to be affected by a dust stor...      147   \n48838      4  President Ma Ying-jeou said Wednesday that a s...      368   \n48842      4  A preliminary report on the cause of the April...      476   \n48852      4  The families of the four people who were kille...      245   \n\n       has_hedge  has_2p  has_1ps  has_nums  has_bri_ire_afh_am_hondu  \n0              2       0        0         0                         2  \n1              1       0        1         3                         0  \n2              2       3        0        35                        15  \n3              2       3       15        18                         2  \n5              1       0        1         7                         0  \n...          ...     ...      ...       ...                       ...  \n48829          1       0        0        11                         2  \n48833          1       0        0         7                         4  \n48838          1       0        0        19                         4  \n48842          1       0        0         5                         7  \n48852          1       0        0         8                         0  \n\n[24750 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Text</th>\n      <th>lengths</th>\n      <th>has_hedge</th>\n      <th>has_2p</th>\n      <th>has_1ps</th>\n      <th>has_nums</th>\n      <th>has_bri_ire_afh_am_hondu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>A little less than a decade ago, hockey fans w...</td>\n      <td>146</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>The writers of the HBO series The Sopranos too...</td>\n      <td>122</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Despite claims from the TV news outlet to offe...</td>\n      <td>705</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>35</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>After receiving 'subpar' service and experienc...</td>\n      <td>705</td>\n      <td>2</td>\n      <td>3</td>\n      <td>15</td>\n      <td>18</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>At a cafeteria-table press conference Monday, ...</td>\n      <td>93</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48829</th>\n      <td>4</td>\n      <td>Opposition Democratic Progressive Party (DPP) ...</td>\n      <td>319</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>48833</th>\n      <td>4</td>\n      <td>Taiwan is likely to be affected by a dust stor...</td>\n      <td>147</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>48838</th>\n      <td>4</td>\n      <td>President Ma Ying-jeou said Wednesday that a s...</td>\n      <td>368</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>19</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>48842</th>\n      <td>4</td>\n      <td>A preliminary report on the cause of the April...</td>\n      <td>476</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>48852</th>\n      <td>4</td>\n      <td>The families of the four people who were kille...</td>\n      <td>245</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>24750 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_test = np.load('./HAN_prepro_data/X_test_prep.npy')\nylens_test = pd.read_csv('./HAN_prepro_data/ylens_test_prep.csv')\nimport ast\nylens_test['Num_Tokens'] = ylens_test['Num_Tokens'].apply(ast.literal_eval)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T03:21:40.408726Z","iopub.execute_input":"2024-04-17T03:21:40.409350Z","iopub.status.idle":"2024-04-17T03:21:40.805905Z","shell.execute_reply.started":"2024-04-17T03:21:40.409316Z","shell.execute_reply":"2024-04-17T03:21:40.804871Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"test_df_categorised = pd.read_csv('./HAN_prepro_data/balancedtestwithclass_new_cleaned.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T06:14:38.380764Z","iopub.execute_input":"2024-04-16T06:14:38.381078Z","iopub.status.idle":"2024-04-16T06:14:38.610961Z","shell.execute_reply.started":"2024-04-16T06:14:38.381053Z","shell.execute_reply":"2024-04-16T06:14:38.609704Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import re\nHEDGE_REGEX = r\"may|might|possib|probab|assum|likely|perhap|seem\"\n\ntest_df_categorised['lengths'] = test_df_categorised['Text'].apply(lambda s: len(s.split()))\ntest_df_categorised['has_hedge'] = test_df_categorised['Text'].apply(lambda text : len(re.findall(HEDGE_REGEX, text)))\ntest_df_categorised['has_2p'] = test_df_categorised['Text'].apply(lambda text : len(re.findall(\"you\",text)))\ntest_df_categorised['has_1ps'] = test_df_categorised['Text'].apply(lambda text : len(re.findall(r\"\\b(I|i)\\b\", text)))\ntest_df_categorised['has_nums'] = test_df_categorised['Text'].apply(lambda text : len(re.findall(r\"[0-9]|millio|trillio|billio|dollar|\\$|\\%\", text)))\n\ntest_df_categorised['has_bri_ire_afh_am_hondu'] = test_df_categorised['Text'].apply(lambda text : len(re.findall(r\"brit|afgha|america|u.s|hondur|ire\", text)))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:26:28.660317Z","iopub.execute_input":"2024-04-16T07:26:28.660757Z","iopub.status.idle":"2024-04-16T07:26:30.418112Z","shell.execute_reply.started":"2024-04-16T07:26:28.660726Z","shell.execute_reply":"2024-04-16T07:26:30.417059Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"\nimport torch\nimport json\nfrom IPython.display import Markdown, display\n\nlabelid2label = ['Satire', 'Hoax', 'Propaganda', 'Trusted']\n\nclass AttentionVisualizerHcl():\n    def __init__(self, model, preprocessor):\n\n        class Struct:\n            def __init__(self, **entries):\n                self.__dict__.update(entries)\n        \n        self.model = model\n        self.preprocessor = preprocessor\n\n    def visualize_attention(self, doc_and_label_row, max_sent_len, max_num_sents, device='cpu', preprocess_label=False, sents_only=False):\n        # doc_and_label_row should contain a row of the df with columns ['Text'] and ['Label']\n        \n        words, X, y, num_sentences, num_tokens = self.preprocessor.preprocess_single_row(doc_and_label_row, max_sent_len, max_num_sents, preprocess_label)\n        pred, word_weights, sent_weights = self.model(X, num_sentences, num_tokens, return_attn_weights=True)\n        pred = torch.argmax(pred, dim = -1).cpu().item()\n        # remove the padding elements (which have 0 weight)\n        sent_weights = sent_weights.squeeze(0,2)[:num_sentences]\n        word_weights = word_weights[0].squeeze(2).tolist()\n        word_weights = [weights[:num] for num, weights in zip(num_tokens[0], word_weights)]\n        \n        display(Markdown('<p style=\"font-size:18px\"> Ground Truth: '+ labelid2label[y] + '&emsp;&emsp;&emsp;Prediction: '+labelid2label[pred] +'</p>'))\n        i = 0\n        if sents_only:\n            line = []\n            for sent_weight in sent_weights:\n                sent_weight = sent_weight.item()\n                line.append('<span style=\"background-color:rgba(255,0,0,' +\\\n                        str(sent_weight) +\\\n                        ');font-size:16px;color:rgba(255,0,0,0);\">' + '_____' + '</span>')\n            display(Markdown(\" \".join(line)))\n            return words, word_weights, sent_weights\n        max_weight_sent = max(map(max, word_weights))\n        min_weight_sent = min(map(min, word_weights))\n        \n        for sent, word_weights_sent, sent_weight in zip(words, word_weights, sent_weights):\n            i += 1\n            sent_weight = sent_weight.item()\n            line = [self.__make_sent(sent_weight)]\n            line_length = 5\n            for word, word_weight in zip(sent, word_weights_sent):\n                line_length += len(word) + 1\n                line.append(self.__make_word(word, self.__scale_weight(word_weight,\n                                                                       max_weight_sent,\n                                                                       min_weight_sent),\n                                             sent_weight))\n                \n                if line_length > 60:\n                    display(Markdown(\" \".join(line)))\n                    line = [self.__make_blank()]\n                    line_length = 5\n                    \n            display(Markdown(\" \".join(line)))\n        return words, word_weights, sent_weights\n\n    def __make_blank(self):\n        return '<span style=\"color:rgba(255,255,255,0);font-size:16px\">' + '_____' + '</span>'\n    \n    def __make_sent(self, sent_weight):\n        return '<span style=\"background-color:rgba(255,0,0,' +\\\n                    str(sent_weight) +\\\n                    ');font-size:16px;color:rgba(255,0,0,0);\">' + '_____' + '</span>'\n    \n    def __make_word(self, word, word_weight, sent_weight):\n        return '<span style=\"background-color:rgba(0,0,255,' +\\\n                        str(word_weight*sent_weight) + ');font-size:16px;\">' +\\\n                        word.replace('$', '\\$').replace(\"'\", \"\\'\") + '</span>'\n    \n    def __scale_weight(self, orig_weight, max_weight, min_weight):\n        out = (orig_weight-min_weight)/(max_weight-min_weight)\n        if type(out) == torch.Tensor:\n            out = out.item()\n        return out\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:50:51.001046Z","iopub.execute_input":"2024-04-17T07:50:51.001524Z","iopub.status.idle":"2024-04-17T07:50:51.025667Z","shell.execute_reply.started":"2024-04-17T07:50:51.001492Z","shell.execute_reply":"2024-04-17T07:50:51.024222Z"},"trusted":true},"execution_count":214,"outputs":[]},{"cell_type":"code","source":"avhan =AttentionVisualizerHcl(modelhan, pp)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:51:10.065234Z","iopub.execute_input":"2024-04-17T07:51:10.066347Z","iopub.status.idle":"2024-04-17T07:51:10.071556Z","shell.execute_reply.started":"2024-04-17T07:51:10.066279Z","shell.execute_reply":"2024-04-17T07:51:10.070369Z"},"trusted":true},"execution_count":216,"outputs":[]},{"cell_type":"code","source":"a,b,c = av.visualize_attention(test_df_categorised.loc[925], MAX_SENT_LEN, MAX_NUM_SENT, preprocess_label=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T09:34:03.242141Z","iopub.execute_input":"2024-04-16T09:34:03.242860Z","iopub.status.idle":"2024-04-16T09:34:03.278040Z","shell.execute_reply.started":"2024-04-16T09:34:03.242815Z","shell.execute_reply":"2024-04-16T09:34:03.276665Z"},"trusted":true},"execution_count":287,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<p style=\"font-size:18px\"> Ground Truth: Hoax&emsp;&emsp;&emsp;Prediction: Hoax</p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.38874557614326477);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.016056856978135723);font-size:16px;\">5</span> <span style=\"background-color:rgba(0,0,255,0.020698486688090607);font-size:16px;\">fast</span> <span style=\"background-color:rgba(0,0,255,0.02129833752830908);font-size:16px;\">facts</span> <span style=\"background-color:rgba(0,0,255,0.011524553205517521);font-size:16px;\">you</span> <span style=\"background-color:rgba(0,0,255,0.016486570148576907);font-size:16px;\">probably</span> <span style=\"background-color:rgba(0,0,255,0.03097247692137667);font-size:16px;\">didnt</span> <span style=\"background-color:rgba(0,0,255,0.016011315827400934);font-size:16px;\">know</span> <span style=\"background-color:rgba(0,0,255,0.0171647435457063);font-size:16px;\">about</span> <span style=\"background-color:rgba(0,0,255,0.05146342352472175);font-size:16px;\">melania</span> <span style=\"background-color:rgba(0,0,255,0.041566688314819945);font-size:16px;\">trump</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.04591509591271989);font-size:16px;\">melania</span> <span style=\"background-color:rgba(0,0,255,0.028355713106230727);font-size:16px;\">trump</span> <span style=\"background-color:rgba(0,0,255,0.012247979738759828);font-size:16px;\">put</span> <span style=\"background-color:rgba(0,0,255,0.013013152133284144);font-size:16px;\">herself</span> <span style=\"background-color:rgba(0,0,255,0.009197132015150808);font-size:16px;\">in</span> <span style=\"background-color:rgba(0,0,255,0.010008817029084101);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.01834613074796995);font-size:16px;\">spotlight</span> <span style=\"background-color:rgba(0,0,255,0.00870751180335951);font-size:16px;\">for</span> <span style=\"background-color:rgba(0,0,255,0.008723928056131775);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.010647690366518863);font-size:16px;\">first</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.008847746471155497);font-size:16px;\">time</span> <span style=\"background-color:rgba(0,0,255,0.011365597006624983);font-size:16px;\">in</span> <span style=\"background-color:rgba(0,0,255,0.016603707321182683);font-size:16px;\">husband</span> <span style=\"background-color:rgba(0,0,255,0.03700650170729606);font-size:16px;\">donalds</span> <span style=\"background-color:rgba(0,0,255,0.01621257881927857);font-size:16px;\">campaign</span> <span style=\"background-color:rgba(0,0,255,0.014686968851251658);font-size:16px;\">for</span> <span style=\"background-color:rgba(0,0,255,0.016837381248815574);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.0252438916419563);font-size:16px;\">us</span> <span style=\"background-color:rgba(0,0,255,0.04378042908871803);font-size:16px;\">presidency</span> <span style=\"background-color:rgba(0,0,255,0.024503234169420577);font-size:16px;\">last</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.22007574141025543);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.02273649267632144);font-size:16px;\">no</span> <span style=\"background-color:rgba(0,0,255,0.03821373473479856);font-size:16px;\">sooner</span> <span style=\"background-color:rgba(0,0,255,0.018649093130474206);font-size:16px;\">than</span> <span style=\"background-color:rgba(0,0,255,0.014499200555871734);font-size:16px;\">she</span> <span style=\"background-color:rgba(0,0,255,0.018259406043645718);font-size:16px;\">left</span> <span style=\"background-color:rgba(0,0,255,0.018866790258637245);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.030778401239769125);font-size:16px;\">stage</span> <span style=\"background-color:rgba(0,0,255,0.020357442717770652);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.024849845463984527);font-size:16px;\">critics</span> <span style=\"background-color:rgba(0,0,255,0.015349968370589944);font-size:16px;\">were</span> <span style=\"background-color:rgba(0,0,255,0.019294035377876557);font-size:16px;\">looking</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.018778214049307275);font-size:16px;\">for</span> <span style=\"background-color:rgba(0,0,255,0.026431328558105618);font-size:16px;\">anything</span> <span style=\"background-color:rgba(0,0,255,0.023157477832222818);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.05776415248607784);font-size:16px;\">bash</span> <span style=\"background-color:rgba(0,0,255,0.02682186673431031);font-size:16px;\">her</span> <span style=\"background-color:rgba(0,0,255,0.030701174053866447);font-size:16px;\">one</span> <span style=\"background-color:rgba(0,0,255,0.04361369235567004);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.3911786675453186);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.031957847680044546);font-size:16px;\">but</span> <span style=\"background-color:rgba(0,0,255,0.03599790734979267);font-size:16px;\">here</span> <span style=\"background-color:rgba(0,0,255,0.0296223557946747);font-size:16px;\">are</span> <span style=\"background-color:rgba(0,0,255,0.023020838125524853);font-size:16px;\">some</span> <span style=\"background-color:rgba(0,0,255,0.03905215102418634);font-size:16px;\">facts</span> <span style=\"background-color:rgba(0,0,255,0.01846301448845027);font-size:16px;\">that</span> <span style=\"background-color:rgba(0,0,255,0.02310931820121194);font-size:16px;\">you</span> <span style=\"background-color:rgba(0,0,255,0.029764580963340698);font-size:16px;\">may</span> <span style=\"background-color:rgba(0,0,255,0.028613988156066132);font-size:16px;\">never</span> <span style=\"background-color:rgba(0,0,255,0.027366275796589727);font-size:16px;\">have</span> <span style=\"background-color:rgba(0,0,255,0.040575180293827035);font-size:16px;\">known</span> <span style=\"background-color:rgba(0,0,255,0.04628526382162988);font-size:16px;\">about</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.1690829805142743);font-size:16px;\">melania</span> <span style=\"background-color:rgba(0,0,255,0.082531055180701);font-size:16px;\">.</span>"},"metadata":{}}]},{"cell_type":"code","source":"a,b,c = av.visualize_attention(test_df_categorised.loc[1890], MAX_SENT_LEN, MAX_NUM_SENT, preprocess_label=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T10:05:05.388771Z","iopub.execute_input":"2024-04-16T10:05:05.389310Z","iopub.status.idle":"2024-04-16T10:05:05.455075Z","shell.execute_reply.started":"2024-04-16T10:05:05.389267Z","shell.execute_reply":"2024-04-16T10:05:05.453934Z"},"trusted":true},"execution_count":306,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<p style=\"font-size:18px\"> Ground Truth: Propaganda&emsp;&emsp;&emsp;Prediction: Propaganda</p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.09338170289993286);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.02092750562633254);font-size:16px;\">even</span> <span style=\"background-color:rgba(0,0,255,0.02368837651080304);font-size:16px;\">obama</span> <span style=\"background-color:rgba(0,0,255,0.04979552181771765);font-size:16px;\">doesnt</span> <span style=\"background-color:rgba(0,0,255,0.01527078041893253);font-size:16px;\">have</span> <span style=\"background-color:rgba(0,0,255,0.01447282377451875);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.025939287446273517);font-size:16px;\">buy</span> <span style=\"background-color:rgba(0,0,255,0.05893300377786621);font-size:16px;\">obamacare</span> <span style=\"background-color:rgba(0,0,255,0.010631760941267998);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.013529857892208407);font-size:16px;\">it</span> <span style=\"background-color:rgba(0,0,255,0.027426691691069198);font-size:16px;\">turns</span> <span style=\"background-color:rgba(0,0,255,0.020298586214447824);font-size:16px;\">out</span> <span style=\"background-color:rgba(0,0,255,0.02467000552769924);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.1411142796278);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.008329520109437348);font-size:16px;\">and</span> <span style=\"background-color:rgba(0,0,255,0.00803010261123373);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.008891861238929802);font-size:16px;\">very</span> <span style=\"background-color:rgba(0,0,255,0.013397972173326961);font-size:16px;\">fact</span> <span style=\"background-color:rgba(0,0,255,0.008930756496887834);font-size:16px;\">that</span> <span style=\"background-color:rgba(0,0,255,0.045641123647989196);font-size:16px;\">obamacare</span> <span style=\"background-color:rgba(0,0,255,0.015450093763923579);font-size:16px;\">forces</span> <span style=\"background-color:rgba(0,0,255,0.01288559984918485);font-size:16px;\">citizens</span> <span style=\"background-color:rgba(0,0,255,0.007020857850592278);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.01278941126331217);font-size:16px;\">purchase</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.007016186613236593);font-size:16px;\">a</span> <span style=\"background-color:rgba(0,0,255,0.012094125990982666);font-size:16px;\">private</span> <span style=\"background-color:rgba(0,0,255,0.011755189796761711);font-size:16px;\">insurance</span> <span style=\"background-color:rgba(0,0,255,0.012629792927773888);font-size:16px;\">product</span> <span style=\"background-color:rgba(0,0,255,0.00847571108654909);font-size:16px;\">or</span> <span style=\"background-color:rgba(0,0,255,0.008087956403666339);font-size:16px;\">be</span> <span style=\"background-color:rgba(0,0,255,0.016707451478635803);font-size:16px;\">fined</span> <span style=\"background-color:rgba(0,0,255,0.008619499972911568);font-size:16px;\">by</span> <span style=\"background-color:rgba(0,0,255,0.008260855159368027);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.023645554399136078);font-size:16px;\">irs</span> <span style=\"background-color:rgba(0,0,255,0.008413722031568233);font-size:16px;\">is</span> <span style=\"background-color:rgba(0,0,255,0.01737559795347016);font-size:16px;\">blatantly</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.012869389060230909);font-size:16px;\">unconstitutional</span> <span style=\"background-color:rgba(0,0,255,0.004814714523017811);font-size:16px;\">and</span> <span style=\"background-color:rgba(0,0,255,0.005071731585981598);font-size:16px;\">an</span> <span style=\"background-color:rgba(0,0,255,0.01329769450550302);font-size:16px;\">outlandish</span> <span style=\"background-color:rgba(0,0,255,0.01374621585695854);font-size:16px;\">interpretation</span> <span style=\"background-color:rgba(0,0,255,0.008014191996160195);font-size:16px;\">of</span> <span style=\"background-color:rgba(0,0,255,0.009145837029699688);font-size:16px;\">the</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.02424311453118411);font-size:16px;\">commerce</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.11197298020124435);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.086220334175198);font-size:16px;\">obamacare</span> <span style=\"background-color:rgba(0,0,255,0.019757235127196304);font-size:16px;\">is</span> <span style=\"background-color:rgba(0,0,255,0.016195168264801284);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.022681242540419908);font-size:16px;\">biggest</span> <span style=\"background-color:rgba(0,0,255,0.020808622350178628);font-size:16px;\">government</span> <span style=\"background-color:rgba(0,0,255,0.027173111154929926);font-size:16px;\">boondoggle</span> <span style=\"background-color:rgba(0,0,255,0.013781338403809842);font-size:16px;\">our</span> <span style=\"background-color:rgba(0,0,255,0.012855061952215807);font-size:16px;\">nation</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.006376685247572061);font-size:16px;\">has</span> <span style=\"background-color:rgba(0,0,255,0.006612188536016596);font-size:16px;\">ever</span> <span style=\"background-color:rgba(0,0,255,0.005607169361417602);font-size:16px;\">seen</span> <span style=\"background-color:rgba(0,0,255,0.003732506977548856);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.004618592759377537);font-size:16px;\">and</span> <span style=\"background-color:rgba(0,0,255,0.004657084665605073);font-size:16px;\">it</span> <span style=\"background-color:rgba(0,0,255,0.006399652680191761);font-size:16px;\">is</span> <span style=\"background-color:rgba(0,0,255,0.013107637019526896);font-size:16px;\">doomed</span> <span style=\"background-color:rgba(0,0,255,0.006729884707865038);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.011967809380681461);font-size:16px;\">crash</span> <span style=\"background-color:rgba(0,0,255,0.008513768421821099);font-size:16px;\">and</span> <span style=\"background-color:rgba(0,0,255,0.02102474271860885);font-size:16px;\">burn</span> <span style=\"background-color:rgba(0,0,255,0.015803798825034496);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.10022211819887161);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.015915433330761394);font-size:16px;\">nobody</span> <span style=\"background-color:rgba(0,0,255,0.008048285271199994);font-size:16px;\">who</span> <span style=\"background-color:rgba(0,0,255,0.015511796820600278);font-size:16px;\">understands</span> <span style=\"background-color:rgba(0,0,255,0.007280429003525972);font-size:16px;\">it</span> <span style=\"background-color:rgba(0,0,255,0.009542483583794817);font-size:16px;\">wants</span> <span style=\"background-color:rgba(0,0,255,0.006004604041091346);font-size:16px;\">it</span> <span style=\"background-color:rgba(0,0,255,0.005313362335782852);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.007124336422278201);font-size:16px;\">and</span> <span style=\"background-color:rgba(0,0,255,0.008431416460744925);font-size:16px;\">even</span> <span style=\"background-color:rgba(0,0,255,0.011003799910034308);font-size:16px;\">those</span> <span style=\"background-color:rgba(0,0,255,0.01061402545419669);font-size:16px;\">who</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.03237498000839386);font-size:16px;\">foolishly</span> <span style=\"background-color:rgba(0,0,255,0.012226791858974708);font-size:16px;\">were</span> <span style=\"background-color:rgba(0,0,255,0.03336381362622351);font-size:16px;\">mind-tricked</span> <span style=\"background-color:rgba(0,0,255,0.013896092660392632);font-size:16px;\">into</span> <span style=\"background-color:rgba(0,0,255,0.017509849083397706);font-size:16px;\">supporting</span> <span style=\"background-color:rgba(0,0,255,0.006759423797918685);font-size:16px;\">it</span> <span style=\"background-color:rgba(0,0,255,0.006032398910607779);font-size:16px;\">have</span> <span style=\"background-color:rgba(0,0,255,0.005710984761715393);font-size:16px;\">no</span> <span style=\"background-color:rgba(0,0,255,0.013186921330115607);font-size:16px;\">clue</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.005587469895084356);font-size:16px;\">just</span> <span style=\"background-color:rgba(0,0,255,0.006932721884571039);font-size:16px;\">how</span> <span style=\"background-color:rgba(0,0,255,0.008559021305629654);font-size:16px;\">badly</span> <span style=\"background-color:rgba(0,0,255,0.006484713002205196);font-size:16px;\">its</span> <span style=\"background-color:rgba(0,0,255,0.006661195327982396);font-size:16px;\">going</span> <span style=\"background-color:rgba(0,0,255,0.006297318760686278);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.011073751746868053);font-size:16px;\">hurt</span> <span style=\"background-color:rgba(0,0,255,0.008929161978893038);font-size:16px;\">them</span> <span style=\"background-color:rgba(0,0,255,0.010202124074484863);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.10944917798042297);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.021775225553672284);font-size:16px;\">every</span> <span style=\"background-color:rgba(0,0,255,0.045344738284564534);font-size:16px;\">rational</span> <span style=\"background-color:rgba(0,0,255,0.019074477528823894);font-size:16px;\">person</span> <span style=\"background-color:rgba(0,0,255,0.01908953057137037);font-size:16px;\">wants</span> <span style=\"background-color:rgba(0,0,255,0.013248761499762013);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.01569730882365263);font-size:16px;\">be</span> <span style=\"background-color:rgba(0,0,255,0.04961821005312744);font-size:16px;\">exempted</span> <span style=\"background-color:rgba(0,0,255,0.02456105642158917);font-size:16px;\">from</span> <span style=\"background-color:rgba(0,0,255,0.09696883588996431);font-size:16px;\">obamacare</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.025452915300322017);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.09913370013237);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.014735476153195768);font-size:16px;\">any</span> <span style=\"background-color:rgba(0,0,255,0.020452794701408747);font-size:16px;\">lawmakers</span> <span style=\"background-color:rgba(0,0,255,0.010194783464121298);font-size:16px;\">who</span> <span style=\"background-color:rgba(0,0,255,0.021042886960401314);font-size:16px;\">continue</span> <span style=\"background-color:rgba(0,0,255,0.013112348863892167);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.03231812335239214);font-size:16px;\">defend</span> <span style=\"background-color:rgba(0,0,255,0.04572311267363345);font-size:16px;\">obamacare</span> <span style=\"background-color:rgba(0,0,255,0.009534331452688715);font-size:16px;\">will</span> <span style=\"background-color:rgba(0,0,255,0.009883563851818126);font-size:16px;\">likely</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.007562506032253274);font-size:16px;\">find</span> <span style=\"background-color:rgba(0,0,255,0.008336097356041329);font-size:16px;\">themselves</span> <span style=\"background-color:rgba(0,0,255,0.004892056882025155);font-size:16px;\">out</span> <span style=\"background-color:rgba(0,0,255,0.005098033909291541);font-size:16px;\">of</span> <span style=\"background-color:rgba(0,0,255,0.005233893393429653);font-size:16px;\">a</span> <span style=\"background-color:rgba(0,0,255,0.0074683581584986955);font-size:16px;\">job</span> <span style=\"background-color:rgba(0,0,255,0.006497470636094177);font-size:16px;\">when</span> <span style=\"background-color:rgba(0,0,255,0.01097637590568201);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.03423641171798404);font-size:16px;\">2014</span> <span style=\"background-color:rgba(0,0,255,0.014720929519373807);font-size:16px;\">elections</span> <span style=\"background-color:rgba(0,0,255,0.00972228235982183);font-size:16px;\">come</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.011211980468589892);font-size:16px;\">around</span> <span style=\"background-color:rgba(0,0,255,0.011901230756664445);font-size:16px;\">.</span>"},"metadata":{}}]},{"cell_type":"code","source":"short_trusted = (test_df_categorised['Label'] == 3) & (test_df_categorised['Text'].apply(lambda t: re.search(r'obama|trump|melania|biden', t.lower())))\ntest_df_categorised[short_trusted].sort_values('lengths').head(20)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T10:01:48.534432Z","iopub.execute_input":"2024-04-16T10:01:48.534944Z","iopub.status.idle":"2024-04-16T10:01:48.775723Z","shell.execute_reply.started":"2024-04-16T10:01:48.534886Z","shell.execute_reply":"2024-04-16T10:01:48.774533Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":299,"outputs":[{"execution_count":299,"output_type":"execute_result","data":{"text/plain":"                                                   Text  Label  Category  \\\n1890   Top lawmakers on Capitol Hill are negotiating...      3         4   \n2191   After months of collecting signatures to get ...      3         4   \n2143   The battle continues to rage between the indi...      3         4   \n1727   With preparations being made for the massive ...      3         4   \n1896   Thank you to all those who voted in our selfn...      3         4   \n2007   In what is quickly shaping up to be the bigge...      3         4   \n1587   The Law of Attraction, made popular by 'The S...      3         2   \n1775   Tweet (NewsTarget) California governor Arnold...      3         4   \n1756   If you're 'Ready for Hillary' in 2016, you mi...      3         4   \n1644   With a sad twist of irony, corporate and gove...      3         3   \n1863   It recently went public that the Obama admini...      3         2   \n1987   He was widely panned for it, but former Texas...      3         4   \n2156   Army Veteran Donald Siefkin wasn't asking for...      3         2   \n2104   The number of illegal immigrants arriving via...      3         4   \n1754   In Brave New America, simply acknowledging th...      3         2   \n2051   In approximately 25 years, fresh water may be...      3         3   \n1683   During his first campaign for president, then...      3         4   \n1786   In the wake of revelations - thanks in every ...      3         4   \n1814   The White House has been caught in yet anothe...      3         4   \n1641   The president of the United States has his pr...      3         4   \n\n      lengths  has_hedge  has_2p  has_1ps  has_nums  has_bri_ire_afh_am_hondu  \\\n1890      321          1       0        1         4                         2   \n2191      322          0       0        0        30                         2   \n2143      380          0       0        1        10                         4   \n1727      423          0       0        0         8                         1   \n1896      510          5       4        2        57                         5   \n2007      531          3       0        0        11                         5   \n1587      534          0       7        7        20                         7   \n1775      565          0       0        2        20                         3   \n1756      574          4       6        0        18                         4   \n1644      576          0       1        0         8                         3   \n1863      583          1       2        0        20                         6   \n1987      596          4       3        4        14                        13   \n2156      597          0       2        2        21                        10   \n2104      604          2       1        0        30                         3   \n1754      606          4      10        0         3                         8   \n2051      615          5       0        0        49                         8   \n1683      618          0       0        1        32                         6   \n1786      621          0       3        3        29                         4   \n1814      624          1       4        1         9                         9   \n1641      625          1       1        0         0                         2   \n\n      has_days  \n1890         0  \n2191         0  \n2143         0  \n1727         0  \n1896         0  \n2007         0  \n1587        12  \n1775         0  \n1756         0  \n1644         0  \n1863         0  \n1987         0  \n2156         0  \n2104         0  \n1754         0  \n2051         3  \n1683         0  \n1786         0  \n1814         0  \n1641         3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Category</th>\n      <th>lengths</th>\n      <th>has_hedge</th>\n      <th>has_2p</th>\n      <th>has_1ps</th>\n      <th>has_nums</th>\n      <th>has_bri_ire_afh_am_hondu</th>\n      <th>has_days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1890</th>\n      <td>Top lawmakers on Capitol Hill are negotiating...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>321</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2191</th>\n      <td>After months of collecting signatures to get ...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>322</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2143</th>\n      <td>The battle continues to rage between the indi...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>380</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>10</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1727</th>\n      <td>With preparations being made for the massive ...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>423</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1896</th>\n      <td>Thank you to all those who voted in our selfn...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>510</td>\n      <td>5</td>\n      <td>4</td>\n      <td>2</td>\n      <td>57</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2007</th>\n      <td>In what is quickly shaping up to be the bigge...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>531</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1587</th>\n      <td>The Law of Attraction, made popular by 'The S...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>534</td>\n      <td>0</td>\n      <td>7</td>\n      <td>7</td>\n      <td>20</td>\n      <td>7</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>1775</th>\n      <td>Tweet (NewsTarget) California governor Arnold...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>565</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>20</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1756</th>\n      <td>If you're 'Ready for Hillary' in 2016, you mi...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>574</td>\n      <td>4</td>\n      <td>6</td>\n      <td>0</td>\n      <td>18</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1644</th>\n      <td>With a sad twist of irony, corporate and gove...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>576</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1863</th>\n      <td>It recently went public that the Obama admini...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>583</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>20</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1987</th>\n      <td>He was widely panned for it, but former Texas...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>596</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>14</td>\n      <td>13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2156</th>\n      <td>Army Veteran Donald Siefkin wasn't asking for...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>597</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>21</td>\n      <td>10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2104</th>\n      <td>The number of illegal immigrants arriving via...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>604</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>30</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1754</th>\n      <td>In Brave New America, simply acknowledging th...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>606</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0</td>\n      <td>3</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2051</th>\n      <td>In approximately 25 years, fresh water may be...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>615</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>49</td>\n      <td>8</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1683</th>\n      <td>During his first campaign for president, then...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>618</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>32</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1786</th>\n      <td>In the wake of revelations - thanks in every ...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>621</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>29</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1814</th>\n      <td>The White House has been caught in yet anothe...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>624</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>9</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1641</th>\n      <td>The president of the United States has his pr...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>625</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"a,b,c = avhan.visualize_attention(test_df.loc[561], MAX_SENT_LEN, MAX_NUM_SENT, preprocess_label=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:53:19.884434Z","iopub.execute_input":"2024-04-17T07:53:19.884917Z","iopub.status.idle":"2024-04-17T07:53:19.927009Z","shell.execute_reply.started":"2024-04-17T07:53:19.884883Z","shell.execute_reply":"2024-04-17T07:53:19.926178Z"},"trusted":true},"execution_count":222,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<p style=\"font-size:18px\"> Ground Truth: Satire&emsp;&emsp;&emsp;Prediction: Satire</p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.24200034141540527);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.12800093275906924);font-size:16px;\">cnn</span> <span style=\"background-color:rgba(0,0,255,0.0686656732192339);font-size:16px;\">apologized</span> <span style=\"background-color:rgba(0,0,255,0.023735232263345278);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.03139357901777049);font-size:16px;\">its</span> <span style=\"background-color:rgba(0,0,255,0.04592112639376344);font-size:16px;\">viewers</span> <span style=\"background-color:rgba(0,0,255,0.03297088506997794);font-size:16px;\">today</span> <span style=\"background-color:rgba(0,0,255,0.02809632537479983);font-size:16px;\">for</span> <span style=\"background-color:rgba(0,0,255,0.04498048909980942);font-size:16px;\">briefly</span> <span style=\"background-color:rgba(0,0,255,0.05424646468441979);font-size:16px;\">airing</span> <span style=\"background-color:rgba(0,0,255,0.011694496760459914);font-size:16px;\">a</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.013522807299843266);font-size:16px;\">story</span> <span style=\"background-color:rgba(0,0,255,0.006186737586989254);font-size:16px;\">on</span> <span style=\"background-color:rgba(0,0,255,0.006035391070540488);font-size:16px;\">sunday</span> <span style=\"background-color:rgba(0,0,255,0.000594714139850972);font-size:16px;\">that</span> <span style=\"background-color:rgba(0,0,255,0.0);font-size:16px;\">had</span> <span style=\"background-color:rgba(0,0,255,0.006083250916267387);font-size:16px;\">nothing</span> <span style=\"background-color:rgba(0,0,255,0.0011575253685266321);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.004128781753417192);font-size:16px;\">do</span> <span style=\"background-color:rgba(0,0,255,0.007408141100190395);font-size:16px;\">with</span> <span style=\"background-color:rgba(0,0,255,0.011685815890008213);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.023447332433060464);font-size:16px;\">missing</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.05884020775388262);font-size:16px;\">malaysia</span> <span style=\"background-color:rgba(0,0,255,0.053390606686742885);font-size:16px;\">airlines</span> <span style=\"background-color:rgba(0,0,255,0.0688980601869735);font-size:16px;\">flight</span> <span style=\"background-color:rgba(0,0,255,0.04763412665826261);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.1594906896352768);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.020649687691945987);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.01806528332357854);font-size:16px;\">story</span> <span style=\"background-color:rgba(0,0,255,0.008646701176333989);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.01616890932158344);font-size:16px;\">which</span> <span style=\"background-color:rgba(0,0,255,0.029477051111571808);font-size:16px;\">caused</span> <span style=\"background-color:rgba(0,0,255,0.019445070525178833);font-size:16px;\">thousands</span> <span style=\"background-color:rgba(0,0,255,0.013894376726604674);font-size:16px;\">of</span> <span style=\"background-color:rgba(0,0,255,0.022729155530379585);font-size:16px;\">viewers</span> <span style=\"background-color:rgba(0,0,255,0.011627106412791006);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.027408742458556182);font-size:16px;\">contact</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.012749780262664837);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.024212070591006957);font-size:16px;\">network</span> <span style=\"background-color:rgba(0,0,255,0.011138855219376497);font-size:16px;\">in</span> <span style=\"background-color:rgba(0,0,255,0.019359907712518405);font-size:16px;\">anger</span> <span style=\"background-color:rgba(0,0,255,0.003234946891362784);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.0027125262895308574);font-size:16px;\">had</span> <span style=\"background-color:rgba(0,0,255,0.004640105857272176);font-size:16px;\">something</span> <span style=\"background-color:rgba(0,0,255,0.005116338466443487);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.007460621025571788);font-size:16px;\">do</span> <span style=\"background-color:rgba(0,0,255,0.011782907475781665);font-size:16px;\">with</span> <span style=\"background-color:rgba(0,0,255,0.03097433474280984);font-size:16px;\">crimea</span> <span style=\"background-color:rgba(0,0,255,0.011159797107724308);font-size:16px;\">,</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.03868795194976976);font-size:16px;\">ukraine</span> <span style=\"background-color:rgba(0,0,255,0.012694811958309184);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.023550440378798432);font-size:16px;\">and</span> <span style=\"background-color:rgba(0,0,255,0.04992943166600428);font-size:16px;\">russia</span> <span style=\"background-color:rgba(0,0,255,0.03472092075275935);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.12299803644418716);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.010093119473519926);font-size:16px;\">in</span> <span style=\"background-color:rgba(0,0,255,0.009448084967218757);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.012868296658751758);font-size:16px;\">official</span> <span style=\"background-color:rgba(0,0,255,0.014594173455341478);font-size:16px;\">apology</span> <span style=\"background-color:rgba(0,0,255,0.00643498179435829);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.02652403866875466);font-size:16px;\">cnn</span> <span style=\"background-color:rgba(0,0,255,0.02058838454793205);font-size:16px;\">chief</span> <span style=\"background-color:rgba(0,0,255,0.023513236783770788);font-size:16px;\">jeff</span> <span style=\"background-color:rgba(0,0,255,0.02006761178976706);font-size:16px;\">zucker</span> <span style=\"background-color:rgba(0,0,255,0.004801311342946055);font-size:16px;\">wrote</span> <span style=\"background-color:rgba(0,0,255,9.357809542919335e-05);font-size:16px;\">,</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.0006071479116512968);font-size:16px;\">on</span> <span style=\"background-color:rgba(0,0,255,0.0014025631151565775);font-size:16px;\">sunday</span> <span style=\"background-color:rgba(0,0,255,0.0006888246952133639);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.002859542331954672);font-size:16px;\">we</span> <span style=\"background-color:rgba(0,0,255,0.007937976743716902);font-size:16px;\">briefly</span> <span style=\"background-color:rgba(0,0,255,0.004674681473790687);font-size:16px;\">cut</span> <span style=\"background-color:rgba(0,0,255,0.007356644247277597);font-size:16px;\">away</span> <span style=\"background-color:rgba(0,0,255,0.00613151254378937);font-size:16px;\">from</span> <span style=\"background-color:rgba(0,0,255,0.011810869359970423);font-size:16px;\">our</span> <span style=\"background-color:rgba(0,0,255,0.02522546625264316);font-size:16px;\">nonstop</span> <span style=\"background-color:rgba(0,0,255,0.015550009921839653);font-size:16px;\">coverage</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.008925258203804763);font-size:16px;\">of</span> <span style=\"background-color:rgba(0,0,255,0.016238086085855984);font-size:16px;\">flight</span> <span style=\"background-color:rgba(0,0,255,0.022970723204320517);font-size:16px;\">370</span> <span style=\"background-color:rgba(0,0,255,0.006366211604516508);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.010686967589795354);font-size:16px;\">talk</span> <span style=\"background-color:rgba(0,0,255,0.007798670855183193);font-size:16px;\">about</span> <span style=\"background-color:rgba(0,0,255,0.014694351880544517);font-size:16px;\">something</span> <span style=\"background-color:rgba(0,0,255,0.03439082976146793);font-size:16px;\">else</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.20533621311187744);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.046498688702378346);font-size:16px;\">were</span> <span style=\"background-color:rgba(0,0,255,0.03024411137347906);font-size:16px;\">not</span> <span style=\"background-color:rgba(0,0,255,0.03886646819640896);font-size:16px;\">going</span> <span style=\"background-color:rgba(0,0,255,0.036200423050911534);font-size:16px;\">to</span> <span style=\"background-color:rgba(0,0,255,0.1218194811302222);font-size:16px;\">sugarcoat</span> <span style=\"background-color:rgba(0,0,255,0.03433919140873926);font-size:16px;\">it</span> <span style=\"background-color:rgba(0,0,255,0.05036888212525839);font-size:16px;\">:</span> <span style=\"background-color:rgba(0,0,255,0.0552907778666426);font-size:16px;\">we</span> <span style=\"background-color:rgba(0,0,255,0.20533621311187744);font-size:16px;\">messed</span> <span style=\"background-color:rgba(0,0,255,0.11446427415928825);font-size:16px;\">up</span> <span style=\"background-color:rgba(0,0,255,0.11636646054406043);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,0.2701747417449951);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.18462358252074268);font-size:16px;\">cnn</span> <span style=\"background-color:rgba(0,0,255,0.12192390469922851);font-size:16px;\">regrets</span> <span style=\"background-color:rgba(0,0,255,0.04734815943184023);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.06829797851267416);font-size:16px;\">error</span> <span style=\"background-color:rgba(0,0,255,0.032604771279978684);font-size:16px;\">and</span> <span style=\"background-color:rgba(0,0,255,0.08450575802784707);font-size:16px;\">promises</span> <span style=\"background-color:rgba(0,0,255,0.052300251325189916);font-size:16px;\">our</span> <span style=\"background-color:rgba(0,0,255,0.050560102972480515);font-size:16px;\">viewers</span> <span style=\"background-color:rgba(0,0,255,0.020283860226074278);font-size:16px;\">that</span> <span style=\"background-color:rgba(0,0,255,0.03089278975774513);font-size:16px;\">it</span> <span style=\"background-color:rgba(0,0,255,0.11843866558609938);font-size:16px;\">wont</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.09777943071779445);font-size:16px;\">happen</span> <span style=\"background-color:rgba(0,0,255,0.07655611543207946);font-size:16px;\">again</span> <span style=\"background-color:rgba(0,0,255,0.07871297236991769);font-size:16px;\">.</span>"},"metadata":{}}]},{"cell_type":"code","source":"short_trusted = (test_df_categorised['lengths'] < 100) & (test_df_categorised['Label'] == 4)\ntest_df_categorised[(test_df_categorised['has_nums'] > 0) & short_trusted].head(20)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T08:20:45.389472Z","iopub.execute_input":"2024-04-16T08:20:45.389876Z","iopub.status.idle":"2024-04-16T08:20:45.411233Z","shell.execute_reply.started":"2024-04-16T08:20:45.389847Z","shell.execute_reply":"2024-04-16T08:20:45.410041Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":190,"outputs":[{"execution_count":190,"output_type":"execute_result","data":{"text/plain":"                                                   Text  Label  Category  \\\n2268  British American Tobacco announced Tuesday tha...      4         3   \n2318  The plaintiff in the lawsuit that legalized ab...      4         4   \n2334  Gold for current delivery closed at $1,107.80 ...      4         0   \n2399  Triple Olympic gold medalist Stephanie Rice sa...      4         5   \n2401  Singapore exchange to buy Australian bourse fo...      4         3   \n2407  West Indies beat England by five wickets under...      4         5   \n2413  Eurozone recovery falters in Q4 as economy gro...      4         0   \n2467  Coast Guard Adm. Thad Allen: cap now funneling...      4         3   \n2487  Spanish bank BBVA reported Wednesday its fourt...      4         3   \n2526  Results Thursday from the St. Petersburg Open ...      4         5   \n2542  Brome Howard Inn 18281 Rosecroft Rd., St. Mary...      4         3   \n2544  Results Sunday from the Japan Open, a $1.2 mil...      4         5   \n2556  Simone Hauswald of Germany mastered windy and ...      4         5   \n2563  Consumers increased their spending in June for...      4         0   \n2566  The United Network for Organ Sharing (UNOS) co...      4         2   \n2609  America picked up its first victory of the Mex...      4         5   \n2612  Norway's Marit Bjoergen has won the women's 10...      4         5   \n2629  A federal judge has sentenced former Democrati...      4         4   \n2666  Gold for current delivery closed at $1,159.70 ...      4         0   \n2686  Serbia coach Radomir Antic has reduced his squ...      4         5   \n\n      lengths  has_hedge  has_2p  has_1ps  has_nums  has_bri_ire_afh_am_hondu  \\\n2268       55          0       0        0         9                         3   \n2318       98          2       0        0         6                         2   \n2334       22          0       0        0        14                         1   \n2399       91          0       1        0         4                         0   \n2401       13          0       0        0         4                         1   \n2407       74          0       0        0        25                         0   \n2413       15          0       0        0         4                         0   \n2467       20          0       0        0         9                         0   \n2487       99          0       0        0        45                         0   \n2526       53          0       0        0        18                         7   \n2542       35          0       0        0        31                         1   \n2544       51          0       0        0        16                         1   \n2556       84          0       0        0        12                         0   \n2563       99          0       0        0         9                         0   \n2566       55          0       0        0        37                         0   \n2609       89          0       0        0        12                         2   \n2612       73          0       0        0        14                         2   \n2629       95          0       0        0        19                         2   \n2666       22          0       0        0        14                         1   \n2686       88          0       0        0         7                         0   \n\n      has_days  \n2268         1  \n2318         0  \n2334         2  \n2399         1  \n2401         0  \n2407         1  \n2413         0  \n2467         0  \n2487         1  \n2526         1  \n2542         3  \n2544         1  \n2556         1  \n2563         0  \n2566         0  \n2609         2  \n2612         2  \n2629         1  \n2666         2  \n2686         1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Category</th>\n      <th>lengths</th>\n      <th>has_hedge</th>\n      <th>has_2p</th>\n      <th>has_1ps</th>\n      <th>has_nums</th>\n      <th>has_bri_ire_afh_am_hondu</th>\n      <th>has_days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2268</th>\n      <td>British American Tobacco announced Tuesday tha...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>55</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2318</th>\n      <td>The plaintiff in the lawsuit that legalized ab...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>98</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2334</th>\n      <td>Gold for current delivery closed at $1,107.80 ...</td>\n      <td>4</td>\n      <td>0</td>\n      <td>22</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2399</th>\n      <td>Triple Olympic gold medalist Stephanie Rice sa...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>91</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2401</th>\n      <td>Singapore exchange to buy Australian bourse fo...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2407</th>\n      <td>West Indies beat England by five wickets under...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>74</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>25</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2413</th>\n      <td>Eurozone recovery falters in Q4 as economy gro...</td>\n      <td>4</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2467</th>\n      <td>Coast Guard Adm. Thad Allen: cap now funneling...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2487</th>\n      <td>Spanish bank BBVA reported Wednesday its fourt...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>99</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>45</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2526</th>\n      <td>Results Thursday from the St. Petersburg Open ...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>53</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2542</th>\n      <td>Brome Howard Inn 18281 Rosecroft Rd., St. Mary...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>35</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>31</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2544</th>\n      <td>Results Sunday from the Japan Open, a $1.2 mil...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>51</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2556</th>\n      <td>Simone Hauswald of Germany mastered windy and ...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2563</th>\n      <td>Consumers increased their spending in June for...</td>\n      <td>4</td>\n      <td>0</td>\n      <td>99</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2566</th>\n      <td>The United Network for Organ Sharing (UNOS) co...</td>\n      <td>4</td>\n      <td>2</td>\n      <td>55</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2609</th>\n      <td>America picked up its first victory of the Mex...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>89</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2612</th>\n      <td>Norway's Marit Bjoergen has won the women's 10...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>73</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2629</th>\n      <td>A federal judge has sentenced former Democrati...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>95</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>19</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2666</th>\n      <td>Gold for current delivery closed at $1,159.70 ...</td>\n      <td>4</td>\n      <td>0</td>\n      <td>22</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2686</th>\n      <td>Serbia coach Radomir Antic has reduced his squ...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>88</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"a,b,c = av.visualize_attention(test_df_categorised.loc[2467], MAX_SENT_LEN, MAX_NUM_SENT, preprocess_label=True)\na,b,c = av.visualize_attention(test_df_categorised.loc[2334], MAX_SENT_LEN, MAX_NUM_SENT, preprocess_label=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T09:34:37.166425Z","iopub.execute_input":"2024-04-16T09:34:37.166836Z","iopub.status.idle":"2024-04-16T09:34:37.204477Z","shell.execute_reply.started":"2024-04-16T09:34:37.166806Z","shell.execute_reply":"2024-04-16T09:34:37.203358Z"},"trusted":true},"execution_count":290,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<p style=\"font-size:18px\"> Ground Truth: Trusted&emsp;&emsp;&emsp;Prediction: Trusted</p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,1.0);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.04612308740615845);font-size:16px;\">coast</span> <span style=\"background-color:rgba(0,0,255,0.04704555124044418);font-size:16px;\">guard</span> <span style=\"background-color:rgba(0,0,255,0.0670442059636116);font-size:16px;\">adm.</span> <span style=\"background-color:rgba(0,0,255,0.07110335677862167);font-size:16px;\">thad</span> <span style=\"background-color:rgba(0,0,255,0.04284561425447464);font-size:16px;\">allen</span> <span style=\"background-color:rgba(0,0,255,0.02684144489467144);font-size:16px;\">:</span> <span style=\"background-color:rgba(0,0,255,0.04974472522735596);font-size:16px;\">cap</span> <span style=\"background-color:rgba(0,0,255,0.03876177594065666);font-size:16px;\">now</span> <span style=\"background-color:rgba(0,0,255,0.1004386618733406);font-size:16px;\">funneling</span> <span style=\"background-color:rgba(0,0,255,0.07699908316135406);font-size:16px;\">462,000</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.04530829191207886);font-size:16px;\">gallons</span> <span style=\"background-color:rgba(0,0,255,0.034812189638614655);font-size:16px;\">(</span> <span style=\"background-color:rgba(0,0,255,0.045579664409160614);font-size:16px;\">1.7</span> <span style=\"background-color:rgba(0,0,255,0.026468364521861076);font-size:16px;\">million</span> <span style=\"background-color:rgba(0,0,255,0.0351150780916214);font-size:16px;\">liters</span> <span style=\"background-color:rgba(0,0,255,0.019862961024045944);font-size:16px;\">)</span> <span style=\"background-color:rgba(0,0,255,0.01809554174542427);font-size:16px;\">of</span> <span style=\"background-color:rgba(0,0,255,0.023657288402318954);font-size:16px;\">oil</span> <span style=\"background-color:rgba(0,0,255,0.01755109801888466);font-size:16px;\">a</span> <span style=\"background-color:rgba(0,0,255,0.01983649656176567);font-size:16px;\">day</span> <span style=\"background-color:rgba(0,0,255,0.023630375042557716);font-size:16px;\">from</span> <span style=\"background-color:rgba(0,0,255,0.04681131988763809);font-size:16px;\">gulf</span> <span style=\"background-color:rgba(0,0,255,0.043448325246572495);font-size:16px;\">spill</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.03287554532289505);font-size:16px;\">.</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<p style=\"font-size:18px\"> Ground Truth: Trusted&emsp;&emsp;&emsp;Prediction: Trusted</p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"background-color:rgba(255,0,0,1.0);font-size:16px;color:rgba(255,0,0,0);\">_____</span> <span style=\"background-color:rgba(0,0,255,0.035253413021564484);font-size:16px;\">gold</span> <span style=\"background-color:rgba(0,0,255,0.021404463797807693);font-size:16px;\">for</span> <span style=\"background-color:rgba(0,0,255,0.028654640540480614);font-size:16px;\">current</span> <span style=\"background-color:rgba(0,0,255,0.02937629260122776);font-size:16px;\">delivery</span> <span style=\"background-color:rgba(0,0,255,0.03306358680129051);font-size:16px;\">closed</span> <span style=\"background-color:rgba(0,0,255,0.0252033993601799);font-size:16px;\">at</span> <span style=\"background-color:rgba(0,0,255,0.03220895305275917);font-size:16px;\">\\$</span> <span style=\"background-color:rgba(0,0,255,0.07705462723970413);font-size:16px;\">1,107.80</span> <span style=\"background-color:rgba(0,0,255,0.04180104285478592);font-size:16px;\">per</span> <span style=\"background-color:rgba(0,0,255,0.03937329351902008);font-size:16px;\">troy</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.032713644206523895);font-size:16px;\">ounce</span> <span style=\"background-color:rgba(0,0,255,0.02076738514006138);font-size:16px;\">thursday</span> <span style=\"background-color:rgba(0,0,255,0.020397823303937912);font-size:16px;\">on</span> <span style=\"background-color:rgba(0,0,255,0.021511899307370186);font-size:16px;\">the</span> <span style=\"background-color:rgba(0,0,255,0.02474067360162735);font-size:16px;\">new</span> <span style=\"background-color:rgba(0,0,255,0.030498450621962547);font-size:16px;\">york</span> <span style=\"background-color:rgba(0,0,255,0.04653860628604889);font-size:16px;\">mercantile</span> <span style=\"background-color:rgba(0,0,255,0.03625035658478737);font-size:16px;\">exchange</span> <span style=\"background-color:rgba(0,0,255,0.019604403525590897);font-size:16px;\">,</span> <span style=\"background-color:rgba(0,0,255,0.030437614768743515);font-size:16px;\">up</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<span style=\"color:rgba(255,255,255,0);font-size:16px\">_____</span> <span style=\"background-color:rgba(0,0,255,0.031183507293462753);font-size:16px;\">from</span> <span style=\"background-color:rgba(0,0,255,0.04347136616706848);font-size:16px;\">\\$</span> <span style=\"background-color:rgba(0,0,255,0.09160143882036209);font-size:16px;\">1,096.50</span> <span style=\"background-color:rgba(0,0,255,0.04823124781250954);font-size:16px;\">late</span> <span style=\"background-color:rgba(0,0,255,0.092160165309906);font-size:16px;\">wedensday</span> <span style=\"background-color:rgba(0,0,255,0.04649776220321655);font-size:16px;\">.</span>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 2. FAN Analysis","metadata":{}},{"cell_type":"markdown","source":"First, define the model:","metadata":{}},{"cell_type":"code","source":"class AttentionUnit(nn.Module):\n    def __init__(self, input_dim, hidden_dim=None, num_outputs=1, attn_dropout=0.0):\n        super(AttentionUnit, self).__init__()\n        if hidden_dim is None:\n            hidden_dim = input_dim\n        self.hidden = nn.Linear(input_dim, hidden_dim)\n        self.query = nn.Linear(hidden_dim, num_outputs, bias=False)\n    def forward(self, encoder_output, padding_positions=None, return_weights=False):\n        #Calculate u_{i} = tanh(Wh_{i}+b) [B,L,H]-->[B,L,H]\n        hidden_rep = F.tanh(self.hidden(encoder_output))\n        #Calculate a_{i} = softmax(u_{i}^Tc) with masking [B,L,H]-->[B,L,1]\n        similarity = self.query(hidden_rep)\n        if padding_positions is not None:\n            similarity = similarity.masked_fill(padding_positions, -float('inf'))\n        attention_weights = F.softmax(similarity, dim=1)\n        #Return weighted sum [B,L,1], [B,L,H]-->[B,H]\n        if return_weights:\n            return torch.bmm(attention_weights.transpose(1,2), hidden_rep).squeeze(1), attention_weights\n        return torch.bmm(attention_weights.transpose(1,2), hidden_rep).squeeze(1)\n\nclass LSTMFlatAttentionFCNNClassifier(torch.nn.Module):\n    '''\n    Classifier that uses an LSTM as an encoder followed by an attention block\n    and a Fully-Connected Neural Network(FCNN) as a decoder.\n    '''\n    def __init__(self, vocab_len, embed_dim, hidden_dim, num_lstm_layers, num_classes, attn_dropout=0.0, pretrained_embeddings=None, freeze_embeds=False):\n        super(LSTMFlatAttentionFCNNClassifier, self).__init__()\n        if pretrained_embeddings is not None:\n            self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=freeze_embeds)\n        else:\n            self.embedding = nn.Embedding(num_embeddings=vocab_len, embedding_dim=embed_dim)\n\n        self.encoder = nn.LSTM(input_size=embed_dim, hidden_size=hidden_dim, num_layers=num_lstm_layers, batch_first=True, bidirectional=True)\n        self.attn = AttentionUnit(2*hidden_dim)\n        self.decoder = nn.Linear(2*hidden_dim, num_classes)\n\n    def forward(self, X_batch, lengths, return_attn_weights=False):\n        embeddings = self.embedding(X_batch)\n\n        embeddings = nn.utils.rnn.pack_padded_sequence(embeddings, lengths.cpu(), enforce_sorted=False, batch_first=True)\n        output, (_, _) = self.encoder(embeddings)\n        output, _ = nn.utils.rnn.pad_packed_sequence(output,batch_first=True)\n\n        padding_positions = self.__get_padding_masks(lengths).to(output.device)\n        doc_embeddings = self.attn(output,padding_positions=padding_positions,return_weights=return_attn_weights)\n        \n        if return_attn_weights:\n            return self.decoder(doc_embeddings[0]), doc_embeddings[1]\n        else:\n            return self.decoder(doc_embeddings)\n    \n    def __get_padding_masks(self, lengths):\n        '''\n        Returns a mask (shape BxLx1) that indicates the position of pad tokens\n        '''\n        max_len = lengths.max()\n        return torch.tensor([[False]*i + [True]*(max_len-i) for i in lengths]).unsqueeze(2)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:35:40.104136Z","iopub.execute_input":"2024-04-17T06:35:40.104761Z","iopub.status.idle":"2024-04-17T06:35:40.130936Z","shell.execute_reply.started":"2024-04-17T06:35:40.104709Z","shell.execute_reply":"2024-04-17T06:35:40.128394Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 1. Categorized evals","metadata":{}},{"cell_type":"markdown","source":"Set hyperparameters and load model","metadata":{}},{"cell_type":"code","source":"MODEL_MAX_LEN = 500\nNUM_CLASSES = 4\nEMBED_DIM = 100\nHIDDEN_DIM = 100\nNUM_LSTM_LAYERS = 1\n\nVOCAB_LEN = 400001 #harcoded for convenience; see below for how it was obtained\n# glove, _ = DataPreprocessorFlat.from_pretrained_embeds(NUM_CLASSES,'/kaggle/input/lun-glove/glove.6B.100d.txt', EMBED_DIM)\n# VOCAB_LEN = len(glove.vocab)\n\nMODEL_PATH = './outputs/model/bestFAN_ml500_ba256_emb100hid100lay1cla4_ep10lr0.0005wd5e-06_af0.5ap2_model.pt'\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ncollate_fn = make_flat_collate_function(MODEL_MAX_LEN)\nmodel = LSTMFlatAttentionFCNNClassifier(VOCAB_LEN, EMBED_DIM, HIDDEN_DIM, NUM_LSTM_LAYERS, NUM_CLASSES)\nmodel.to(DEVICE)\nmodel.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:21:30.203887Z","iopub.execute_input":"2024-04-16T17:21:30.204288Z","iopub.status.idle":"2024-04-16T17:21:33.830329Z","shell.execute_reply.started":"2024-04-16T17:21:30.204257Z","shell.execute_reply":"2024-04-16T17:21:33.829088Z"},"trusted":true},"execution_count":115,"outputs":[{"execution_count":115,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"Load Preprocessed test data and sub-categorized test data","metadata":{"execution":{"iopub.status.busy":"2024-04-11T12:15:02.320834Z","iopub.execute_input":"2024-04-11T12:15:02.321256Z","iopub.status.idle":"2024-04-11T12:15:04.003140Z","shell.execute_reply.started":"2024-04-11T12:15:02.321225Z","shell.execute_reply":"2024-04-11T12:15:04.002122Z"}}},{"cell_type":"code","source":"X_test = pd.read_parquet('./FAN_prepro_data/X_test_prep_flat.parquet')['Text']\ny_test = pd.read_parquet('./FAN_prepro_data/y_test_prep_flat.parquet')['Label']\nembeds = torch.tensor(np.load('./glove_embs.npy'))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:22:17.171551Z","iopub.execute_input":"2024-04-16T17:22:17.171935Z","iopub.status.idle":"2024-04-16T17:22:19.658270Z","shell.execute_reply.started":"2024-04-16T17:22:17.171905Z","shell.execute_reply":"2024-04-16T17:22:19.657318Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"test_df_categorised = pd.read_csv('/kaggle/input/lun-glove/balancedtestwithclass_new_cleaned.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:04:56.921848Z","iopub.execute_input":"2024-04-17T07:04:56.922388Z","iopub.status.idle":"2024-04-17T07:04:57.143552Z","shell.execute_reply.started":"2024-04-17T07:04:56.922351Z","shell.execute_reply":"2024-04-17T07:04:57.142409Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\ndef categorised_eval_flat(categories_df, X, ylens, model, device, category_list=[0,1,2,3,4,5]):\n    records = {'category':[], 'support':[], 'acc':[], 'f1':[], 'precision':[], 'recall':[]}\n    all_preds = []\n    all_truths = []\n    idxes = []\n    for cat in category_list:\n        idx = categories_df[categories_df['Category']==cat].index\n        ylens_cat = ylens.loc[idx]\n        X_cat = X.loc[idx]\n        loader = DataLoader(WrapperDatasetFlat(X_cat, ylens_cat),\n                          batch_size=128,\n                          collate_fn=collate_fn,\n                          shuffle=False)\n        model.to(device)\n        preds=[]\n        truths=[]\n        for X_batch, lengths, y_batch in tqdm(loader):\n            #Move to correct device\n            X_batch = X_batch.to(device)\n\n            #Forward pass\n            outputs = model(X_batch, lengths)\n            if type(outputs)==tuple:\n                logits = outputs[0]\n            else:\n                logits = outputs\n\n            #Logging\n            preds.append(torch.argmax(logits, dim=-1).cpu())\n            truths.append(y_batch)\n        preds = torch.cat(preds)\n        truths = torch.cat(truths)\n        records['category'].append(cat)\n        records['support'].append(len(X_cat))\n        records['acc'].append(accuracy_score(truths, preds))\n        records['f1'].append(f1_score(truths, preds, average='macro'))\n        records['precision'].append(precision_score(truths, preds, average='macro'))\n        records['recall'].append(recall_score(truths, preds, average='macro'))\n        all_preds.append(preds)\n        all_truths.append(truths)\n        idxes.append(idx)\n    return records, all_preds, all_truths, idxes","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:04:20.886093Z","iopub.execute_input":"2024-04-17T07:04:20.886780Z","iopub.status.idle":"2024-04-17T07:04:20.903767Z","shell.execute_reply.started":"2024-04-17T07:04:20.886738Z","shell.execute_reply":"2024-04-17T07:04:20.902603Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"results = categorised_eval_flat(test_df_categorised, X_test_flat, y_test_flat, model, DEVICE, category_list=[0,1,2,3,4,5])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:05:25.314144Z","iopub.execute_input":"2024-04-17T07:05:25.314617Z","iopub.status.idle":"2024-04-17T07:05:44.449047Z","shell.execute_reply.started":"2024-04-17T07:05:25.314585Z","shell.execute_reply":"2024-04-17T07:05:44.447750Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stderr","text":"100%|██████████| 2/2 [00:00<00:00,  2.10it/s]\n100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n100%|██████████| 5/5 [00:03<00:00,  1.26it/s]\n100%|██████████| 8/8 [00:05<00:00,  1.37it/s]\n100%|██████████| 9/9 [00:06<00:00,  1.33it/s]\n100%|██████████| 2/2 [00:00<00:00,  2.15it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(results)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T07:48:01.353422Z","iopub.execute_input":"2024-04-15T07:48:01.353786Z","iopub.status.idle":"2024-04-15T07:48:01.368995Z","shell.execute_reply.started":"2024-04-15T07:48:01.353757Z","shell.execute_reply":"2024-04-15T07:48:01.368156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(results).to_csv('./outputs/FAN_categorized_eval_results.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T07:48:25.792374Z","iopub.execute_input":"2024-04-15T07:48:25.792776Z","iopub.status.idle":"2024-04-15T07:48:25.800877Z","shell.execute_reply.started":"2024-04-15T07:48:25.792745Z","shell.execute_reply":"2024-04-15T07:48:25.799641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(test_df_categorised[test_df_categorised['Category']==2]['Label'], test_df_categorised[test_df_categorised['Category']==2]['pred_fan']))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:27:19.731707Z","iopub.execute_input":"2024-04-16T17:27:19.732140Z","iopub.status.idle":"2024-04-16T17:27:19.749990Z","shell.execute_reply.started":"2024-04-16T17:27:19.732102Z","shell.execute_reply":"2024-04-16T17:27:19.748861Z"},"trusted":true},"execution_count":144,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           1       0.41      0.69      0.51        16\n           2       0.33      0.22      0.27        18\n           3       0.96      0.70      0.81       493\n           4       0.18      0.88      0.29        32\n\n    accuracy                           0.70       559\n   macro avg       0.47      0.62      0.47       559\nweighted avg       0.88      0.70      0.75       559\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Visualize attention","metadata":{}},{"cell_type":"code","source":"class AttnVizPreprocessorFlat():\n\n    def __init__(self, data_vocab):\n        self.vocab = data_vocab\n        print(\"Vocab created: {} unique tokens\".format(len(self.vocab)))\n        \n    @classmethod\n    def from_pretrained_embeds(cls, embed_path, embed_dim, sep=\" \",  specials=['<unk>']):\n        # start with all '0's for special tokens\n        embeds = [np.asarray([0]*embed_dim, dtype=np.float32)]*len(specials)\n        words = OrderedDict()\n        with open(embed_path, encoding=\"utf-8\") as f:\n            for i, line in enumerate(f):\n                if i == 38522 and 'twitter.27B.100d' in embed_path:\n                    continue\n                splitline = line.split()\n                \n                word = splitline[0]\n                if word not in words:\n                    words[word] = 0\n                words[word]+=1\n                embeds.append(np.asarray(splitline[1:], dtype=np.float32))\n                \n        embeds = torch.tensor(np.array(embeds))\n        data_vocab = vocab(words, specials=specials)\n        data_vocab.set_default_index(data_vocab['<unk>'])\n        return cls(data_vocab)\n\n    def get_vocab_size(self):\n        return len(self.vocab)\n    \n    def preprocess_single_row(self, row, model_max_len, preprocess_label=False):\n        '''\n        Converts text into integers that index the vocab,\n        and converts labels into the range [0,num_classes-1]\n        \n        Return tokens by sentence (unpadded), idx by sentence (padded), label, num_sentences, num_tokens\n        '''\n        text = row['Text']\n        label = row['Label']\n        \n        words = [word_tokenize(sent.lower()) for sent in sent_tokenize(text.replace(\"'\",\"\"))]\n        words = [word for sent in words for word in sent][:model_max_len] # flatten and truncate\n        token_idxs = self.vocab(words)\n        num_tokens = len(token_idxs)\n        \n        if preprocess_label:\n            label -= 1\n        return words, torch.tensor(token_idxs, dtype=torch.long), label,\\\n                torch.tensor(num_tokens, dtype=torch.long).unsqueeze(0)\n                \n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-17T06:44:24.546115Z","iopub.execute_input":"2024-04-17T06:44:24.547321Z","iopub.status.idle":"2024-04-17T06:44:24.563610Z","shell.execute_reply.started":"2024-04-17T06:44:24.547255Z","shell.execute_reply":"2024-04-17T06:44:24.561703Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"MODEL_MAX_LEN = 500\nNUM_CLASSES = 4\nEMBED_DIM = 100\nHIDDEN_DIM = 100\nNUM_LSTM_LAYERS = 1\n\nVOCAB_LEN = 400001 #harcoded for convenience; see below for how it was obtained\n# glove, _ = DataPreprocessorFlat.from_pretrained_embeds(NUM_CLASSES,'/kaggle/input/lun-glove/glove.6B.100d.txt', EMBED_DIM)\n# VOCAB_LEN = len(glove.vocab)\n\nEMBED_PATH = '../glove.6B.100d.txt'\nMODEL_PATH = './outputs/model/bestFAN_ml500_ba256_emb100hid100lay1cla4_ep10lr0.0005wd5e-06_af0.5ap2_model.pt'\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ncollate_fn = make_flat_collate_function(MODEL_MAX_LEN)\nmodel = LSTMFlatAttentionFCNNClassifier(VOCAB_LEN, EMBED_DIM, HIDDEN_DIM, NUM_LSTM_LAYERS, NUM_CLASSES)\nmodel.to(DEVICE)\nmodel.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\nppflat = AttnVizPreprocessorFlat.from_pretrained_embeds(EMBED_PATH, EMBED_DIM)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:21:13.703391Z","iopub.execute_input":"2024-04-17T07:21:13.704127Z","iopub.status.idle":"2024-04-17T07:21:29.193648Z","shell.execute_reply.started":"2024-04-17T07:21:13.704092Z","shell.execute_reply":"2024-04-17T07:21:29.192194Z"},"trusted":true},"execution_count":144,"outputs":[{"name":"stdout","text":"Vocab created: 400001 unique tokens\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport torch\nimport json\nfrom IPython.display import Markdown, display\n\nlabelid2label = ['Satire', 'Hoax', 'Propaganda', 'Trusted']\n\nclass AttentionVisualizerFlat():\n    def __init__(self, model, preprocessor):\n        \n        self.model = model\n        self.preprocessor = preprocessor\n\n    def visualize_attention(self, doc_and_label_row, model_max_len, device='cpu', preprocess_label=False):\n        # doc_and_label_row should contain a row of the df with columns ['Text'] and ['Label']\n        \n        words, X, y, num_tokens = self.preprocessor.preprocess_single_row(doc_and_label_row, model_max_len, preprocess_label)\n        pred, word_weights = self.model(X.unsqueeze(0), num_tokens, return_attn_weights=True)\n        pred = torch.argmax(pred, dim = -1).cpu().item()\n        word_weights = word_weights.squeeze(0,2).cpu()\n        \n        max_weight = word_weights.max()\n        min_weight = word_weights.min()\n        line = []\n        line_length = 0\n        \n        display(Markdown('<p style=\"font-size:18px\"> Ground Truth: '+ labelid2label[y] + '&emsp;&emsp;&emsp;Prediction: '+labelid2label[pred] +'</p>'))\n        \n        for word, weight in zip(words, word_weights):\n            line_length += len(word)\n            line.append(self.__make_word(word, self.__scale_weight(weight, max_weight, min_weight)))\n            if line_length > 60:\n                display(Markdown(\" \".join(line)))\n                line = []\n                line_length = 0\n        if len(line) > 0:\n            display(Markdown(\" \".join(line)))\n        return words, pred, word_weights\n    \n    def __make_word(self, word, word_weight):\n        return '<span style=\"background-color:rgba(0,0,255,' +\\\n                        str(word_weight.item()) + ');font-size:16px;\">' +\\\n                        word.replace('$', '\\$').replace(\"'\", \"\\'\") + '</span>'\n\n    def __scale_weight(self, orig_weight, max_weight, min_weight):\n        return (orig_weight-min_weight)/(max_weight-min_weight) * 0.5\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:01:03.208836Z","iopub.execute_input":"2024-04-17T07:01:03.209303Z","iopub.status.idle":"2024-04-17T07:01:03.225836Z","shell.execute_reply.started":"2024-04-17T07:01:03.209257Z","shell.execute_reply":"2024-04-17T07:01:03.224150Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"avflat = AttentionVisualizerFlat(model, ppflat)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:01:04.366396Z","iopub.execute_input":"2024-04-17T07:01:04.366861Z","iopub.status.idle":"2024-04-17T07:01:04.373121Z","shell.execute_reply.started":"2024-04-17T07:01:04.366829Z","shell.execute_reply":"2024-04-17T07:01:04.371745Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/lun-glove/balancedtest.csv', header=None, names=['Label', 'Text'])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:07:22.933117Z","iopub.execute_input":"2024-04-17T12:07:22.933588Z","iopub.status.idle":"2024-04-17T12:07:23.181339Z","shell.execute_reply.started":"2024-04-17T12:07:22.933556Z","shell.execute_reply":"2024-04-17T12:07:23.179857Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X_test_flat = pd.read_parquet('./FAN_prepro_data/X_test_prep_flat.parquet')['Text']\ny_test_flat = pd.read_parquet('./FAN_prepro_data/y_test_prep_flat.parquet')['Label']","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:03:50.563859Z","iopub.execute_input":"2024-04-17T07:03:50.564356Z","iopub.status.idle":"2024-04-17T07:03:50.871165Z","shell.execute_reply.started":"2024-04-17T07:03:50.564319Z","shell.execute_reply":"2024-04-17T07:03:50.869685Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"def predic(te):\n    w, tok, lab, pad = ppflat.preprocess_single_row({'Text':te, 'Label':1}, 500, False)\n    pred = model(tok.unsqueeze(0), pad, return_attn_weights=False)\n    return torch.argmax(pred, dim = -1).cpu().item()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:21:39.041396Z","iopub.execute_input":"2024-04-17T07:21:39.043972Z","iopub.status.idle":"2024-04-17T07:21:39.051650Z","shell.execute_reply.started":"2024-04-17T07:21:39.043925Z","shell.execute_reply":"2024-04-17T07:21:39.049771Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"code","source":"test_df['pred_flat_2'] = -1\ntest_df['pred_flat_2'] = test_df['Text'].apply(predic)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:21:39.550946Z","iopub.execute_input":"2024-04-17T07:21:39.551402Z","iopub.status.idle":"2024-04-17T07:25:35.375005Z","shell.execute_reply.started":"2024-04-17T07:21:39.551371Z","shell.execute_reply":"2024-04-17T07:25:35.373752Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"test_df['pred_flat'] = -1\ntest_df['truths'] = -1\nfor p, t, i in zip(results[1],results[2],results[3]):\n    test_df.loc[i, 'pred_flat'] = p.tolist()\n    test_df.loc[i, 'truths'] = t.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:08:32.545705Z","iopub.execute_input":"2024-04-17T07:08:32.546935Z","iopub.status.idle":"2024-04-17T07:08:32.564228Z","shell.execute_reply.started":"2024-04-17T07:08:32.546894Z","shell.execute_reply":"2024-04-17T07:08:32.562948Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"test_df['length'] = test_df['Text'].apply(lambda s: len(s.split()))","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:26:50.357285Z","iopub.execute_input":"2024-04-17T07:26:50.357804Z","iopub.status.idle":"2024-04-17T07:26:50.481103Z","shell.execute_reply.started":"2024-04-17T07:26:50.357771Z","shell.execute_reply":"2024-04-17T07:26:50.479762Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"test_df[(test_df['pred_hier']==test_df['pred_flat']) & (test_df['pred_hier']==test_df['truths'])  & (test_df['length'] < 100) & (test_df['pred_flat'] == 3) & (test_df['Text'].apply(lambda t: re.search(r'[0-9]', t) is not None))]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T08:31:12.157644Z","iopub.execute_input":"2024-04-17T08:31:12.158139Z","iopub.status.idle":"2024-04-17T08:31:12.237273Z","shell.execute_reply.started":"2024-04-17T08:31:12.158107Z","shell.execute_reply":"2024-04-17T08:31:12.235812Z"},"trusted":true},"execution_count":258,"outputs":[{"execution_count":258,"output_type":"execute_result","data":{"text/plain":"      Label                                               Text  pred_flat  \\\n2268      4  British American Tobacco announced Tuesday tha...          3   \n2334      4  Gold for current delivery closed at $1,107.80 ...          3   \n2399      4  Triple Olympic gold medalist Stephanie Rice sa...          3   \n2401      4  Singapore exchange to buy Australian bourse fo...          3   \n2407      4  West Indies beat England by five wickets under...          3   \n2413      4  Eurozone recovery falters in Q4 as economy gro...          3   \n2467      4  Coast Guard Adm. Thad Allen: cap now funneling...          3   \n2487      4  Spanish bank BBVA reported Wednesday its fourt...          3   \n2526      4  Results Thursday from the St. Petersburg Open ...          3   \n2542      4  Brome Howard Inn 18281 Rosecroft Rd., St. Mary...          3   \n2544      4  Results Sunday from the Japan Open, a $1.2 mil...          3   \n2556      4  Simone Hauswald of Germany mastered windy and ...          3   \n2563      4  Consumers increased their spending in June for...          3   \n2609      4  America picked up its first victory of the Mex...          3   \n2612      4  Norway's Marit Bjoergen has won the women's 10...          3   \n2629      4  A federal judge has sentenced former Democrati...          3   \n2666      4  Gold for current delivery closed at $1,159.70 ...          3   \n2686      4  Serbia coach Radomir Antic has reduced his squ...          3   \n2702      4  Unemployment in Britain for the three months e...          3   \n2731      4  German consumer goods company Beiersdorf repor...          3   \n2760      4  Share prices on the London Stock Exchange were...          3   \n2825      4  Scores at lunch Tuesday on the first day of th...          3   \n2830      4  Sevilla's Diego Perotti will be sidelined for ...          3   \n2833      4  Attacking midfielder Marek Hamsik has extended...          3   \n2877      4  The United States beat Russia 4-3 on Sunday fo...          3   \n2879      4  Pakistan has been bowled out for 296 on the fo...          3   \n2884      4  Netherlands becomes first team to qualify for ...          3   \n2892      4  Death toll from Indonesian volcano climbs to 9...          3   \n2930      4  Montenegro's government on Thursday canceled a...          3   \n2967      4  Barbados international and former Millwall for...          3   \n2981      4  Dominican Republic cyclist Leonardo Grullon ha...          3   \n2997      4  River Plate midfielder Diego Buonanotte has un...          3   \n\n      truths  pred_hier  pred_flat_2  length  \n2268       3          3            3      55  \n2334       3          3            3      22  \n2399       3          3            3      91  \n2401       3          3            3      13  \n2407       3          3            3      74  \n2413       3          3            3      15  \n2467       3          3            3      20  \n2487       3          3            3      99  \n2526       3          3            3      53  \n2542       3          3            3      35  \n2544       3          3            3      51  \n2556       3          3            3      84  \n2563       3          3            3      99  \n2609       3          3            3      89  \n2612       3          3            3      73  \n2629       3          3            3      95  \n2666       3          3            3      22  \n2686       3          3            3      88  \n2702       3          3            3      87  \n2731       3          3            3      86  \n2760       3          3            3      24  \n2825       3          3            3      40  \n2830       3          3            3      86  \n2833       3          3            3      86  \n2877       3          3            3      71  \n2879       3          3            3      74  \n2884       3          3            3      13  \n2892       3          3            3      11  \n2930       3          3            3      98  \n2967       3          3            3      75  \n2981       3          3            3      96  \n2997       3          3            3      96  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Text</th>\n      <th>pred_flat</th>\n      <th>truths</th>\n      <th>pred_hier</th>\n      <th>pred_flat_2</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2268</th>\n      <td>4</td>\n      <td>British American Tobacco announced Tuesday tha...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>2334</th>\n      <td>4</td>\n      <td>Gold for current delivery closed at $1,107.80 ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>2399</th>\n      <td>4</td>\n      <td>Triple Olympic gold medalist Stephanie Rice sa...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>91</td>\n    </tr>\n    <tr>\n      <th>2401</th>\n      <td>4</td>\n      <td>Singapore exchange to buy Australian bourse fo...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2407</th>\n      <td>4</td>\n      <td>West Indies beat England by five wickets under...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>2413</th>\n      <td>4</td>\n      <td>Eurozone recovery falters in Q4 as economy gro...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>2467</th>\n      <td>4</td>\n      <td>Coast Guard Adm. Thad Allen: cap now funneling...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2487</th>\n      <td>4</td>\n      <td>Spanish bank BBVA reported Wednesday its fourt...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>99</td>\n    </tr>\n    <tr>\n      <th>2526</th>\n      <td>4</td>\n      <td>Results Thursday from the St. Petersburg Open ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>2542</th>\n      <td>4</td>\n      <td>Brome Howard Inn 18281 Rosecroft Rd., St. Mary...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>2544</th>\n      <td>4</td>\n      <td>Results Sunday from the Japan Open, a $1.2 mil...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>2556</th>\n      <td>4</td>\n      <td>Simone Hauswald of Germany mastered windy and ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>2563</th>\n      <td>4</td>\n      <td>Consumers increased their spending in June for...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>99</td>\n    </tr>\n    <tr>\n      <th>2609</th>\n      <td>4</td>\n      <td>America picked up its first victory of the Mex...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>89</td>\n    </tr>\n    <tr>\n      <th>2612</th>\n      <td>4</td>\n      <td>Norway's Marit Bjoergen has won the women's 10...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>2629</th>\n      <td>4</td>\n      <td>A federal judge has sentenced former Democrati...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>2666</th>\n      <td>4</td>\n      <td>Gold for current delivery closed at $1,159.70 ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>2686</th>\n      <td>4</td>\n      <td>Serbia coach Radomir Antic has reduced his squ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>2702</th>\n      <td>4</td>\n      <td>Unemployment in Britain for the three months e...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>2731</th>\n      <td>4</td>\n      <td>German consumer goods company Beiersdorf repor...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>2760</th>\n      <td>4</td>\n      <td>Share prices on the London Stock Exchange were...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>2825</th>\n      <td>4</td>\n      <td>Scores at lunch Tuesday on the first day of th...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>2830</th>\n      <td>4</td>\n      <td>Sevilla's Diego Perotti will be sidelined for ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>2833</th>\n      <td>4</td>\n      <td>Attacking midfielder Marek Hamsik has extended...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>2877</th>\n      <td>4</td>\n      <td>The United States beat Russia 4-3 on Sunday fo...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>2879</th>\n      <td>4</td>\n      <td>Pakistan has been bowled out for 296 on the fo...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>2884</th>\n      <td>4</td>\n      <td>Netherlands becomes first team to qualify for ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2892</th>\n      <td>4</td>\n      <td>Death toll from Indonesian volcano climbs to 9...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2930</th>\n      <td>4</td>\n      <td>Montenegro's government on Thursday canceled a...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>98</td>\n    </tr>\n    <tr>\n      <th>2967</th>\n      <td>4</td>\n      <td>Barbados international and former Millwall for...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>2981</th>\n      <td>4</td>\n      <td>Dominican Republic cyclist Leonardo Grullon ha...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>96</td>\n    </tr>\n    <tr>\n      <th>2997</th>\n      <td>4</td>\n      <td>River Plate midfielder Diego Buonanotte has un...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>96</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install captum\nimport captum\nfrom captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:07:36.942113Z","iopub.execute_input":"2024-04-17T12:07:36.942615Z","iopub.status.idle":"2024-04-17T12:07:53.205117Z","shell.execute_reply.started":"2024-04-17T12:07:36.942580Z","shell.execute_reply":"2024-04-17T12:07:53.203344Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: captum in /opt/conda/lib/python3.10/site-packages (0.7.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from captum) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from captum) (1.26.4)\nRequirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.10/site-packages (from captum) (2.1.2+cpu)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from captum) (4.66.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (2024.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6->captum) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6->captum) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"pp.preprocess_single_row?","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:44:38.534902Z","iopub.execute_input":"2024-04-17T10:44:38.535272Z","iopub.status.idle":"2024-04-17T10:44:38.542545Z","shell.execute_reply.started":"2024-04-17T10:44:38.535246Z","shell.execute_reply":"2024-04-17T10:44:38.541126Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[0;31mSignature:\u001b[0m\n\u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_single_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmax_sent_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmax_num_sents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mpreprocess_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m\nConverts text into integers that index the vocab,\nand converts labels into the range [0,num_classes-1]\n\nReturn tokens by sentence (unpadded), idx by sentence (padded), label, num_sentences, num_tokens\n\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_33/1799194567.py\n\u001b[0;31mType:\u001b[0m      method"},"metadata":{}}]},{"cell_type":"code","source":"token_reference = TokenReferenceBase(reference_token_idx=0)\nlig = LayerIntegratedGradients(model, model.embedding)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:07:53.207403Z","iopub.execute_input":"2024-04-17T12:07:53.207833Z","iopub.status.idle":"2024-04-17T12:07:53.215658Z","shell.execute_reply.started":"2024-04-17T12:07:53.207797Z","shell.execute_reply":"2024-04-17T12:07:53.213763Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\nF.softmax(torch.tensor([[1.0],[2],[3],[4]]), dim=-2)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T11:15:53.522060Z","iopub.execute_input":"2024-04-17T11:15:53.522536Z","iopub.status.idle":"2024-04-17T11:15:53.594490Z","shell.execute_reply.started":"2024-04-17T11:15:53.522502Z","shell.execute_reply":"2024-04-17T11:15:53.592893Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"tensor([[0.0321],\n        [0.0871],\n        [0.2369],\n        [0.6439]])"},"metadata":{}}]},{"cell_type":"code","source":"import torch.nn.functional as F\nvis_data_records_ig = []\nlabelid2label = ['Satire', 'Hoax', 'Propaganda', 'Trusted']\ndef interpret_sentence(model, text_and_label, vizpreproc, max_num_sents, max_sent_len):\n    words, tokens, labels, num_sents, num_tokens = vizpreproc.preprocess_single_row(text_and_label, max_sent_len, max_num_sents, preprocess_label=True)\n    words = [sent + ['<UNK>']*(max_sent_len-num_tok) for sent, num_tok in zip(words, num_tokens[0])]\n    words += [['<UNK>']*max_sent_len]*(max_num_sents-len(words))\n\n    model.zero_grad()\n\n\n    # predict\n    logits = model(tokens, num_sents.unsqueeze(0), num_tokens)\n    print('here')\n    pred = torch.argmax(logits, dim=-1).item()\n    prob = F.softmax(logits, dim = 1)[0][pred]\n    \n    # \n    base_tokens = torch.zeros_like(tokens)\n    \n    \n    # compute attributions and approximation delta using layer integrated gradients\n    attributions_ig = lig.attribute(tokens, baselines=0, target=[0],additional_forward_args=(num_sents.unsqueeze(0), num_tokens) , n_steps=10, return_convergence_delta=False)\n\n    print('pred: ', labelid2label[pred], '(', '%.2f'%prob, ')')\n    return attributions_ig\n    add_attributions_to_visualizer(attributions_ig, text, prob, pred, labels, delta, vis_data_records_ig)\n    \ndef add_attributions_to_visualizer(attributions, text, prob, pred, label, delta, vis_data_records):\n    attributions = attributions.sum(dim=2).squeeze(0)\n    attributions = attributions / torch.norm(attributions)\n    attributions = attributions.cpu().detach().numpy()\n\n    # storing couple samples in an array for visualization purposes\n    vis_data_records.append(visualization.VisualizationDataRecord(\n                            attributions,\n                            prob,\n                            labelid2label[pred],\n                            labelid2label[label],\n                            labelid2label[3],\n                            attributions.sum(),\n                            text,\n                            delta))","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:08:02.107096Z","iopub.execute_input":"2024-04-17T12:08:02.107818Z","iopub.status.idle":"2024-04-17T12:08:02.128132Z","shell.execute_reply.started":"2024-04-17T12:08:02.107760Z","shell.execute_reply":"2024-04-17T12:08:02.126295Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"d","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:01:54.509237Z","iopub.execute_input":"2024-04-17T12:01:54.509699Z","iopub.status.idle":"2024-04-17T12:01:54.519962Z","shell.execute_reply.started":"2024-04-17T12:01:54.509667Z","shell.execute_reply":"2024-04-17T12:01:54.518147Z"},"trusted":true},"execution_count":111,"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"tensor([16])"},"metadata":{}}]},{"cell_type":"code","source":"a = interpret_sentence(model, test_df.iloc[0], pp, 30, 30)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:09:14.802638Z","iopub.execute_input":"2024-04-17T12:09:14.804265Z","iopub.status.idle":"2024-04-17T12:09:16.147570Z","shell.execute_reply.started":"2024-04-17T12:09:14.804201Z","shell.execute_reply":"2024-04-17T12:09:16.145516Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"here\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43minterpret_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[11], line 23\u001b[0m, in \u001b[0;36minterpret_sentence\u001b[0;34m(model, text_and_label, vizpreproc, max_num_sents, max_sent_len)\u001b[0m\n\u001b[1;32m     19\u001b[0m base_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(tokens)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# compute attributions and approximation delta using layer integrated gradients\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m attributions_ig \u001b[38;5;241m=\u001b[39m \u001b[43mlig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_sents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_convergence_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred: \u001b[39m\u001b[38;5;124m'\u001b[39m, labelid2label[pred], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39mprob, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attributions_ig\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/captum/attr/_core/layer/layer_integrated_gradients.py:496\u001b[0m, in \u001b[0;36mLayerIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta, attribute_to_layer_input)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mig\u001b[38;5;241m.\u001b[39mgradient_func \u001b[38;5;241m=\u001b[39m gradient_func\n\u001b[1;32m    490\u001b[0m all_inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    491\u001b[0m     (inps \u001b[38;5;241m+\u001b[39m additional_forward_args)\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m additional_forward_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m inps\n\u001b[1;32m    494\u001b[0m )\n\u001b[0;32m--> 496\u001b[0m attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# self\u001b[39;49;00m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaselines_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43minternal_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minternal_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_convergence_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# handle multiple outputs\u001b[39;00m\n\u001b[1;32m    509\u001b[0m output: List[Tuple[Tensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    511\u001b[0m         attributions[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(num_outputs))\n\u001b[1;32m    516\u001b[0m ]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/captum/attr/_core/integrated_gradients.py:286\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    274\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m _batch_attribution(\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    276\u001b[0m         num_examples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_convergence_delta:\n\u001b[1;32m    296\u001b[0m     start_point, end_point \u001b[38;5;241m=\u001b[39m baselines, inputs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/captum/attr/_core/integrated_gradients.py:351\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    348\u001b[0m expanded_target \u001b[38;5;241m=\u001b[39m _expand_target(target, n_steps)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaled_features_tpl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_additional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[1;32m    360\u001b[0m scaled_grads \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    361\u001b[0m     grad\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(step_sizes)\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(grad\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads\n\u001b[1;32m    364\u001b[0m ]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/captum/attr/_core/layer/layer_integrated_gradients.py:472\u001b[0m, in \u001b[0;36mLayerIntegratedGradients.attribute.<locals>.gradient_func\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m    468\u001b[0m         hooks\u001b[38;5;241m.\u001b[39mappend(hook)\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;66;03m# the inputs is an empty tuple\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# coz it is prepended into additional_forward_args\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m hooks:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/captum/_utils/common.py:531\u001b[0m, in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    528\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _format_inputs(inputs)\n\u001b[1;32m    529\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[0;32m--> 531\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mforward_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _select_targets(output, target)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[5], line 62\u001b[0m, in \u001b[0;36mBiLSTMHeAttFCNNClassifier.forward\u001b[0;34m(self, X_batch, num_sents, sent_lens, return_attn_weights)\u001b[0m\n\u001b[1;32m     60\u001b[0m output, (_, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_encoder(embeddings)\n\u001b[1;32m     61\u001b[0m padding_positions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_padding_masks(lens[:n], max_sent_len)\u001b[38;5;241m.\u001b[39mto(output\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 62\u001b[0m sent_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attn_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_attn_weights:\n\u001b[1;32m     64\u001b[0m     word_attn_weights\u001b[38;5;241m.\u001b[39mappend(sent_embeddings[\u001b[38;5;241m1\u001b[39m])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[5], line 16\u001b[0m, in \u001b[0;36mAttentionUnit.forward\u001b[0;34m(self, encoder_output, padding_positions, return_weights)\u001b[0m\n\u001b[1;32m     14\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery(hidden_rep)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding_positions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m \u001b[43msimilarity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadding_positions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m attention_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(similarity\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#Return weighted sum [B,L,1], [B,L,H]-->[B,H]\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (16) must match the size of tensor b (160) at non-singleton dimension 1"],"ename":"RuntimeError","evalue":"The size of tensor a (16) must match the size of tensor b (160) at non-singleton dimension 1","output_type":"error"}]},{"cell_type":"code","source":"a[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T11:38:44.364081Z","iopub.execute_input":"2024-04-17T11:38:44.364602Z","iopub.status.idle":"2024-04-17T11:38:44.374306Z","shell.execute_reply.started":"2024-04-17T11:38:44.364564Z","shell.execute_reply":"2024-04-17T11:38:44.372287Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"torch.Size([16, 30])"},"metadata":{}}]},{"cell_type":"code","source":"torch.tensor([[False]*i + [True]*(30-i) for i in a[1]]).unsqueeze(2).shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:01:33.788968Z","iopub.execute_input":"2024-04-17T12:01:33.789563Z","iopub.status.idle":"2024-04-17T12:01:33.802409Z","shell.execute_reply.started":"2024-04-17T12:01:33.789523Z","shell.execute_reply":"2024-04-17T12:01:33.800525Z"},"trusted":true},"execution_count":107,"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"torch.Size([16, 30, 1])"},"metadata":{}}]}]}